{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "import copy\n",
    "from PIL import Image, ImageFilter\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a smaller subset of data for quicker experiments\n",
    "TRAIN_SUBSET_SIZE = 8000  # Reduced from 10000\n",
    "VALID_SUBSET_SIZE = 8000\n",
    "TEST_SUBSET_SIZE = 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seeds for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tensor created on MPS successfully: mps:0\n",
      "MPS is working properly\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Function for checking device\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        try:\n",
    "            # Try creating a tensor on MPS\n",
    "            test_tensor = torch.zeros(1, device=\"mps\")\n",
    "            print(f\"Test tensor created on MPS successfully: {test_tensor.device}\")\n",
    "            print(\"MPS is working properly\")\n",
    "            return torch.device(\"mps\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing MPS: {e}\")\n",
    "    \n",
    "    print(\"Using CPU\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset subset function\n",
    "def create_subset_dataset(original_dataset, num_samples=10000, balanced=True):\n",
    "    \"\"\"\n",
    "    Create a subset of the original dataset with equal class distribution\n",
    "    \"\"\"\n",
    "    if balanced:\n",
    "        # Get class labels\n",
    "        targets = torch.tensor([target for _, target in original_dataset.samples])\n",
    "        classes = torch.unique(targets)\n",
    "        num_classes = len(classes)\n",
    "        samples_per_class = num_samples // num_classes\n",
    "        \n",
    "        indices = []\n",
    "        for cls in classes:\n",
    "            cls_indices = torch.where(targets == cls)[0]\n",
    "            # If we have fewer samples than requested, take all of them\n",
    "            if len(cls_indices) <= samples_per_class:\n",
    "                indices.extend(cls_indices.tolist())\n",
    "            else:\n",
    "                # Otherwise randomly sample\n",
    "                selected = cls_indices[torch.randperm(len(cls_indices))[:samples_per_class]]\n",
    "                indices.extend(selected.tolist())\n",
    "        \n",
    "        return Subset(original_dataset, indices)\n",
    "    else:\n",
    "        # Simple random subset\n",
    "        return Subset(original_dataset, torch.randperm(len(original_dataset))[:num_samples].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data augmentation techniques\n",
    "def cutout_transform(img, n_holes=1, length=16):\n",
    "    \"\"\"Apply cutout augmentation to a tensor image\"\"\"\n",
    "    h = img.size(1)\n",
    "    w = img.size(2)\n",
    "    \n",
    "    mask = torch.ones((h, w))\n",
    "    \n",
    "    for n in range(n_holes):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        \n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "        \n",
    "        mask[y1: y2, x1: x2] = 0.\n",
    "    \n",
    "    mask = mask.expand_as(img)\n",
    "    return img * mask\n",
    "\n",
    "class CutoutTransform:\n",
    "    \"\"\"Wrapper class for the cutout transform to use in torchvision transforms\"\"\"\n",
    "    def __init__(self, n_holes=1, length=16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return cutout_transform(img, self.n_holes, self.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries of transforms for our experiments\n",
    "standard_transforms = {\n",
    "    'baseline': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'horizontal_flip': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'rotation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'color_jitter': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'combined_standard': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Advanced augmentation with Cutout\n",
    "advanced_transforms = {\n",
    "    'cutout': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        CutoutTransform(n_holes=1, length=32)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original datasets...\n",
      "Creating subsets...\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Training samples: 8000\n",
      "Validation samples: 8000\n",
      "Test samples: 8000\n"
     ]
    }
   ],
   "source": [
    "# Load full datasets first\n",
    "print(\"Loading original datasets...\")\n",
    "full_train_dataset = ImageFolder(root='data/train', transform=standard_transforms['baseline'])\n",
    "full_valid_dataset = ImageFolder(root='data/valid', transform=standard_transforms['baseline'])\n",
    "full_test_dataset = ImageFolder(root='data/test', transform=standard_transforms['baseline'])\n",
    "\n",
    "# Create reduced subsets\n",
    "print(\"Creating subsets...\")\n",
    "train_dataset = create_subset_dataset(full_train_dataset, num_samples=TRAIN_SUBSET_SIZE)\n",
    "valid_dataset = create_subset_dataset(full_valid_dataset, num_samples=VALID_SUBSET_SIZE)\n",
    "test_dataset = create_subset_dataset(full_test_dataset, num_samples=TEST_SUBSET_SIZE)\n",
    "\n",
    "# Save class names\n",
    "class_names = full_train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(valid_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientnet_model(num_classes=10, pretrained=True, dropout_rate=0.2):\n",
    "    \"\"\"Create EfficientNet B0 model\"\"\"\n",
    "    if pretrained:\n",
    "        weights = EfficientNet_B0_Weights.DEFAULT\n",
    "        model = efficientnet_b0(weights=weights)\n",
    "    else:\n",
    "        model = efficientnet_b0(weights=None)\n",
    "    \n",
    "    # Replace classifier\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_rate, inplace=True),\n",
    "        nn.Linear(in_features=in_features, out_features=num_classes),\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom CNN as a third architecture option\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        \n",
    "        # Fully connected\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False) as t:\n",
    "        for images, labels in t:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to conduct an experiment\n",
    "def run_experiment(experiment_name, model, train_dataset, valid_dataset, test_dataset, \n",
    "                  hyperparams, batch_size=64, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Run a full training experiment with given hyperparameters\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} Running experiment: {experiment_name} {'='*20}\")\n",
    "    for key, value in hyperparams.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    if hyperparams['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'], \n",
    "                              weight_decay=hyperparams['weight_decay'])\n",
    "    elif hyperparams['optimizer'] == 'sgd':\n",
    "        momentum = hyperparams.get('momentum', 0.9)  # Default momentum to 0.9 if not specified\n",
    "        nesterov = hyperparams.get('nesterov', False)  # Default nesterov to False if not specified\n",
    "        optimizer = optim.SGD(model.parameters(), lr=hyperparams['learning_rate'], \n",
    "                             momentum=momentum, weight_decay=hyperparams['weight_decay'],\n",
    "                             nesterov=nesterov)\n",
    "\n",
    "    # Initialize criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize scheduler\n",
    "    if hyperparams['scheduler'] == 'plateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    elif hyperparams['scheduler'] == 'cosine':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    best_val_acc = 0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train and validate\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        valid_loss, valid_acc = validate(model, valid_loader, criterion, device)\n",
    "        \n",
    "        # Scheduler step\n",
    "        if hyperparams['scheduler'] == 'plateau':\n",
    "            scheduler.step(valid_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if valid_acc > best_val_acc:\n",
    "            best_val_acc = valid_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time/60:.2f} minutes\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_acc, all_preds, all_labels = evaluate(model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'name': experiment_name,\n",
    "        'hyperparams': hyperparams,\n",
    "        'train_losses': train_losses,\n",
    "        'valid_losses': valid_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'valid_accuracies': valid_accuracies,\n",
    "        'test_accuracy': test_acc,\n",
    "        'confusion_matrix': cm,\n",
    "        'model_state': best_model_wts,\n",
    "        'all_preds': all_preds,\n",
    "        'all_labels': all_labels\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Few-shot learning implementation =======\n",
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "    \n",
    "    def forward(self, support_images, support_labels, query_images):\n",
    "        \"\"\"\n",
    "        Implements the forward pass of Prototypical Networks\n",
    "        \n",
    "        Args:\n",
    "            support_images: support set images [n_classes * n_shots, channels, height, width]\n",
    "            support_labels: support set labels [n_classes * n_shots]\n",
    "            query_images: query set images [n_queries, channels, height, width]\n",
    "        \n",
    "        Returns:\n",
    "            query_logits: classification logits for the query images\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        support_features = self.backbone(support_images)  # [n_classes * n_shots, feature_dim]\n",
    "        query_features = self.backbone(query_images)      # [n_queries, feature_dim]\n",
    "        \n",
    "        # Compute class prototypes\n",
    "        n_classes = len(torch.unique(support_labels))\n",
    "        prototypes = torch.zeros(n_classes, support_features.shape[1], device=support_features.device)\n",
    "        \n",
    "        for c in range(n_classes):\n",
    "            # Select features of class c\n",
    "            class_mask = (support_labels == c)\n",
    "            class_features = support_features[class_mask]\n",
    "            # Average features to get the prototype\n",
    "            prototypes[c] = class_features.mean(dim=0)\n",
    "        \n",
    "        # Compute distances between query features and prototypes\n",
    "        # Expand dimensions for broadcasting\n",
    "        query_features = query_features.unsqueeze(1)  # [n_queries, 1, feature_dim]\n",
    "        prototypes = prototypes.unsqueeze(0)          # [1, n_classes, feature_dim]\n",
    "        \n",
    "        # Compute Euclidean distances\n",
    "        distances = torch.sum((query_features - prototypes)**2, dim=2)\n",
    "        \n",
    "        # Convert distances to logits (negative distances)\n",
    "        return -distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_evaluation(backbone, test_dataset, device, n_way=5, n_shot=5, n_query=15, n_episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluates the backbone on few-shot classification tasks\n",
    "    \"\"\"\n",
    "    backbone.eval()\n",
    "    \n",
    "    # Function to create few-shot tasks\n",
    "    def create_episode(dataset, n_way, n_shot, n_query):\n",
    "        # Sample n_way classes\n",
    "        classes = random.sample(range(len(dataset.classes)), n_way)\n",
    "        \n",
    "        # Initialize tensors to store images and labels\n",
    "        support_images = []\n",
    "        support_labels = []\n",
    "        query_images = []\n",
    "        query_labels = []\n",
    "        \n",
    "        # For each class, sample n_shot and n_query examples\n",
    "        for i, cls in enumerate(classes):\n",
    "            # Get indices of all examples from this class\n",
    "            class_indices = [idx for idx, (_, label) in enumerate(dataset) if label == cls]\n",
    "            # Sample support and query sets\n",
    "            support_indices = random.sample(class_indices, n_shot)\n",
    "            remaining_indices = [idx for idx in class_indices if idx not in support_indices]\n",
    "            query_indices = random.sample(remaining_indices, min(n_query, len(remaining_indices)))\n",
    "            \n",
    "            # Add to support and query sets\n",
    "            for idx in support_indices:\n",
    "                image, _ = dataset[idx]\n",
    "                support_images.append(image)\n",
    "                support_labels.append(i)  # Use an index from 0 to n_way-1 as the label\n",
    "            \n",
    "            for idx in query_indices:\n",
    "                image, _ = dataset[idx]\n",
    "                query_images.append(image)\n",
    "                query_labels.append(i)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "        \n",
    "        return support_images, support_labels, query_images, query_labels\n",
    "    \n",
    "    # Create prototypical network\n",
    "    proto_net = PrototypicalNetworks(backbone).to(device)\n",
    "    \n",
    "    # List to store accuracies\n",
    "    accuracies = []\n",
    "    \n",
    "    # Evaluate over multiple episodes\n",
    "    for episode in tqdm(range(n_episodes), desc=\"Few-shot evaluation\"):\n",
    "        # Create an episode (task)\n",
    "        support_images, support_labels, query_images, query_labels = create_episode(\n",
    "            test_dataset, n_way, n_shot, n_query\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        support_images = support_images.to(device)\n",
    "        support_labels = support_labels.to(device)\n",
    "        query_images = query_images.to(device)\n",
    "        query_labels = query_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            query_logits = proto_net(support_images, support_labels, query_images)\n",
    "            _, query_preds = torch.max(query_logits, dim=1)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (query_preds == query_labels).float().mean().item() * 100\n",
    "            accuracies.append(accuracy)\n",
    "    \n",
    "    # Return average accuracy\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    \n",
    "    print(f\"Few-shot learning ({n_way}-way, {n_shot}-shot): {avg_accuracy:.2f}% ± {std_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor for few-shot learning\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Use a pre-trained model but remove the final layer\n",
    "        self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        # Remove the classifier\n",
    "        self.features = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        # Add a flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement ensemble prediction\n",
    "def ensemble_prediction(models, test_loader, device, method='hard'):\n",
    "    \"\"\"\n",
    "    Implement ensemble prediction using multiple models\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained models\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Device to run on\n",
    "        method: 'hard' for majority voting or 'soft' for probability averaging\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Ensemble accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    if not models:\n",
    "        return 0.0, [], []\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                probabilities.append(probs.cpu())\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        all_probs.append(torch.cat(probabilities, dim=0).numpy())\n",
    "    \n",
    "    # Get true labels\n",
    "    true_labels = []\n",
    "    for _, labels in test_loader:\n",
    "        true_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Create ensemble predictions\n",
    "    if method == 'hard':\n",
    "        # Majority voting\n",
    "        ensemble_preds = []\n",
    "        for i in range(len(true_labels)):\n",
    "            votes = [all_predictions[j][i] for j in range(len(models))]\n",
    "            # Count occurrences of each class\n",
    "            vote_counts = np.bincount(votes, minlength=num_classes)\n",
    "            # Select class with most votes\n",
    "            ensemble_preds.append(np.argmax(vote_counts))\n",
    "    else:  # 'soft' voting\n",
    "        # Average probabilities\n",
    "        ensemble_probs = np.mean(all_probs, axis=0)\n",
    "        ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(ensemble_preds) == np.array(true_labels)) * 100\n",
    "    \n",
    "    return accuracy, ensemble_preds, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIGURATIONS\n",
    "# 1. Architecture Comparison (removed ResNet)\n",
    "architectures = {\n",
    "    'efficientnet': create_efficientnet_model(num_classes),\n",
    "    'custom_cnn': CustomCNN(num_classes)\n",
    "}\n",
    "\n",
    "# 2. Hyperparameter Configurations for Training Process\n",
    "training_hyperparams = [\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'sgd', 'learning_rate': 0.01, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'cosine', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.0001, 'scheduler': 'plateau', 'weight_decay': 0.0001},  # Lower learning rate\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.01, 'scheduler': 'plateau', 'weight_decay': 0.0001},    # Higher learning rate\n",
    "    {'optimizer': 'sgd', 'learning_rate': 0.001, 'scheduler': 'cosine', 'weight_decay': 0.0001},     # SGD with cosine scheduler\n",
    "    {'optimizer': 'sgd', 'learning_rate': 0.01, 'scheduler': 'cosine', 'weight_decay': 0.0001, 'momentum': 0.9, 'nesterov': True}  # SGD with Nesterov momentum\n",
    "]\n",
    "\n",
    "# 3. Hyperparameter Configurations for Regularization\n",
    "regularization_hyperparams = [\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001, 'dropout_rate': 0.2},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.001, 'dropout_rate': 0.2},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0, 'dropout_rate': 0.2},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001, 'dropout_rate': 0.5},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001, 'dropout_rate': 0.0}\n",
    "]\n",
    "\n",
    "# 4. Data Augmentation Experiments\n",
    "# We'll use a modified version of the train_dataset for each transform\n",
    "augmentation_datasets = {}\n",
    "\n",
    "# Apply each transform to create new datasets\n",
    "for name, transform in standard_transforms.items():\n",
    "    augmentation_datasets[name] = ImageFolder(\n",
    "        root='data/train', \n",
    "        transform=transform\n",
    "    )\n",
    "    # Create a subset of the data\n",
    "    augmentation_datasets[name] = create_subset_dataset(augmentation_datasets[name], num_samples=TRAIN_SUBSET_SIZE)\n",
    "\n",
    "# Add advanced augmentation\n",
    "for name, transform in advanced_transforms.items():\n",
    "    augmentation_datasets[name] = ImageFolder(\n",
    "        root='data/train', \n",
    "        transform=transform\n",
    "    )\n",
    "    # Create a subset of the data\n",
    "    augmentation_datasets[name] = create_subset_dataset(augmentation_datasets[name], num_samples=TRAIN_SUBSET_SIZE)\n",
    "\n",
    "# Dictionary to store results of all experiments\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ARCHITECTURE COMPARISON ==============================\n",
      "\n",
      "Training efficientnet...\n",
      "\n",
      "==================== Running experiment: Architecture_efficientnet ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065b92fd37a843c79a3fcda5610aad18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.9279 | Train Acc: 68.56%\n",
      "Valid Loss: 0.6850 | Valid Acc: 76.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6575e3c9b142efb7bc6aaa4e9e7325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.4403 | Train Acc: 84.61%\n",
      "Valid Loss: 0.7002 | Valid Acc: 76.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b936ec5901ae4a71a20a676317034a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.3044 | Train Acc: 89.42%\n",
      "Valid Loss: 0.7406 | Valid Acc: 77.71%\n",
      "Training completed in 2.85 minutes\n",
      "Test Accuracy: 78.67%\n",
      "\n",
      "Training custom_cnn...\n",
      "\n",
      "==================== Running experiment: Architecture_custom_cnn ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84806b1eb294883812109ed1c02dd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 2.1121 | Train Acc: 20.19%\n",
      "Valid Loss: 2.1781 | Valid Acc: 19.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4d90e9ca6542c1b5e0cc98f9dd2dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 1.9828 | Train Acc: 23.55%\n",
      "Valid Loss: 1.9764 | Valid Acc: 24.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccd6468576448cca576dbee379875d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 1.9205 | Train Acc: 26.07%\n",
      "Valid Loss: 1.8664 | Valid Acc: 28.95%\n",
      "Training completed in 3.15 minutes\n",
      "Test Accuracy: 28.48%\n"
     ]
    }
   ],
   "source": [
    "# ==== RUN EXPERIMENTS ====\n",
    "# 1. Architecture Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" ARCHITECTURE COMPARISON \" + \"=\"*30)\n",
    "architecture_results = {}\n",
    "\n",
    "for arch_name, model in architectures.items():\n",
    "    print(f\"\\nTraining {arch_name}...\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    hyperparams = {\n",
    "        'optimizer': 'adam',\n",
    "        'learning_rate': 0.001,\n",
    "        'scheduler': 'plateau',\n",
    "        'weight_decay': 0.0001\n",
    "    }\n",
    "    \n",
    "    results = run_experiment(\n",
    "        f\"Architecture_{arch_name}\",\n",
    "        model, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,  # Larger batch size for faster training\n",
    "        num_epochs=3  # Further reduced epochs for faster comparison\n",
    "    )\n",
    "    \n",
    "    architecture_results[arch_name] = results\n",
    "    all_results[f\"Architecture_{arch_name}\"] = results\n",
    "    \n",
    "    # Save model state\n",
    "    torch.save(model.state_dict(), f\"{arch_name}_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TRAINING HYPERPARAMETERS COMPARISON ==============================\n",
      "Using best architecture: efficientnet\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_1 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1082bcf1bb79468fb7940d94921af44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.2789 | Train Acc: 90.33%\n",
      "Valid Loss: 0.7669 | Valid Acc: 77.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060af80e60734263a36adb8e98433c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1761 | Train Acc: 94.04%\n",
      "Valid Loss: 0.8718 | Valid Acc: 77.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87aee53c5de1468aae6098d122a26594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1405 | Train Acc: 95.34%\n",
      "Valid Loss: 1.0005 | Valid Acc: 76.54%\n",
      "Training completed in 2.89 minutes\n",
      "Test Accuracy: 77.96%\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_2 ====================\n",
      "optimizer: sgd\n",
      "learning_rate: 0.01\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51af51204a046e1b73e128a57d3b1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.010000\n",
      "Train Loss: 0.0840 | Train Acc: 97.38%\n",
      "Valid Loss: 0.7036 | Valid Acc: 81.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a5efd239c048bfa164d68016ce0779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.010000\n",
      "Train Loss: 0.0436 | Train Acc: 98.76%\n",
      "Valid Loss: 0.7085 | Valid Acc: 81.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d16b3532f74dfeba1ae8d5c9180b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.010000\n",
      "Train Loss: 0.0280 | Train Acc: 99.21%\n",
      "Valid Loss: 0.7164 | Valid Acc: 82.04%\n",
      "Training completed in 2.92 minutes\n",
      "Test Accuracy: 81.65%\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_3 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: cosine\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2689971e273244b598a2f604439271b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.000750\n",
      "Train Loss: 0.1856 | Train Acc: 93.92%\n",
      "Valid Loss: 0.8499 | Valid Acc: 77.79%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac33a058757d44cf8b05967fcc6eb79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.000250\n",
      "Train Loss: 0.0929 | Train Acc: 97.03%\n",
      "Valid Loss: 0.8195 | Valid Acc: 80.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8957c750e5b24557af9f3dabf09f4970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.000000\n",
      "Train Loss: 0.0386 | Train Acc: 98.89%\n",
      "Valid Loss: 0.7621 | Valid Acc: 81.89%\n",
      "Training completed in 2.98 minutes\n",
      "Test Accuracy: 81.79%\n"
     ]
    }
   ],
   "source": [
    "# 2. Training Hyperparameters Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" TRAINING HYPERPARAMETERS COMPARISON \" + \"=\"*30)\n",
    "training_results = {}\n",
    "\n",
    "for arch_name, model_creator in architectures.items():\n",
    "    print(f\"\\nTesting architecture: {arch_name}\")\n",
    "    \n",
    "    for i, hyperparams in enumerate(training_hyperparams):\n",
    "        # Create a new model with this architecture\n",
    "        if arch_name == 'efficientnet':\n",
    "            model = create_efficientnet_model(num_classes)\n",
    "        else:\n",
    "            model = CustomCNN(num_classes)\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        experiment_name = f\"Training_Hyperparams_{arch_name}_{i+1}\"\n",
    "        results = run_experiment(\n",
    "            experiment_name,\n",
    "            model, \n",
    "            train_dataset, \n",
    "            valid_dataset, \n",
    "            test_dataset,\n",
    "            hyperparams,\n",
    "            batch_size=128,\n",
    "            num_epochs=3\n",
    "        )\n",
    "        \n",
    "        training_results[experiment_name] = results\n",
    "        all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== REGULARIZATION HYPERPARAMETERS COMPARISON ==============================\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_1 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940452f3d49a426eaebd9877bf0ebe46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.1531 | Train Acc: 94.95%\n",
      "Valid Loss: 1.0889 | Valid Acc: 74.97%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472b841da2544fdbbf94544b53923f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1227 | Train Acc: 96.25%\n",
      "Valid Loss: 0.9122 | Valid Acc: 77.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a3769cdb964f998864dac95cf4654c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1048 | Train Acc: 96.55%\n",
      "Valid Loss: 1.0311 | Valid Acc: 77.34%\n",
      "Training completed in 2.99 minutes\n",
      "Test Accuracy: 78.15%\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_2 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cd19c0b350441f8d6858e884c5ae6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.1576 | Train Acc: 94.89%\n",
      "Valid Loss: 0.9251 | Valid Acc: 75.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d38acad71c94a36a45af3a954012487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1568 | Train Acc: 94.70%\n",
      "Valid Loss: 0.8873 | Valid Acc: 76.86%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9386d252fb044e4d96efcdc7e39abdd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1501 | Train Acc: 95.04%\n",
      "Valid Loss: 0.8594 | Valid Acc: 76.59%\n",
      "Training completed in 2.98 minutes\n",
      "Test Accuracy: 76.45%\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_3 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6a2553443343579f1ba3904a462bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.1663 | Train Acc: 94.50%\n",
      "Valid Loss: 1.0589 | Valid Acc: 76.99%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae9c72c8e1a45e48c41010c4c8499ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1346 | Train Acc: 95.55%\n",
      "Valid Loss: 0.9799 | Valid Acc: 76.03%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4391c017cc4e5fae9d2b4b04581e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.0913 | Train Acc: 96.85%\n",
      "Valid Loss: 1.1091 | Valid Acc: 76.74%\n",
      "Training completed in 2.97 minutes\n",
      "Test Accuracy: 76.17%\n"
     ]
    }
   ],
   "source": [
    "# 3. Regularization Hyperparameters Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" REGULARIZATION HYPERPARAMETERS COMPARISON \" + \"=\"*30)\n",
    "regularization_results = {}\n",
    "\n",
    "for arch_name, model_creator in architectures.items():\n",
    "    print(f\"\\nTesting architecture: {arch_name}\")\n",
    "    \n",
    "    for i, hyperparams in enumerate(regularization_hyperparams):\n",
    "        # Create a new model with this architecture\n",
    "        if arch_name == 'efficientnet':\n",
    "            model = create_efficientnet_model(num_classes, dropout_rate=hyperparams.get('dropout_rate', 0.2))\n",
    "        else:\n",
    "            model = CustomCNN(num_classes)  # Note: You'd need to modify CustomCNN to use the dropout rate parameter\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        experiment_name = f\"Regularization_Hyperparams_{arch_name}_{i+1}\"\n",
    "        results = run_experiment(\n",
    "            experiment_name,\n",
    "            model, \n",
    "            train_dataset, \n",
    "            valid_dataset, \n",
    "            test_dataset,\n",
    "            hyperparams,\n",
    "            batch_size=128,\n",
    "            num_epochs=3\n",
    "        )\n",
    "        \n",
    "        regularization_results[experiment_name] = results\n",
    "        all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== DATA AUGMENTATION COMPARISON ==============================\n",
      "\n",
      "Testing standard augmentation: baseline\n",
      "\n",
      "==================== Running experiment: Augmentation_baseline ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a3b45a9dfe4c26bb04e7d71e46aafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6552 | Train Acc: 78.70%\n",
      "Valid Loss: 0.5431 | Valid Acc: 80.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114460fcd1ff4adeab89fb5c87faddbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3117 | Train Acc: 89.36%\n",
      "Valid Loss: 0.6553 | Valid Acc: 79.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f480f3d1d7d4441a6461f43527c2a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2018 | Train Acc: 93.17%\n",
      "Valid Loss: 0.8108 | Valid Acc: 77.61%\n",
      "Training completed in 3.02 minutes\n",
      "Test Accuracy: 79.96%\n",
      "\n",
      "Testing standard augmentation: horizontal_flip\n",
      "\n",
      "==================== Running experiment: Augmentation_horizontal_flip ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72236f974fcf4805ad5f75d53564ed95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6042 | Train Acc: 78.84%\n",
      "Valid Loss: 0.5905 | Valid Acc: 79.25%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59758cf07ab24a689095cf983154f115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3724 | Train Acc: 86.59%\n",
      "Valid Loss: 0.6182 | Valid Acc: 79.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26658fad84c4c0b9c67519865e07925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2613 | Train Acc: 90.70%\n",
      "Valid Loss: 0.6715 | Valid Acc: 79.09%\n",
      "Training completed in 3.05 minutes\n",
      "Test Accuracy: 79.60%\n",
      "\n",
      "Testing standard augmentation: rotation\n",
      "\n",
      "==================== Running experiment: Augmentation_rotation ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4399f8216aad41359b2eae5d2a4a4689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6220 | Train Acc: 78.31%\n",
      "Valid Loss: 0.5323 | Valid Acc: 81.51%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0b132b374845909b4b6baf89572478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3810 | Train Acc: 86.54%\n",
      "Valid Loss: 0.6145 | Valid Acc: 80.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7268446790894e0db42fa3046e2c2475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.3094 | Train Acc: 88.91%\n",
      "Valid Loss: 0.6353 | Valid Acc: 79.58%\n",
      "Training completed in 3.34 minutes\n",
      "Test Accuracy: 81.10%\n",
      "\n",
      "Testing standard augmentation: color_jitter\n",
      "\n",
      "==================== Running experiment: Augmentation_color_jitter ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caf35483a114c7bbd0046569dc91163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5990 | Train Acc: 78.89%\n",
      "Valid Loss: 0.5583 | Valid Acc: 80.11%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba2a0c7328e4c7d861eab1c68e2a969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3578 | Train Acc: 87.67%\n",
      "Valid Loss: 0.6170 | Valid Acc: 79.45%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326bd84be64f4712b876d069f20a0c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2520 | Train Acc: 91.08%\n",
      "Valid Loss: 0.6793 | Valid Acc: 78.71%\n",
      "Training completed in 3.69 minutes\n",
      "Test Accuracy: 80.74%\n"
     ]
    }
   ],
   "source": [
    "# 4. Data Augmentation Experiments\n",
    "print(\"\\n\" + \"=\"*30 + \" DATA AUGMENTATION COMPARISON \" + \"=\"*30)\n",
    "augmentation_results = {}\n",
    "\n",
    "for arch_name, model_creator in architectures.items():\n",
    "    print(f\"\\nTesting architecture: {arch_name}\")\n",
    "    \n",
    "    # Standard augmentations\n",
    "    for aug_name in ['baseline', 'horizontal_flip', 'rotation', 'color_jitter']:\n",
    "        print(f\"\\nTesting standard augmentation: {aug_name}\")\n",
    "        \n",
    "        # Create a new model with this architecture\n",
    "        if arch_name == 'efficientnet':\n",
    "            model = create_efficientnet_model(num_classes)\n",
    "        else:\n",
    "            model = CustomCNN(num_classes)\n",
    "            \n",
    "        model = model.to(device)\n",
    "        \n",
    "        experiment_name = f\"Augmentation_{arch_name}_{aug_name}\"\n",
    "        results = run_experiment(\n",
    "            experiment_name,\n",
    "            model,\n",
    "            augmentation_datasets[aug_name],\n",
    "            valid_dataset,\n",
    "            test_dataset,\n",
    "            hyperparams,\n",
    "            batch_size=128,\n",
    "            num_epochs=3\n",
    "        )\n",
    "        \n",
    "        augmentation_results[experiment_name] = results\n",
    "        all_results[experiment_name] = results\n",
    "    \n",
    "    # Advanced augmentation (cutout)\n",
    "    print(f\"\\nTesting advanced augmentation with {arch_name}: cutout\")\n",
    "    \n",
    "    # Create a new model with this architecture\n",
    "    if arch_name == 'efficientnet':\n",
    "        model = create_efficientnet_model(num_classes)\n",
    "    else:\n",
    "        model = CustomCNN(num_classes)\n",
    "        \n",
    "    model = model.to(device)\n",
    "    \n",
    "    experiment_name = f\"Augmentation_{arch_name}_cutout\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model,\n",
    "        augmentation_datasets['cutout'],\n",
    "        valid_dataset,\n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    augmentation_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== FEW-SHOT LEARNING ==============================\n",
      "Evaluating few-shot learning capabilities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad05b542c37c4e0585b2d9504ef7c101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Few-shot evaluation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot learning (5-way, 5-shot): 73.53% ± 8.09%\n"
     ]
    }
   ],
   "source": [
    "# 5. Few-shot Learning Experiment\n",
    "print(\"\\n\" + \"=\"*30 + \" FEW-SHOT LEARNING \" + \"=\"*30)\n",
    "\n",
    "# Create feature extractors for few-shot learning\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "\n",
    "# Create custom CNN feature extractor\n",
    "class CustomCNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNNFeatureExtractor, self).__init__()\n",
    "        # Create the base components of CustomCNN\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply convolution blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        \n",
    "        # Flatten and apply FC layer\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "custom_feature_extractor = CustomCNNFeatureExtractor().to(device)\n",
    "\n",
    "# Modify few_shot_evaluation to handle Subset objects\n",
    "def few_shot_evaluation(backbone, dataset, device, n_way=5, n_shot=5, n_query=15, n_episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluates the backbone on few-shot classification tasks\n",
    "    \"\"\"\n",
    "    backbone.eval()\n",
    "    \n",
    "    # Get the original dataset if this is a subset\n",
    "    original_dataset = dataset\n",
    "    if isinstance(dataset, Subset):\n",
    "        # Get the original dataset\n",
    "        original_dataset = dataset.dataset\n",
    "        # Get the class mapping from the original dataset\n",
    "        class_indices = {}\n",
    "        for idx in dataset.indices:\n",
    "            _, label = original_dataset[idx]\n",
    "            if label not in class_indices:\n",
    "                class_indices[label] = []\n",
    "            class_indices[label].append(idx)\n",
    "    else:\n",
    "        # If not a subset, create the mapping directly\n",
    "        class_indices = {}\n",
    "        for idx, (_, label) in enumerate(dataset):\n",
    "            if label not in class_indices:\n",
    "                class_indices[label] = []\n",
    "            class_indices[label].append(idx)\n",
    "    \n",
    "    # Create few-shot tasks function\n",
    "    def create_episode(n_way, n_shot, n_query):\n",
    "        # Sample n_way classes\n",
    "        available_classes = list(class_indices.keys())\n",
    "        if len(available_classes) < n_way:\n",
    "            print(f\"Warning: Only {len(available_classes)} classes available, but {n_way} requested.\")\n",
    "            n_way = len(available_classes)\n",
    "        \n",
    "        classes = random.sample(available_classes, n_way)\n",
    "        \n",
    "        # Initialize tensors to store images and labels\n",
    "        support_images = []\n",
    "        support_labels = []\n",
    "        query_images = []\n",
    "        query_labels = []\n",
    "        \n",
    "        # For each class, sample n_shot and n_query examples\n",
    "        for i, cls in enumerate(classes):\n",
    "            # Get indices of all examples from this class\n",
    "            cls_indices = class_indices[cls]\n",
    "            \n",
    "            # Sample support and query sets\n",
    "            if len(cls_indices) <= n_shot:\n",
    "                support_indices = cls_indices\n",
    "                query_indices = []\n",
    "            else:\n",
    "                # Randomly sample without replacement\n",
    "                random.shuffle(cls_indices)\n",
    "                support_indices = cls_indices[:n_shot]\n",
    "                query_indices = cls_indices[n_shot:n_shot+min(n_query, len(cls_indices)-n_shot)]\n",
    "            \n",
    "            # Add to support and query sets\n",
    "            for idx in support_indices:\n",
    "                image, _ = original_dataset[idx]\n",
    "                support_images.append(image)\n",
    "                support_labels.append(i)  # Use an index from 0 to n_way-1 as the label\n",
    "            \n",
    "            for idx in query_indices:\n",
    "                image, _ = original_dataset[idx]\n",
    "                query_images.append(image)\n",
    "                query_labels.append(i)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "        \n",
    "        return support_images, support_labels, query_images, query_labels\n",
    "    \n",
    "    # Create prototypical network\n",
    "    proto_net = PrototypicalNetworks(backbone).to(device)\n",
    "    \n",
    "    # List to store accuracies\n",
    "    accuracies = []\n",
    "    \n",
    "    # Evaluate over multiple episodes\n",
    "    for episode in tqdm(range(n_episodes), desc=\"Few-shot evaluation\"):\n",
    "        # Create an episode (task)\n",
    "        support_images, support_labels, query_images, query_labels = create_episode(\n",
    "            n_way, n_shot, n_query\n",
    "        )\n",
    "        \n",
    "        # Skip episodes with too few query examples\n",
    "        if len(query_images) < 5:\n",
    "            continue\n",
    "        \n",
    "        # Move to device\n",
    "        support_images = support_images.to(device)\n",
    "        support_labels = support_labels.to(device)\n",
    "        query_images = query_images.to(device)\n",
    "        query_labels = query_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            query_logits = proto_net(support_images, support_labels, query_images)\n",
    "            _, query_preds = torch.max(query_logits, dim=1)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (query_preds == query_labels).float().mean().item() * 100\n",
    "            accuracies.append(accuracy)\n",
    "    \n",
    "    # Return average accuracy\n",
    "    if accuracies:\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        std_accuracy = np.std(accuracies)\n",
    "    else:\n",
    "        avg_accuracy = 0\n",
    "        std_accuracy = 0\n",
    "    \n",
    "    print(f\"Few-shot learning ({n_way}-way, {n_shot}-shot): {avg_accuracy:.2f}% ± {std_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy, std_accuracy\n",
    "\n",
    "print(\"Evaluating few-shot learning capabilities...\")\n",
    "\n",
    "# Evaluate EfficientNet feature extractor\n",
    "print(\"\\nTesting EfficientNet feature extractor:\")\n",
    "efficientnet_acc, efficientnet_std = few_shot_evaluation(\n",
    "    feature_extractor, \n",
    "    test_dataset, \n",
    "    device, \n",
    "    n_way=5,    # 5-way classification \n",
    "    n_shot=5,   # 5-shot learning\n",
    "    n_query=15, # 15 query samples per class\n",
    "    n_episodes=20  # 20 episodes for quick evaluation\n",
    ")\n",
    "\n",
    "# Evaluate Custom CNN feature extractor\n",
    "print(\"\\nTesting Custom CNN feature extractor:\")\n",
    "custom_acc, custom_std = few_shot_evaluation(\n",
    "    custom_feature_extractor,\n",
    "    test_dataset,\n",
    "    device,\n",
    "    n_way=5,\n",
    "    n_shot=5,\n",
    "    n_query=15,\n",
    "    n_episodes=20\n",
    ")\n",
    "\n",
    "# Store results for both architectures\n",
    "few_shot_results = {\n",
    "    'efficientnet': {\n",
    "        'name': 'Few-shot Learning (EfficientNet, 5-way, 5-shot)',\n",
    "        'accuracy': efficientnet_acc,\n",
    "        'std': efficientnet_std\n",
    "    },\n",
    "    'custom_cnn': {\n",
    "        'name': 'Few-shot Learning (Custom CNN, 5-way, 5-shot)', \n",
    "        'accuracy': custom_acc,\n",
    "        'std': custom_std\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add results to all_results\n",
    "all_results['few_shot_efficientnet'] = few_shot_results['efficientnet']\n",
    "all_results['few_shot_custom_cnn'] = few_shot_results['custom_cnn']\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\nFew-shot Learning Architecture Comparison:\")\n",
    "for arch_name, result in few_shot_results.items():\n",
    "    print(f\"{arch_name}: {result['accuracy']:.2f}% ± {result['std']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== REDUCED TRAINING SET EXPERIMENT ==============================\n",
      "\n",
      "Testing with reduced training set size: 4000 samples\n",
      "\n",
      "==================== Running experiment: Reduced_Train_Size_4000 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a7b719fbe84fd384748e24c7a68c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5410 | Train Acc: 81.50%\n",
      "Valid Loss: 0.5539 | Valid Acc: 79.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcb4dbfed8b4cbe8f2ecd49b257430a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.2097 | Train Acc: 93.08%\n",
      "Valid Loss: 0.5776 | Valid Acc: 80.99%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02397e56904449e900d15a804807b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1162 | Train Acc: 96.05%\n",
      "Valid Loss: 0.6875 | Valid Acc: 80.09%\n",
      "Training completed in 2.02 minutes\n",
      "Test Accuracy: 81.66%\n",
      "\n",
      "Testing with reduced training set size: 2000 samples\n",
      "\n",
      "==================== Running experiment: Reduced_Train_Size_2000 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf24063940742bb8b25cc024671cf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5861 | Train Acc: 79.95%\n",
      "Valid Loss: 0.6542 | Valid Acc: 78.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e945f7ce1f40c5906a9442437b243f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.2467 | Train Acc: 92.55%\n",
      "Valid Loss: 0.5533 | Valid Acc: 81.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0aeb3b48f6840ba8cbe332af0ee24fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.0887 | Train Acc: 97.60%\n",
      "Valid Loss: 0.5822 | Valid Acc: 81.41%\n",
      "Training completed in 1.47 minutes\n",
      "Test Accuracy: 81.54%\n"
     ]
    }
   ],
   "source": [
    "# 6. Reduced Training Set Size Experiment\n",
    "print(\"\\n\" + \"=\"*30 + \" REDUCED TRAINING SET EXPERIMENT \" + \"=\"*30)\n",
    "\n",
    "# Create even smaller training subsets\n",
    "smaller_train_sizes = [TRAIN_SUBSET_SIZE // 2, TRAIN_SUBSET_SIZE // 4]\n",
    "reduction_results = {}\n",
    "\n",
    "for arch_name, model_creator in architectures.items():\n",
    "    print(f\"\\nTesting architecture: {arch_name}\")\n",
    "    \n",
    "    for size in smaller_train_sizes:\n",
    "        print(f\"\\nTesting with reduced training set size: {size} samples\")\n",
    "        \n",
    "        # Create reduced training dataset\n",
    "        reduced_train_dataset = create_subset_dataset(full_train_dataset, num_samples=size)\n",
    "        \n",
    "        # Create a new model with this architecture\n",
    "        if arch_name == 'efficientnet':\n",
    "            model = create_efficientnet_model(num_classes)\n",
    "        else:\n",
    "            model = CustomCNN(num_classes)\n",
    "            \n",
    "        model = model.to(device)\n",
    "        \n",
    "        experiment_name = f\"Reduced_Train_Size_{arch_name}_{size}\"\n",
    "        results = run_experiment(\n",
    "            experiment_name,\n",
    "            model,\n",
    "            reduced_train_dataset,\n",
    "            valid_dataset,\n",
    "            test_dataset,\n",
    "            hyperparams,\n",
    "            batch_size=128,\n",
    "            num_epochs=3\n",
    "        )\n",
    "        \n",
    "        reduction_results[experiment_name] = results\n",
    "        all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ENSEMBLE METHODS ==============================\n",
      "\n",
      "Training ensemble model 1/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc7c7f08fcf437488c9e2a732775209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Acc: 88.31% | Valid Acc: 81.15%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42163b861bc24ceb865f780e4e56fa37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 | Train Acc: 96.41% | Valid Acc: 81.06%\n",
      "\n",
      "Training ensemble model 2/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c58b4887824d6da93c14790a504b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Acc: 93.38% | Valid Acc: 77.89%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a153fe0aa44d4f99eccfffb4a98944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 | Train Acc: 96.64% | Valid Acc: 79.39%\n",
      "\n",
      "Training ensemble model 3/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b6b5d25de54e35955cc9861ce22399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Acc: 93.34% | Valid Acc: 76.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239210e429b0469887cac7336c01b389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 | Train Acc: 96.02% | Valid Acc: 77.55%\n",
      "Testing ensemble methods...\n",
      "Hard voting ensemble accuracy: 77.60%\n",
      "Soft voting ensemble accuracy: 77.60%\n"
     ]
    }
   ],
   "source": [
    "# 7. Ensemble Methods\n",
    "print(\"\\n\" + \"=\"*30 + \" ENSEMBLE METHODS \" + \"=\"*30)\n",
    "\n",
    "# Instead of trying to load saved model states which have different architectures,\n",
    "# let's train a few simple models separately for the ensemble\n",
    "\n",
    "# Create test data loader for ensemble evaluation\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# Train 3 different models with slight variations for the ensemble\n",
    "ensemble_models = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 7. Ensemble Methods\n",
    "print(\"\\n\" + \"=\"*30 + \" ENSEMBLE METHODS \" + \"=\"*30)\n",
    "ensemble_results = {}\n",
    "\n",
    "for arch_name, model_creator in architectures.items():\n",
    "    print(f\"\\nTesting ensemble for architecture: {arch_name}\")\n",
    "    \n",
    "    # Train 3 different models with this architecture\n",
    "    ensemble_models = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(f\"\\nTraining ensemble model {i+1}/3...\")\n",
    "        \n",
    "        # Create a new model with this architecture\n",
    "        if arch_name == 'efficientnet':\n",
    "            model = create_efficientnet_model(num_classes)\n",
    "        else:\n",
    "            model = CustomCNN(num_classes)\n",
    "            \n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Rest of the training code...\n",
    "        # [existing ensemble creation code]\n",
    "        \n",
    "    # Test ensemble methods\n",
    "    print(f\"Testing ensemble methods for {arch_name}...\")\n",
    "    # Hard voting\n",
    "    hard_accuracy, hard_preds, hard_labels = ensemble_prediction(\n",
    "        ensemble_models,\n",
    "        test_loader,\n",
    "        device,\n",
    "        method='hard'\n",
    "    )\n",
    "    print(f\"Hard voting ensemble accuracy ({arch_name}): {hard_accuracy:.2f}%\")\n",
    "    \n",
    "    # Soft voting\n",
    "    soft_accuracy, soft_preds, soft_labels = ensemble_prediction(\n",
    "        ensemble_models,\n",
    "        test_loader,\n",
    "        device,\n",
    "        method='soft'\n",
    "    )\n",
    "    print(f\"Soft voting ensemble accuracy ({arch_name}): {soft_accuracy:.2f}%\")\n",
    "    \n",
    "    ensemble_results[arch_name] = {\n",
    "        'hard_voting': {\n",
    "            'accuracy': hard_accuracy,\n",
    "            'predictions': hard_preds,\n",
    "            'labels': hard_labels\n",
    "        },\n",
    "        'soft_voting': {\n",
    "            'accuracy': soft_accuracy,\n",
    "            'predictions': soft_preds,\n",
    "            'labels': soft_labels\n",
    "        }\n",
    "    }\n",
    "    all_results[f'ensemble_{arch_name}'] = ensemble_results[arch_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== RESULTS SUMMARY ==============================\n",
      "\n",
      "Architecture Comparison:\n",
      "efficientnet: 78.67%\n",
      "custom_cnn: 28.48%\n",
      "\n",
      "Training Hyperparameters Comparison:\n",
      "Training_Hyperparams_1 - {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001}: 77.96%\n",
      "Training_Hyperparams_2 - {'optimizer': 'sgd', 'learning_rate': 0.01, 'scheduler': 'plateau', 'weight_decay': 0.0001}: 81.65%\n",
      "Training_Hyperparams_3 - {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'cosine', 'weight_decay': 0.0001}: 81.79%\n",
      "\n",
      "Regularization Hyperparameters Comparison:\n",
      "Regularization_Hyperparams_1 - Weight Decay: 0.0001: 78.15%\n",
      "Regularization_Hyperparams_2 - Weight Decay: 0.001: 76.45%\n",
      "Regularization_Hyperparams_3 - Weight Decay: 0.0: 76.17%\n",
      "\n",
      "Data Augmentation Comparison:\n",
      "Augmentation_baseline: 79.96%\n",
      "Augmentation_horizontal_flip: 79.60%\n",
      "Augmentation_rotation: 81.10%\n",
      "Augmentation_color_jitter: 80.74%\n",
      "Augmentation_cutout: 81.58%\n",
      "\n",
      "Few-shot Learning (5-way, 5-shot): 73.53% ± 8.09%\n",
      "\n",
      "Reduced Training Set Size Comparison:\n",
      "Size 4000: 81.66%\n",
      "Size 2000: 81.54%\n",
      "\n",
      "Ensemble Hard Voting: 77.60%\n",
      "Ensemble Soft Voting: 77.60%\n"
     ]
    }
   ],
   "source": [
    "# 8. Summarize and Visualize Results\n",
    "print(\"\\n\" + \"=\"*30 + \" RESULTS SUMMARY \" + \"=\"*30)\n",
    "\n",
    "# 1. Architecture Comparison\n",
    "print(\"\\nArchitecture Comparison:\")\n",
    "for arch_name, results in architecture_results.items():\n",
    "    print(f\"{arch_name}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 2. Training Hyperparameters\n",
    "print(\"\\nTraining Hyperparameters Comparison:\")\n",
    "for name, results in training_results.items():\n",
    "    # Extract architecture name from the experiment name\n",
    "    parts = name.split('_')\n",
    "    if len(parts) > 2:  # If it contains architecture info\n",
    "        arch = parts[2]  # Architecture name should be the third part\n",
    "        print(f\"{name} ({arch}) - {results['hyperparams']}: {results['test_accuracy']:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{name} - {results['hyperparams']}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 3. Regularization Hyperparameters\n",
    "print(\"\\nRegularization Hyperparameters Comparison:\")\n",
    "for name, results in regularization_results.items():\n",
    "    # Extract architecture name if present\n",
    "    parts = name.split('_')\n",
    "    if len(parts) > 2:  # If it contains architecture info\n",
    "        arch = parts[2]  # Architecture name should be the third part\n",
    "        print(f\"{name} ({arch}) - Weight Decay: {results['hyperparams']['weight_decay']}: {results['test_accuracy']:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{name} - Weight Decay: {results['hyperparams']['weight_decay']}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 4. Data Augmentation\n",
    "print(\"\\nData Augmentation Comparison:\")\n",
    "for name, results in augmentation_results.items():\n",
    "    print(f\"{name}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 5. Few-shot Learning\n",
    "print(\"\\nFew-shot Learning Comparison:\")\n",
    "for arch_name, result in few_shot_results.items():\n",
    "    print(f\"{arch_name}: {result['accuracy']:.2f}% ± {result['std']:.2f}%\")\n",
    "\n",
    "# 6. Reduced Training Set Size\n",
    "print(\"\\nReduced Training Set Size Comparison:\")\n",
    "for name, results in reduction_results.items():\n",
    "    parts = name.split('_')\n",
    "    if len(parts) > 3:  # If it contains architecture info\n",
    "        arch = parts[3]  # Architecture name\n",
    "        size = parts[4]  # Size should be the last part\n",
    "        print(f\"Size {size} ({arch}): {results['test_accuracy']:.2f}%\")\n",
    "    else:\n",
    "        size = name.split('_')[-1]\n",
    "        print(f\"Size {size}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 7. Ensemble Methods\n",
    "print(\"\\nEnsemble Methods Comparison:\")\n",
    "if isinstance(ensemble_results, dict):\n",
    "    # Check if we have separate results for each architecture\n",
    "    if 'efficientnet' in ensemble_results or 'custom_cnn' in ensemble_results:\n",
    "        for arch, results in ensemble_results.items():\n",
    "            print(f\"{arch} - Hard Voting: {results['hard_voting']['accuracy']:.2f}%\")\n",
    "            print(f\"{arch} - Soft Voting: {results['soft_voting']['accuracy']:.2f}%\")\n",
    "    else:\n",
    "        # Original format\n",
    "        print(f\"Hard Voting: {ensemble_results['hard_voting']['accuracy']:.2f}%\")\n",
    "        print(f\"Soft Voting: {ensemble_results['soft_voting']['accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdIAAAPeCAYAAAAI5OjmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAumVJREFUeJzs3QeYVNX5OOADItixUlRUYkhsWKLGAolGTbD+1Bh7IpaIsXcjsQUbamJvxIbR2LvRBGPU2EWssVdULIBGAUVFhPk/3/k/s89suyy4C7O77/s8Azt37sw9c+/d2e98851zO5RKpVICAAAAAAAa1LHhxQAAAAAAQJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIB6jjj3/8Y+rQoUP65JNPZrjucsstl3bffffZ0i5alziH4lwCAIA5RUw657zzzjt5/1955ZVzuilAM5FIB1qdiy66KAck66yzTqo2L7/8cg5UI2hqSY899ljezoQJE1K1euutt9I+++yTvve976V55pknLbTQQqlfv37p3HPPTV999dWcbh4AQKsWybmIicu3iLeWXHLJNGDAgHTeeeelzz//vKpjzaOOOiq3e8cdd0zt2Ycffpj39XPPPTfLr/GPf/yjapPl8b5+/etfp169eqUuXbqkRRddNG2yySZp+PDhadq0aXO6eQAzpdPMrQ4w511zzTW5EvzJJ59Mb775Zvr+978/x9ry2muvpY4dO9ZKpA8ZMiRtuOGGuY0tJTo3sZ2ohl944YVTtbn77rvT9ttvn4Pl3XbbLa2yyirpm2++SY888kg68sgj00svvZQuueSS1JbFlwWdOvkzCwC0rBNPPDH17t07TZ06NY0dOzb95z//SYccckg666yz0p133plWXXXVqos1S6VSuu6663K8/Pe//z0n/RdccMHUXhPpsa9jX6y++uqznEi/8MILG0ymz8mY9LLLLku/+93vUvfu3dNvfvOb1KdPn3ys77vvvrTXXnuljz76KP3hD39IbdWyyy6b9//cc889p5sCNBM9fKBVGT16dA7sb7311lztHEn1E044YYbP+/bbb9P06dNT586dm7U9kShuSyZPnpzmn3/+73yMdtpppxw43n///alnz541j+2///75y49ItLdFcY7FFwZRERY3AICWttlmm6W11lqr5v7gwYNzDLblllum//u//0uvvPJKmnfeeVM1iWT/+++/n9sZFfQR2w8cOHBON6tNmlMx6RNPPJGT6Outt15O9Fd+URJf9Dz11FPpxRdfTG1RZd9TnwDaFlO7AK1KJM4XWWSRtMUWW6Rf/epX+X5jc9H9+c9/Tuecc05afvnlc8I7qsXDq6++mnbYYYe0xBJL5E7FD3/4w3TMMcfUe50YylquwunatWvaY4890pdfftnoHOkxvDaqsMPPfvazmmG20VEo++c//5l+8pOf5GR1BJPxPqI6u66iNkalSVR1h6g+Km8n3nfRPHx150cszwUf+2WXXXbJ+7V///41j//tb39La665Zt5+DMGM5PiYMWNmeIzOOOOM9MUXX6TLL7+8VhK9LEYQHHzwwbUCzZNOOqnmOMU+jcqUKVOm1NvX0SGM/RmdxWhX3759a/ZvdMDifgSr0e5nn3221vPjOC2wwALp7bffzh22OAYx/DmquKIqqlKcO+uvv35abLHF8nbi9W6++eYG9+kBBxyQz8OVV145t3/EiBEN7u+ovolOQ7yPWK9bt27p5z//eXrmmWdqveZNN91Us98XX3zxPBT2gw8+aPC9xPJtttkm/xznyhFHHGGILACQNtpoo3Tccceld999N8d0Zf/9739zHFGeeq9Hjx5pzz33TP/73/9q1imKNUNMyRGvH7FMxDQrrbRSuvjii2eqfRE7xfMiZo5pPhqK6ctT19SdMjFiv7oxdoiK7HhfEUP9+Mc/Tg8//HAeJRq3us+98cYbcxX4UkstlWPy6FdMnDgxx58Rr8V7i/gq4v+6MWlT4+TYbozKjFg73ud8882XtxexcmV71l577fxzbKu8r8uxfLyH6F8ss8wyeV/H9CiHHnporWkS43jGew+VU/0UzZEecXJ8ARNTL8b73HjjjXPiu6H9/+ijj6bDDjssx5oRP2+77bbp448/TjMS+zeeH8e2odEGEc9XXmsqCnoOP/zwmilgov8TMXndOL0cf0fMHOdQHINI1r/wwgv58b/85S+5vxHndxyDuudP+bg8/fTTOd6P58d5PmzYsFrrRXHM8ccfn49z9AXjvUc/7oEHHmhy37OhvlmMGoljvfTSS+f1or+09dZb12tnTGda7l9EnyUKkupOtdSUcwxoXirSgVYlArFf/vKX+dv9nXfeOQfto0aNqglAK0WQ//XXX6dBgwbVzMcXnYcIgGJ4XSyPpGbM5R1DSk855ZRaz49EdgRVQ4cOzcnOGJoYQfXpp5/eYNt++tOfpoMOOijPSRmJ4BVXXDEvL/9/9dVX50qbSOLGa0RSPtofyesIZstTwcyojfH+X3/99Twc9uyzz87J1hDBbVOC2roiOI9hlqeeempNoBrbic5X7IPf/va3+XXPP//8/B6jrUVDfKOd0YmJwLQp4vX/+te/5g5MBM8jR47M+zyqp2677bZa60Y1eyT9YzRCJJgjYN1qq61y4Bv7fL/99svrxfOj7XWn3okk86abbprWXXfdHGBG0jtGNEQyPxLqZTGPe1Rw7brrrjmIvv766/N+uuuuu/KXH5Wikio6YxHQx7FobEqfqMiJZHysF0F/dFhjqpt4nz/60Y/yOhFkR2Ad53O8h3HjxuW2RAem7n6P9xLnUlwrIPbDv//973TmmWfm4H3fffdt0r4HANqumEoj4qN//etfae+9987L7r333lxUEPFGJNHL0+3F/5FIjaRfUawZIn6NBF/ESjFlSMR+EYNFBW4k+2YkEtO33HJLjvtCxPTRnkgwRptmRbQpYqyIoSPRHEnJKDaIQpFIWNYVcVYkUI8++ugcX0acG7F3xI2fffZZTjzH/ojYLPoDkVAtm5k4OV4rYs/Yp7F+xIK///3vc/FHJLKjnxAxaLx+xP3R/lCOoyNZHH2GiO2iwCOmtoxtRTV/PBYiLo7pYeLYRn9jRuJYx3YiiR7z1Mf7juRzJGUffPDBetehOvDAA/N+jJg59mski2Nf33DDDY1uI9oc07fEPokvAWYk+iBxPkWSOqZ8iSlu7rnnnvyFThSOxHlYKb5giGmLyudbHM8ouIn3EwnoOB9j30e8H18URbxeKR7bfPPN8zGJ8y9i+djH0ceM9cOkSZNy/y8ej9+fKIqJQqGIv+M41J2Gp6G+Z/xO1LXddtvlYxD7NfoN48ePz8fuvffeq+lHxPkXX0TEl0zRrujTlPu90S+onCpmRucY0MxKAK3EU089FVne0r333pvvT58+vbT00kuXDj744FrrjR49Oq+30EILlcaPH1/rsZ/+9KelBRdcsPTuu+/WWh6vVXbCCSfk5++555611tl2221Liy22WK1lyy67bGngwIE192+66ab83AceeKDWep9//nlp4YUXLu299961lo8dO7bUtWvXWsub0sY//elPeTvxXht678OHD6+z93KGPL+3uu9z5513rrXeO++8U5prrrlKp5xySq3lL7zwQqlTp071lleaOHFifs2tt9661BTPPfdcXv+3v/1treVHHHFEXn7//ffX2tex7LHHHqtZds899+Rl8847b6399Ze//KXecYjjFMsOPPDAWvt0iy22KHXu3Ln08ccf1yz/8ssva7Xnm2++Ka2yyiqljTbaqNbyeL2OHTuWXnrppRnu7zjO+++/f6P7IrbRrVu3vJ2vvvqqZvldd92VX+v444+v915OPPHEWq+xxhprlNZcc81GtwEAtB0R70U8MGrUqEbXifgj4oPGYpxw3XXX5dd56KGHZhhrNvYaAwYMKH3ve99rUrtvvvnm/NpvvPFGvj9p0qTSPPPMUzr77LMbfH912xDxXWWcN2XKlByjr7322qWpU6fWrHfllVfm9TbYYIN6z414K2KvsoiHO3ToUNpss81qbWu99dbLMeisxMmx3djWVVddVbMs2tqjR4/SdtttV7Msjl9j8XtD+3ro0KG5rZWxb8SYjaV36sak22yzTY5933rrrZplH374Ye5/RD+k7v7fZJNNavVDDj300LwPJkyYUGrM888/n59bt5/WmNtvvz2vf/LJJ9da/qtf/Sq/1zfffLPW++nSpUut86Ic+8e+jfOpbPDgwfXOofJxOfPMM2sdl9VXXz3H4uXz4ttvv83LK3322Wel7t271+onFvU96/bN4vlxP36/GhOvEcfnF7/4RWnatGk1yy+44IL83CuuuGKmzzGg+ZjaBWhV1ehxoZoYthaiYmbHHXfM1cINTWcR3/aXK2dCVIs89NBDucqgbmVE5fDHygriSlG5EVXEUZ0ws6LKIIbiRUXDJ598UnOba665ctVHeYjgzLaxOdR9nzFFSlRPREVDZVujQigq1+sOZ6xU3jdNvVhUzJcYYrhopXKFUt251KOSO4ZulpUrZmJ4ceX+Ki+Piqu6ooKm7tDQqDqPiu6yynlEo8ojhvrG8a87DUvYYIMNcrtmJKqToto+KoYaEvNERkVKVNBUzqUYFfArrLBCg/PKN3SONvSeAYD2KabtiErahmKcqJ6NGC9G6oWG4pyGVL5GxEjxGhEPRQwS95sS08e0HjH9RihPd9jQ9C5NETFUxOhRNVx5Uc0YWRiV1A3ZbbfdalX1RuwYOdpyNXLl8piyJUYvzkqcHPs/RlGWRcVzTDvT1Hitcl/H1CexrahWj7bWncawKaLPFCMUolo/RpCWxfQiMeozRkvW7etEhXVlPyTizXidmDaoOfsE0S+K0b11+wTxXmN6zEoxFU3lKNBy7B/9v8ptNtYniPMkKvkrj0vcj1g8pnwJ0Z7y9bXimH/66af5PIhzt6Hflbp9z8aOZ7xmTOkTfYyGRJ8k+iYxxVDlyNo4v2MUQd0+wXc9x4CZI5EOtAoRrEXCPJLocTHLGIIZtwiOYvqLGDpYVwzDrFQOJmIeuaaom8guB+KNBT1F3njjjZqEbwRYlbcIZiNom5U2Noe6+ynaGgFrdAbqtjWmISm3tSER3IXKDluRCMAjQCx3pMqiMxKJ57oBet1jEvMVhphLsaHldY9VbKuy0xB+8IMf5P8r5yWMKVyiUxkJ7RiWGe89hlM21Dmsu/8aE0NL44JK0dYIbmPIZmWAW36vMR9kXZFIr7svom11g/U4R2fl/AQA2qa4bk1lYjGSgXGtmihOiaRexBLlWKYpSfAQU0vElBMxZ3TEa/EaMYVMU14jCksiaRqJ93I8H7d+/frlhHhMKTOzyjFS3XgykqWNTbk3MzFlJFHL72tm4+SYVqZuMczMxGsx3UfMIx7xaPmaOLHvZuZ4VYqinZh2paF4M6aZifdad673WekTzUqfIOYBr5t4L0+R2dx9gthWnL8z6hPE9JOrrrpqjrtjap3Y/5HIntU+QUz5ElN8xhcD8TsYU99EHyGmNarcF6HuMYoEefRj6u6L73qOATPHHOlAqxDz2n300Uc5mR63uqKC5Re/+EWjFRyzIqoQGlL3gjdNUZ4fL+YtbGjux8rqme+isar1ogtQ1t1P0dZ4nQjwGtoHEcQXBc0RmEbCuDna3dRj0pzHKuZcjDkaI7CNORajQicqlmLew2uvvbbe+k09z6JyKSp4Yt73+PLkT3/6Uw6ko7JpVuYvbOw9AwCEmEc7En6VCeaIRx577LE893TM8RxxXcR+McdyQ/M51xXX7Ylq4PiS/6yzzsqJy0jwRXI85rGe0WvEvN4xR3pc1yVuDcX0MTf0rMa1TTWrMeXMxsnfJUaN9xkXpo8vP2LO69jnkfyNOcMjud6U49UcZuU9xDkX/ZvyBUBnV5uas08QF5SN/RzV+/H7EtfKiteP+djj92BW+wRRaR7XeLr99tvzPPAx3368ZvR311hjjZluZ3O+Z2DGJNKBViGC6gheylekrxSJyEhOxgUniwKYciXyzCZ5Z0ZjAX9cADLEe4gKnu/axsa2U64QqXtF96Khlw21NQKvqKooV2bMjLjQT1y06vHHH681DUtDll122dwJiOqecsVJiFEG8R7i8eYU24oq8Mr3Va58KlcsxcWvouokAtuoGimLRPp3FUn5mLolblGxFBcZjQtWRSK9/F7jYkIxcqFSLGvufQEAtG3lC0/GxRFDVKjGKM5IVFdePLM8crIpsWZcWDQS4XGhx8qq4KKp/+rG9DHyMi5cWVdc8DKKFsqJ9KbGteUYKSrby1NAhpiGI6qLo6K4uXzXOLkhje3rSEJHnBpV0TEVTeWUkU19jbqionq++ebLsWVdr776ah69Wbeqe1bENiKejeRwVLjP6DXjGMaUJlHBXlmVHm0qP96cYqrFmCqnsiq9bp8gLtoZfbPoa1bu34bO3Vk5j2LamrjF7198qRVfLEXyvrJPUDmSNqZ7iZHZRX1JoOWZ2gWoel999VUOYCJB+6tf/areLea4jqArAvoZBY5RZXzFFVfkYZIt8Y19ORirG/BHByaqtU899dQ0derUBodZzkwbG9tObGPxxRfP86xXisrqpoorvkdlQ3Ri6u6XuB9zUBY56qijcvt++9vf5oR4XVHBce655+afN9988/z/OeecU2udqHAKMV9mc7vgggtqvZ+4HxXnUV0V4r1HsFxZ7RSdsKgamVXxWnWHgMaXKlG9H53REPMtxrL4Qqi8LETFUwwVbol9AQC0TZHAPOmkk3LCN+YKr6xcrRvf1Y3DimLNhl4jYpymFBxEQjVi1KiKbyim32OPPXIyPK4pU1mIUhnXRkwVBRuVIoaKaTcuvfTSmrnMy0n75p7e4rvGyQ2ZmX0dP5fj6Ka8Rl3xmjGK94477qg1hUnE7PElRv/+/WumZfmuIuEc7f3Nb36TpxiqK+Yijy8Jyn2COLaVcXqIUQ4Rl8/K6M0icZ7EFzeVSeq4H32xNddcs9H9H+dmFAvNqphWJ65NUCnO8/jyoBz/R6I8Rnmcd955tbZ9+eWX5981fQKYs1SkA1UvEuSRKI/pNhoSc1lH0BPBclx8tEgEJBEgRiVwXDgnOhcRRMZcd88999x3bmtUE0TQFVN2RKATFc1RjREJ0phjOwLJ2PZOO+2U2xzJ8th2zAtZDhyb0sZygHfMMcfk14pEcAwRLCewTzvttPx/dCyi8zEz801GMHfyySenwYMH5+3GcMYI7qICIir/o01HHHFE4fMjEI9jEVXmUUETlUcRoMZQ4hjSG8Mkw2qrrZYGDhyYO0QR+Mecj08++WQOqmO7lVVFzSEqzUeMGJG3GfPrR5I69mvM61mebzyC00jkxxDnuOhSVI7HSIgYovrf//53lrYb52/MXxidxHjPMew3qm5GjRpVM6w5jmGcN9GJjP0QF6aNTk10lqIy5tBDD23WfQEAtA0Rz0TlbiQHI3aIJHpULUdla8TR5YuYR4K0PCdzFHYstdRSebq5iPHqaizWjCRsJPni57g4YyRII4EdsW5Mw1gk4sNIDDYW00cyNaYDiZg+4rSVV145x/kRk8b0JjFPeEzxWJksD9GeuPbMgQcemOPuSNRHDHvllVfmuLSp1dqzI05u7DVjrvkopojXing+3n9M5RKPxevFdC5x/GLkZENfDpSPV1ysMwp4oj8Sx60h0f44P6K/EaMkY59HEjkSuXFuNJe4KGrE0LGNeC/RD4q55SMujottxrkZbQlxPkXcH+db7NeIl+PcjIR/TIVS/lKluUQxS8Tdsa0YWXDDDTfkflb0ScoXoY0irijm2nbbbXP/II5xHKOVVlqpwS8GmiL6ZFG8E+dovE7s+zhv4ve2fLyiTxLnV3xZE/2R+H2J6vQojFp77bVrXVgUmANKAFVuq622Ks0zzzylyZMnN7rO7rvvXpp77rlLn3zySWn06NHx1X3pT3/6U4Prvvjii6Vtt922tPDCC+fX/eEPf1g67rjjah4/4YQT8vM//vjjWs8bPnx4Xh6vX7bsssuWBg4cWGu9Sy+9tPS9732vNNdcc+X1H3jggZrH4ucBAwaUunbtmre9/PLL57Y/9dRTM9XGcNJJJ5WWWmqpUseOHWu168svvyzttddeeRsLLrhgaYcddiiNHz8+rxPvbUbvs+yWW24p9e/fvzT//PPn2worrFDaf//9S6+99lqpKV5//fXS3nvvXVpuueVKnTt3zm3p169f6fzzzy99/fXXNetNnTq1NGTIkFLv3r3zMezVq1dp8ODBtdYp7+stttii3nbiPUS7KjV0DsRxivfx1ltvlX7xi1+U5ptvvlL37t3zfpg2bVqt519++eWlPn36lLp06ZLfdxz78v6a0bYrHyvv7ylTppSOPPLI0mqrrZb3Q7Qjfr7ooovqPe+GG24orbHGGnnbiy66aGnXXXctvf/++7XWKb+XuhpqIwDQNpVj0/It4q0ePXqUfv7zn5fOPffc0qRJk+o9J2KKcowZseL2229f+vDDD+vFiUWx5p133lladdVVc4wacd7pp59euuKKK+rFyXX17du3tMwyyxS+pw033LDUrVu3HB+GiNs22WSTHBdF3PaHP/yhdO+999aLscN5552X48VY98c//nHp0UcfLa255pqlTTfdtGadeE4896abbmpwX44aNarW8sbi5abEyRtssEFp5ZVXrvceI46Ldla64447SiuttFKpU6dOeXvRnvDyyy/n97/AAguUFl988RxbP//887XWCd9++23pwAMPLC2xxBKlDh061IoHGzq2zzzzTO6TxOtGTPyzn/2s9NhjjzVpn5T3Yd3935inn366tMsuu5SWXHLJHOsvssgipY033rj017/+tVYM/vnnn5cOPfTQmvUiFo9Yfvr06bMU+zd2vMvHJfpf6623Xj6P43hccMEFtZ4b2z311FNrzqmIz++66656x6+o71l+rHysoq8abY/zJc6b+B1cZ511SjfeeGO950Z7Yr3YF3Hu77vvvqXPPvus1jozc44BzaND/DMnEvgAMDtFFXzMdTirFSQAALQecW2cqO6N6Viiah7ChhtumD755JMWvW4W0HaZIx0AAABotWLe6bo1gldddVWeEiYSpwDQHMyRDgAAALRaTzzxRL6ezPbbb58vPPrMM8/kizPGdXpiGQA0B4l0AAAAoNWKC7P36tUrnXfeeTUXJo0L3p922mn5YqQA0OqndnnooYfy1ZnjislxJe3bb7+91uMxNOv4449PPXv2TPPOO2/aZJNN0htvvFFrnfgjueuuu+YrWMeVrvfaay/z3wJQz5VXXunvA0ABsTnQmhPpd955Zxo7dmz65ptv8v9XXHFF6tat25xuGlXmP//5j/nRgdaZSJ88eXJabbXV0oUXXtjg42eccUb+RnnYsGFp5MiRaf75508DBgzI85+VRaD+0ksvpXvvvTfddddduQMwaNCg2fguAACg9RObAwBA4zqU6l6RYw6JqpfbbrstbbPNNvl+NCuqYQ4//PB0xBFH5GUTJ05M3bt3z1WFO+20U3rllVfSSiutlEaNGpXWWmutvM6IESPS5ptvnt5///38fAAAYOaIzQEAoJXMkT569Og8HCuGjJZ17do1rbPOOunxxx/PwXr8H0NGy4F6iPU7duyYq2S23XbbBl97ypQp+VY2ffr0PAw1LkoSnQYAAGhJkZj+/PPPc3I5Ytdq11KxubgcAIDWEpdXbSI9AvUQVS6V4n75sfi/7pxnnTp1yhcWKa/TkKFDh6YhQ4a0SLsBAKCpxowZk5ZeeulU7VoqNheXAwDQWuLyqk2kt6TBgwenww47rOZ+DEtdZpll8g6LCyMBAEBLmjRpUurVq1dacMEFU3smLgcAoLXE5VWbSO/Ro0f+f9y4calnz541y+P+6quvXrPO+PHjaz3v22+/zcNBy89vSJcuXfKtrgjWBewAAMwurWX6kpaKzcXlAAC0lri8aidk7N27dw6477vvvlrfEMT8iuutt16+H/9PmDAhPf300zXr3H///XluxZivEQAA+O7E5gAAtHdztCL9iy++SG+++Watixg999xzeR7FGNJ5yCGHpJNPPjn16dMnB+/HHXdcnvh9m222yeuvuOKKadNNN0177713GjZsWJo6dWo64IAD8sWOYj0AAKBpxOYAAFClifSnnnoq/exnP6u5X54fceDAgenKK69MRx11VJo8eXIaNGhQrm7p379/GjFiRJpnnnlqnnPNNdfkAH3jjTfOV1bdbrvt0nnnnTdH3g8AALRWYnMAAGhch1KpVErtXAxL7dq1a764kbkYAQBoaeLPhtkvAABUa/xZtXOkAwAAAABANZBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAU6FT0IAAAAANCWLHf03XO6CdTxzmlbpGqnIh0AAAAAAFprRfq0adPSH//4x/S3v/0tjR07Ni255JJp9913T8cee2zq0KFDXqdUKqUTTjghXXrppWnChAmpX79+6eKLL059+vSZ080HAIA2Q2wOtEWqUqtTa6hMBdqfqq5IP/3003PgfcEFF6RXXnkl3z/jjDPS+eefX7NO3D/vvPPSsGHD0siRI9P888+fBgwYkL7++us52nYAAGhLxOYAALRnVV2R/thjj6Wtt946bbHF//8mcrnllkvXXXddevLJJ2sqXs4555xcBRPrhauuuip179493X777WmnnXaao+0HAIC2QmwOQFtiNEJ1MhqBalbVFenrr79+uu+++9Lrr7+e7z///PPpkUceSZtttlm+P3r06DysdJNNNql5TteuXdM666yTHn/88TnWbgAAaGvE5gAAtGdVXZF+9NFHp0mTJqUVVlghzTXXXHlexlNOOSXtuuuu+fEI1ENUuVSK++XHGjJlypR8K4ttAAAAszc2F5cDANBaVHUi/cYbb0zXXHNNuvbaa9PKK6+cnnvuuXTIIYfkCxsNHDhwll936NChaciQIc3aVgAAaMtaIjavtrjcMP/qY4g/AFAtqjqRfuSRR+bKl/J8in379k3vvvtuDrgjWO/Ro0dePm7cuNSzZ8+a58X91VdfvdHXHTx4cDrssMNqVb706tWrRd8LAAC0Zi0Rm4vLqRa+RKlOvkgBoJpU9RzpX375ZerYsXYTYxjp9OnT88+9e/fOAXvM1VgZfI8cOTKtt956jb5uly5d0kILLVTrBgAAzN7YXFwOAEBrUdUV6VtttVWed3GZZZbJw0efffbZdNZZZ6U999wzP96hQ4c8nPTkk09Offr0ycH7cccdl4eXbrPNNnO6+QAA0GaIzQEAaM+qOpF+/vnn5+B7v/32S+PHj89B+D777JOOP/74mnWOOuqoNHny5DRo0KA0YcKE1L9//zRixIg0zzzzzNG2AwBAWyI2BwCgPavqRPqCCy6YzjnnnHxrTFS+nHjiifnWGpmLD5hV5owEYHZqD7E5AAC0yjnSAQAAAABgTpNIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKdEqz4L333kvvvvtu+vLLL9MSSyyRVl555dSlS5dZeSkAAOA7EJsDAEAVJdLfeeeddPHFF6frr78+vf/++6lUKtU81rlz5/STn/wkDRo0KG233XapY0eF7gAA0FLE5gAAMHs1Kao+6KCD0mqrrZZGjx6dTj755PTyyy+niRMnpm+++SaNHTs2/eMf/0j9+/dPxx9/fFp11VXTqFGjWr7lAADQDonNAQCgSivS559//vT222+nxRZbrN5j3bp1SxtttFG+nXDCCWnEiBFpzJgxae21126J9gIAQLsmNgcAgCpNpA8dOrTJL7jpppt+l/YAAAAFxOYAANBKLjZa9sknn6SRI0emadOm5SqXnj17Nl/LAACAJhObAwBAFSbSb7nllrTXXnulH/zgB2nq1KnptddeSxdeeGHaY489mreFAABAIbE5AABUwcVGwxdffFHr/pAhQ9KTTz6Zb88++2y66aab0jHHHNMSbQQAACqIzQEAoEoT6WuuuWa64447au536tQpjR8/vub+uHHjUufOnZu/hQAAQC1icwAAqNKpXe655560//77pyuvvDIPEz333HPTjjvumOdg/Pbbb1PHjh3zYwAAQMsSmwMAQJUm0pdbbrl09913p+uuuy5tsMEG6aCDDkpvvvlmvkXAvsIKK6R55pmnZVsLAACIzQEAoFqndinbeeed06hRo9Lzzz+fNtxwwzR9+vS0+uqrC9QBAGA2E5sDAECVVaSHf/zjH+mVV15Jq622WrrsssvSgw8+mHbddde02WabpRNPPDHNO++8LddSAACghtgcAACqsCL98MMPT3vssUeueNlnn33SSSedlIeRPvPMM7niZY011kj//Oc/m72BH3zwQfr1r3+dFltssdwZ6Nu3b3rqqadqHi+VSun4449PPXv2zI9vsskm6Y033mj2dgAAQLUQmwMAQJUm0uNiRVH1cv311+eA/eqrr87LO3funAP3W2+9NZ166qnN2rjPPvss9evXL80999y5I/Dyyy+nM888My2yyCI165xxxhnpvPPOS8OGDUsjR45M888/fxowYED6+uuvm7UtAABQLcTmAABQpVO7RBA8evTotOaaa6YxY8bUm3dxpZVWSg8//HCzNu70009PvXr1SsOHD69Z1rt371oVL+ecc0469thj09Zbb52XXXXVVal79+7p9ttvTzvttFOztgcAAKqB2BwAAKq0In3o0KFpt912S0suuWQeNhqVLi3tzjvvTGuttVbafvvtU7du3fIQ1UsvvbTm8eg8jB07Ng8ZLevatWtaZ5110uOPP97i7QMAgDlBbA4AAFVakR4XLtp0003T22+/nfr06ZMWXnjhlm1ZSnlbF198cTrssMPSH/7whzxs9aCDDspDVgcOHJgD9RBVLpXifvmxhkyZMiXfyiZNmtSC7wIAAJpXW4nNxeUAALS5RHqIiwrFbXaZPn16rnopz+8YVS8vvvhinnMxgvXvUsEzZMiQZmwpAADMXm0hNheXAwDQpqZ2+d3vfpfef//9Jr3gDTfckK655prUHHr27Jnnd6y04oorpvfeey//3KNHj/z/uHHjaq0T98uPNWTw4MFp4sSJNbeYVxIAAFqDthSbi8sBAGhTFelLLLFEWnnllVO/fv3SVlttlStRYj7GuKjRZ599ll5++eX0yCOPpOuvvz4vv+SSS5qlcbG91157rday119/PS277LI1FzeKoPy+++5Lq6++es1w0JEjR6Z999230dft0qVLvgEAQGvTlmJzcTkAAG0qkR4XLzrggAPSZZddli666KIcnFdacMEF80WFIkiPuRqby6GHHprWX3/9PHx0hx12SE8++WTeRrkz0KFDh3TIIYekk08+Oc8NGcH7cccdlzsM22yzTbO1AwAAqoXYHAAAqniO9LhI0DHHHJNvUekSQzi/+uqrtPjii6fll18+B87Nbe2110633XZbHvJ54okn5mD8nHPOyRdXKjvqqKPS5MmT06BBg9KECRNS//7904gRI3JFDgAAtEVicwAAqOKLjZYtssgi+TY7bLnllvnWmOgkRCAfNwAAaG/E5gAAUCUXGwUAAAAAgPZKIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAaM5E+gknnJDefffdmX0aAADQzMTmAABQpYn0O+64Iy2//PJp4403Ttdee22aMmVKy7QMAAAoJDYHAIAqTaQ/99xzadSoUWnllVdOBx98cOrRo0fad9998zIAAGD2EZsDAEAVz5G+xhprpPPOOy99+OGH6fLLL0/vv/9+6tevX1p11VXTueeemyZOnNj8LQUAAOoRmwMAQJVfbLRUKqWpU6emb775Jv+8yCKLpAsuuCD16tUr3XDDDc3XSgAAoJDYHAAAqiyR/vTTT6cDDjgg9ezZMx166KG5CuaVV15JDz74YHrjjTfSKaeckg466KDmby0AAFCL2BwAAKowkd63b9+07rrrptGjR+eho2PGjEmnnXZa+v73v1+zzs4775w+/vjj5m4rAABQQWwOAACzR6eZfcIOO+yQ9txzz7TUUks1us7iiy+epk+f/l3bBgAAFBCbAwBAlSbSjzvuuJZpCQAAMFPE5gAAUKVTu2y33Xbp9NNPr7f8jDPOSNtvv31ztQsAAJgBsTkAAFRpIv2hhx5Km2++eb3lm222WX4MAACYPcTmAABQpYn0L774InXu3Lne8rnnnjtNmjSpudoFAADMgNgcAACqNJHet2/fdMMNN9Rbfv3116eVVlqpudoFAADMgNgcAACq+GKjv/zlL9Nbb72VNtpoo7zsvvvuS9ddd1266aabWqKNAABAA8TmAABQpYn0rbbaKt1+++3p1FNPTTfffHOad95506qrrpr+/e9/pw022KBlWgkAANQjNgcAgCpNpIctttgi3wAAgDlLbA4AAFU4RzoAAAAAALQnM12RPm3atHT22WenG2+8Mb333nvpm2++qfX4p59+2pztAwAAGiE2BwCAKq1IHzJkSDrrrLPSjjvumCZOnJgOO+ywfIGjjh07pj/+8Y8t00oAAKAesTkAAFRpIv2aa65Jl156aTr88MNTp06d0s4775wuu+yydPzxx6cnnniiZVoJAADUIzYHAIAqTaSPHTs29e3bN/+8wAIL5MqXsOWWW6a77767+VsIAAA0SGwOAABVmkhfeuml00cffZR/Xn755dO//vWv/POoUaNSly5dmr+FAABAg8TmAABQpYn0bbfdNt1333355wMPPDAdd9xxqU+fPmm33XZLe+65Z0u0EQAAaIDYHAAAZo9OM/uE0047rebnuKjRsssumx577LEcsG+11VbN3T4AAKARYnMAAKjCRPrUqVPTPvvskytdevfunZetu+66+QYAAMw+YnMAAKjSqV3mnnvudMstt7RcawAAgCYRmwMAQBXPkb7NNtuk22+/vWVaAwAANJnYHAAAqnSO9Jhv8cQTT0yPPvpoWnPNNdP8889f6/GDDjqoOdsHAAA0QmwOAABVmki//PLL08ILL5yefvrpfKvUoUMHwToAAMwmYnMAAKjSRPro0aNbpiUAAMBMEZsDAECVzpEOAAAAAADtyUxXpO+5556Fj19xxRXfpT0AAEATic0BAKBKE+mfffZZrftTp05NL774YpowYULaaKONmrNtAABAAbE5AABUaSL9tttuq7ds+vTpad99903LL798c7ULAACYAbE5AAC0ojnSO3bsmA477LB09tlnN8fLAQAAs0hsDgAAVXyx0bfeeit9++23zfVyAADALBKbAwDAHJ7aJapbKpVKpfTRRx+lu+++Ow0cOLA52wYAABQQmwMAQJUm0p999tl6Q0eXWGKJdOaZZ6Y999yzOdsGAAAUEJsDAECVJtIfeOCBlmkJAAAwU8TmAABQpXOkjx49Or3xxhv1lseyd955p7naBQAAzIDYHAAAqjSRvvvuu6fHHnus3vKRI0fmxwAAgNlDbA4AAFWaSI95GPv161dv+brrrpuee+655moXAAAwA2JzAACo0kR6hw4d0ueff15v+cSJE9O0adOaq10AAMAMiM0BAKBKE+k//elP09ChQ2sF5vFzLOvfv39ztw8AAGiE2BwAAGaPTjP7hNNPPz0H7D/84Q/TT37yk7zs4YcfTpMmTUr3339/S7QRAABogNgcAACqtCJ9pZVWSv/973/TDjvskMaPH5+Hku62227p1VdfTausskrLtBIAAKhHbA4AAFVakR6WXHLJdOqppzZ/awAAgJkiNgcAgCqsSB8+fHi66aab6i2PZX/961+bq10AAMAMiM0BAKBKE+lx4aLFF1+83vJu3bqphAEAgNlIbA4AAFWaSH/vvfdS79696y1fdtll82MAAMDsITYHAIAqTaRHdUtc0Kiu559/Pi222GLN1S4AAGAGxOYAAFClifSdd945HXTQQemBBx5I06ZNy7f7778/HXzwwWmnnXZqmVYCAAD1iM0BAGD26DSzTzjppJPSO++8kzbeeOPUqdP/f/r06dPTbrvtlk455ZSWaCMAANAAsTkAAFRpIr1z587phhtuSCeffHJ67rnn0rzzzpv69u2b52EEAABmH7E5AABUaSK9rE+fPvkWJk2alC6++OJ0+eWXp6eeeqo52wcAAMyA2BwAAKo0kR5iLsYrrrgi3Xrrralr165p2223bb6WAQAATSY2BwCAKkqkf/DBB+nKK69Mw4cPTxMmTEifffZZuvbaa9MOO+yQOnTo0DKtBAAA6hGbAwDA7NGxqSvecsstafPNN08//OEP8/yLZ555Zvrwww9Tx44d8zyMAnUAAJg9xOYAAFClFek77rhj+v3vf58vZrTgggu2bKsAAIBGic0BAKBKK9L32muvdOGFF6ZNN900DRs2LA8bBQAAZj+xOQAAVGki/S9/+Uv66KOP0qBBg9J1112XevbsmbbeeutUKpXS9OnTW7aVAABADbE5AABUaSI9zDvvvGngwIHpwQcfTC+88EJaeeWVU/fu3VO/fv3SLrvskm699daWaykAAFBDbA4AAFWaSK/Up0+fdOqpp6YxY8akv/3tb+nLL79MO++8c/O2DgAAmCGxOQAAVMnFRhvTsWPHtNVWW+Xb+PHjm6dVAADATBObAwBAlVWkN6Rbt27N+XIAAMAsEpsDAECVJtIBAAAAAKCtkUgHAAAAAIACEukAAAAAANCcifTvfe976X//+1+95RMmTMiPAQAAs4fYHAAAqjSR/s4776Rp06bVWz5lypT0wQcfNFe7AACAGRCbAwDA7NGpqSveeeedNT/fc889qWvXrjX3I3i/77770nLLLZda0mmnnZYGDx6cDj744HTOOefkZV9//XU6/PDD0/XXX587DAMGDEgXXXRR6t69e4u2BQAA5hSxOQAAVGkifZtttsn/d+jQIQ0cOLDWY3PPPXcO1M8888zUUkaNGpX+8pe/pFVXXbXW8kMPPTTdfffd6aabbsodiAMOOCD98pe/TI8++miLtQUAAOYksTkAAFRpIn369On5/969e+fAefHFF0+zyxdffJF23XXXdOmll6aTTz65ZvnEiRPT5Zdfnq699tq00UYb5WXDhw9PK664YnriiSfSuuuuO9vaCAAAs4vYHAAAqnyO9NGjR9cL1ONiRi1p//33T1tssUXaZJNNai1/+umn09SpU2stX2GFFdIyyyyTHn/88UZfL4aZTpo0qdYNAABam9Yem4vLAQBos4n0008/Pd1www0197fffvu06KKLpqWWWio9//zzzd2+PL/iM888k4YOHVrvsbFjx6bOnTunhRdeuNbymIMxHmtMvFYMNS3fevXq1eztBgCAltbaY3NxOQAAbTaRPmzYsJoA9957703//ve/04gRI9Jmm22WjjzyyGZt3JgxY/LFi6655po0zzzzNNvrxkWRYuhp+RbbAQCA1qa1x+bicgAA2twc6WVRTVIO1u+66660ww47pF/84hf5gkbrrLNOszYuhoeOHz8+/ehHP6pZNm3atPTQQw+lCy64IN1zzz3pm2++ycNXKytfxo0bl3r06NHo63bp0iXfAACgNWvtsbm4HACANluRvsgii9RUikS1S3kOxFKplAPp5rTxxhunF154IT333HM1t7XWWitf3Kj889xzz53uu+++mue89tpr6b333kvrrbdes7YFAACqjdgcAACqtCL9l7/8Zdpll11Snz590v/+9788bDQ8++yz6fvf/36zNm7BBRdMq6yySq1l888/f1psscVqlu+1117psMMOy3NBLrTQQunAAw/Mgfq6667brG0BAIBqIzYHAIAqTaSfffbZeahoVL6cccYZaYEFFsjLP/roo7Tffvu1RBtn2J6OHTum7bbbLk2ZMiUNGDAgXXTRRbO9HQAAMLuJzQEAoEoT6TFc84gjjqi3/NBDD02zw3/+859a9+NCRxdeeGG+AQBAeyI2BwCAKp0jPVx99dWpf//+ackll0zvvvtuXnbOOeekO+64o7nbBwAAFBCbAwBAFSbSL7744jzvYcy/OGHChJqLGC288MI5YAcAAGYPsTkAAFRpIv38889Pl156aTrmmGPSXHPNVbN8rbXWSi+88EJztw8AAGiE2BwAAKo0kT569Oi0xhpr1FvepUuXNHny5OZqFwAAMANicwAAqNJEeu/evdNzzz1Xb/mIESPSiiuu2FztAgAAZkBsDgAAs0enpq544oknpiOOOCLPwbj//vunr7/+OpVKpfTkk0+m6667Lg0dOjRddtllLdtaAABAbA4AANWaSB8yZEj63e9+l37729+meeedNx177LHpyy+/TLvssktacskl07nnnpt22mmnlm0tAAAgNgcAgGpNpEeFS9muu+6abxGsf/HFF6lbt24t1T4AAKAOsTkAAFRpIj106NCh1v355psv3wAAgNlLbA4AAFWaSP/BD35QL2Cv69NPP/2ubQIAAGZAbA4AAFWaSI+5GLt27dpyrQEAAJpEbA4AAFWaSI8LFplzEQAA5jyxOQAAzD4dm7rijIaNAgAAs4fYHAAAqjSRXiqVWrYlAABAk4jNAQCgSqd2mT59esu2BAAAaBKxOQAAVGlFOgAAAAAAtEcS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACnQqehAAWovljr57TjcBaIXeOW2LOd0EAACgFVCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAFprIn3o0KFp7bXXTgsuuGDq1q1b2mabbdJrr71Wa52vv/467b///mmxxRZLCyywQNpuu+3SuHHj5libAQCgLRKbAwDQnlV1Iv3BBx/MgfgTTzyR7r333jR16tT0i1/8Ik2ePLlmnUMPPTT9/e9/TzfddFNe/8MPP0y//OUv52i7AQCgrRGbAwDQnnVKVWzEiBG17l955ZW5+uXpp59OP/3pT9PEiRPT5Zdfnq699tq00UYb5XWGDx+eVlxxxRzgr7vuunOo5QAA0LaIzQEAaM+quiK9rgjOw6KLLpr/j6A9KmE22WSTmnVWWGGFtMwyy6THH398jrUTAADaOrE5AADtSVVXpFeaPn16OuSQQ1K/fv3SKquskpeNHTs2de7cOS288MK11u3evXt+rDFTpkzJt7JJkya1YMsBAKBtaa7YXFwOAEBr0Woq0mM+xhdffDFdf/31zXKhpK5du9bcevXq1SxtBACA9qC5YnNxOQAArUWrSKQfcMAB6a677koPPPBAWnrppWuW9+jRI33zzTdpwoQJtdYfN25cfqwxgwcPzkNRy7cxY8a0aPsBAKCtaM7YXFwOAEBrUdWJ9FKplAP12267Ld1///2pd+/etR5fc80109xzz53uu+++mmWvvfZaeu+999J6663X6Ot26dIlLbTQQrVuAADA7I3NxeUAALQWnap9yOi1116b7rjjjrTgggvWzK0Ywz7nnXfe/P9ee+2VDjvssHyRowi8DzzwwByor7vuunO6+QAA0GaIzQEAaM+qOpF+8cUX5/833HDDWsuHDx+edt999/zz2WefnTp27Ji22267fKGiAQMGpIsuumiOtBcAANoqsTkAAO1Zp2ofPjoj88wzT7rwwgvzDQAAaBlicwAA2rOqniMdAAAAAADmNIl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAABoD4n0Cy+8MC233HJpnnnmSeuss0568skn53STAACgXRKbAwDQ1rSJRPoNN9yQDjvssHTCCSekZ555Jq222mppwIABafz48XO6aQAA0K6IzQEAaIvaRCL9rLPOSnvvvXfaY4890korrZSGDRuW5ptvvnTFFVfM6aYBAEC7IjYHAKAt6pRauW+++SY9/fTTafDgwTXLOnbsmDbZZJP0+OOPN/icKVOm5FvZxIkT8/+TJk1Ks9v0KV/O9m0CbcOc+MyqZj5Pgdb0WVrebqlUSm3JzMbm1RSXB39Lqs/sOhcc+/Z7/B376uTYt18+99uvSa0gLm/1ifRPPvkkTZs2LXXv3r3W8rj/6quvNvicoUOHpiFDhtRb3qtXrxZrJ0Bz63rOnG4BQOs3pz9LP//889S1a9fUVsxsbC4up9p/R5mzHP/2y7Fvvxz79qtrK4jLW30ifVZEhUzM21g2ffr09Omnn6bFFlssdejQYY62DSq/EYtO5JgxY9JCCy00p5sD0Cr5LKVaRcVLBOtLLrlkas/E5S3DZ1/75di3X459++XYt2+O/+yNy1t9In3xxRdPc801Vxo3blyt5XG/R48eDT6nS5cu+VZp4YUXbtF2wqyKD0IfhgDfjc9SqlFbqkSf1dhcXN6yfPa1X459++XYt1+Offvm+M+euLzVX2y0c+fOac0110z33XdfrUqWuL/eeuvN0bYBAEB7IjYHAKCtavUV6SGGgw4cODCttdZa6cc//nE655xz0uTJk9Mee+wxp5sGAADtitgcAIC2qE0k0nfcccf08ccfp+OPPz6NHTs2rb766mnEiBH1LnIErUkMcz7hhBPqDXcGoOl8lsLsJzaf83z2tV+Offvl2Ldfjn375vjPXh1KMaM6AAAAAADQNudIBwAAAACAliSRDgAAAAAABSTSAQAAAACggEQ6NMGjjz6a+vbtm+aee+60zTbbNLjsP//5T+rQoUOaMGFCk15zww03TIccckgLtxwAgGowp2O/3XffvSaOrYb2tEUttU9by7F65513cn/oueeem9NNoQ7Hpu2r+xkPtIxOLfS60KYcdthhafXVV0///Oc/0wILLNDgsvnmmy999NFHqWvXrk16zVtvvTUn4Zv7j2ck8m+//fbU3JZbbrkcwLeGIB5oG+ILyp/97Gfps88+SwsvvPCcbg5Am9ISsSht41j5+1sd4guU6G+ec84537lP2KtXr9xXXXzxxVugpcDscuWVV+acTFMLOKsln9SWqEiHJnjrrbfSRhttlJZeeumaYLLuss6dO6cePXrkb/qbYtFFF00LLrhgC7ccAADqE4tWv2+++Sb/71i13WM7u8w111y5r9qpk1pKGlYqldK33347p5sBVU8iHVJK06dPT0OHDk29e/dO8847b1pttdXSzTffXDME7n//+1/ac88988/xDWBDyxqa2iWmf4lKgqhWX2SRRdKAAQNyZUdDQzSnTJmSjjjiiLTUUkul+eefP62zzjr5NctiG5Gwv+eee9KKK66Yq+A33XTTXFkQ/vjHP6a//vWv6Y477sjtiFs8v/weopIlKkuiLfH+Hn/88Vr74JFHHkk/+clP8vuPioWDDjooTZ48uaat7777bjr00ENrXhug8jP0jDPOSN///vdTly5d0jLLLJNOOeWUBj8XY0hxLIvPphCfLVtttVX+jIzPvpVXXjn94x//yI/HZ1aIx+I5USVR/ryMz6hu3bqleeaZJ/Xv3z+NGjWqZhvl7cbn5RprrJE/1+KLz/Hjx+dRRPEZutBCC6Vddtklffnll9/pPYamfM7O6DMcaB8iSXHAAQfkEYxRGXrcccfl5EW4+uqr01prrZUTppHwis+o+Nwqixhy1113TUsssUT+XOvTp08aPnx4zeNjxoxJO+ywQ/6sicTr1ltvXfNZ25C6sWiMPjz11FNzfBttiM+5Sy65pNZzZnYb7VH8vTjqqKPy/onjGDF62XvvvZf3WfwNiL9DsS/HjRtX83isGxXIl112We6XxN+4useq/Deu7q38NzJcfPHFafnll8+FPj/84Q/zuVUp1o9tbLvttvlvVpxLd955Z36s6O/viBEj8t/cOP6LLbZY2nLLLXNxETMWxzB+9+M4xu9+9AsffPDB9OMf/zjHFT179kxHH310TSIz9nk8fu6559Yc4zg206ZNS3vttVdNvzWOb6xTNqM+YeXULkXbL7c54q3GzmeaX1G8+cILL+R4No57/P4NGjQoffHFF42+VlPj5YiN11xzzby9yAlQvX2neHyPPfZIEydOrPn9Lv9ORoyw22675c/t+FzfbLPN0htvvFHv70ulGO0Sf/uLPjuoTyIdUspJ9KuuuioNGzYsvfTSSzlh/Otf/zoneCLJEYFufMjEz9tvv329ZTvuuGO914wPvI033jittNJKOZkSf5QiWRTBT0MisIr1rr/++vTf//43byeSLJUffpHw+fOf/5yD4YceeigH45F8D/F/BOPlxEzc1l9//ZrnHnPMMXmdaNcPfvCDtPPOO9cEShEAx/O22267vO0bbrghtzfaFCI5FJX3J554Ys1rA5QNHjw4nXbaaTkh9PLLL6drr702de/evUnP3X///XOgH59p0UE4/fTTc4IhvtC75ZZb8jqvvfZa/twpdxSjQxePRbD3zDPP5CA0OqSffvpprdeOgPCCCy5Ijz32WE3yJz63o3133313+te//pXOP//8ZnuPRZ+zM/oMB9qH+NyKitAnn3wyf6adddZZOaEZpk6dmk466aT0/PPP52HV0WmuTI6WP38i6fHKK6/kZGl5moZ4bnwORgL84YcfzsUc5S/sZqby9cwzz8zJ/GeffTbtt99+ad99982fwc25jfZwjOOL4ZEjR+ZEScTP9957b06cRBI9/lZFAjOWvf322/X6EW+++Wb+Gxfxd0PzWUd8X47H43b//ffnJNlPf/rT/Phtt92WDj744HT44YenF198Me2zzz458fLAAw/Uep0hQ4bkv4sR+2+++eb5S5poW9Hf3yiyiektn3rqqXTfffeljh075mR8vDeadm7ElxvxuxMxSuz3tddeO//Ox+/z5Zdfnk4++eS8buzz9dZbL+299941xzqOTezr6JfddNNN+fPg+OOPT3/4wx/SjTfe2KQ+YdkHH3xQuP0Znc+0jMbizfjdi8/fSJJGMjyO/7///e+a/npDmhovxxcosc34u7LqqqvOhnfJrPad4nc5+jKRiyr/fpf7EhEvxGdzfCkaeaX4kj5+x+Nvd1M09bOD/z98A9q1r7/+ujTffPOVHnvssVrL99prr9LOO++cf+7atWtp+PDhtR6vu+yBBx6IcqLSZ599lu/Hc/v169fodjfYYIPSwQcfnH9+9913S3PNNVfpgw8+qLXOxhtvXBo8eHD+ObYVr//mm2/WPH7hhReWunfvXnN/4MCBpa233rrWa4wePTo/77LLLqtZ9tJLL+Vlr7zySs17HTRoUK3nPfzww6WOHTuWvvrqq3x/2WWXLZ199tmNvh+gfZo0aVKpS5cupUsvvbTeY3U/F8Ozzz6bl8VnU+jbt2/pj3/8Y4Ov3dDzv/jii9Lcc89duuaaa2qWffPNN6Ull1yydMYZZ9R63r///e+adYYOHZqXvfXWWzXL9tlnn9KAAQO+03ts6udsUz7DgbYtYr8VV1yxNH369Jplv//97/OyhowaNSp/bnz++ef5/lZbbVXaY489Glz36quvLv3whz+s9dpTpkwpzTvvvKV77rmnwTixMhYtx3q//vWva+7Ha3Xr1q108cUXN3kb7V3s0/79+9datvbaa+fj/K9//SvH+++99169vxVPPvlkvn/CCSfkv3Hjx4+v97qVx6rsk08+KX3ve98r7bfffjXL1l9//dLee+9da73tt9++tPnmm9fcj20ee+yxtf62xrJ//vOfjf79bcjHH3+c13vhhRdq/T2Mv/WU6h3DNdZYo+b+H/7wh3q/TxEXLLDAAqVp06YVHve69t9//9J2223XpD5h+dg0dfuNnc80v6J485JLLiktssgi+Xe17O6778799bFjx9Y77jMTL99+++2z4d3RXH2n6FNELqrS66+/ntd59NFHa/19iL/PN954Y83fl9VWW63W8yK/E3/7iz47qE9FOu1eVH1EleDPf/7zXFVTvkWF+ncZqliuSG+KqMKMSvWoYKxsQ1SrVLYhhujEMM2yGIJXOeS3SOW3y/G8UH5uVCHEtAOV245vq6PiYfTo0U1+z0D7E9UrUVHe1M+7umLIaVQ/9evXL51wwgm5Mq5IfCZGZUWsXxYXYIuhydGWxj73osojPkO/973v1VrWlM/Qpr7Hos/Z7/oZDrQN6667bq0p8qLiNEYfRhz49NNP59GLMcQ7qr432GCDvE6MXglRHR4jF2NodlQaxmibsojlIqaN55VjuZiK4euvv56peLbycyzaGVM5VMaLzbGNtq5uRWf5sz7+lkRFcdzKYuRqTJNS+fdr2WWXzdP3zEj8LYzRpLF+5dQe8VqVfyND3C/6GxkVx1HhOKO/SXGuxmir+Fsa65enBCifoxSL6TPK4njE73/l50Ecp5iq4/333y98nQsvvDC/Vpwn8XsYUzDN7DFo6vYbO59pfkXxZjwW0wbG72rl8Yr+ennU0KzGyzEKidbTd2rsNWO0W0wPXBbT/8TUT3WPN9+dK03Q7pXnFYth/jE/eaWYr2pWxdxlM9OGuABMdKDi/0oRHFX+8asUgU95Xs0ZqXxuOWAqD8OM7cewz0ho1RWdOYBZ+ayLId+h8nOq7vDC3/72t/mLu/JUKzHVVkwtcOCBB37nttX93GvoM7Qpw9Gb+nle9Dlb9/GZ/QwH2rZIRsdnYdyuueaanCCLxFjcL0+bEvOdxrSDcR2JmFohOuExPVZMGRWxXCTW4rl1NSUpW1b0Odlc22jrZvVvTVlloqxIfLES05bFNEGzcgHJWWlnfNETiftLL700Lbnkknn9VVZZxdQ+zXxsi8SXaTEFQ8RKkQiPL7b+9Kc/5alXqvF8pmXyB9V2XjL7+k6zKl67br+juV67vVGRTrsXlSCRMI/OSswbVnmrrBiZWfHtfcwd2BRxMbyoRIpv9+u2ISqBmirm3GtsDvYiP/rRj/LcXHW3Hbd4ze/y2kDbFhcoi4Cwoc+7cmKl8roKDc33Gp+1v/vd7/J8sDGna3TQQ/nzp/Kzp3zxtJhftDIIjPki4/N8dr9HgJlRN9n1xBNP5M+YV199NV/IPuZMjYu/r7DCCg1Wfcbn6sCBA9Pf/va3PE9q+WKgEctFtXBcVK5uLBcXNm0Os2MbbVlcaDoS33Eri/g7Lio3s3+/Ym79mBM7LgoXVYd1t1P5NzLE/ZnZRkN/f+P8jMrXY489Nn+JE9uJi9sxa2L/lecxrjxOkRiPOdAb63/FOjFvcVzDIPqQ8ftXd0RIU/ptTdk+s1dRvBnHK0YFxVzplccrkqNRdVzXnIiXmT19p4Z+v+P8iOsyVcYY5c/s8vGO1x47dmyt3/mmvDb1SaTT7kWwEN/qxwVG40IcEYjExTjiAnRx/7tcQCL+UEWQE1MVRAcpLuLyySef1Fs3pnSJC/zEVZYjkRTTqUR1SVRmRpVmU8XwythWfGDGdpr6DePvf//7PDw4LlYSH6bRSYrAvPLiJfHacXG8uDBNQ+8BaJ/iAmfxGRLTDJSnxIrEUFywqvyFZFxQKz5X4vMsKqgqHXLIIemee+7Jn3vx2RsXQ4tgMETVW1Q+3XXXXenjjz/O1ZBRNRNVeEceeWQaMWJETkLEhbhiiq699tprtr9HgJkRhRtxscaI1a677rocb8aFIWMEYHRg435cgDIuFhYXHq0UFxWM+CymV3nppZfyZ2P58zLiyLjwaFzMMi4EGp+p//nPf/JowxlNE9FUs2Mbbdkmm2yS+vbtm/dj/L2LWD9i/5jCZ2amVogLDMbfo6hCjuMRiZG4TZw4MT8efx9jysbod8Tf3ki6R/9iZi5u3dDf37jIYSTt48ubOAfjIqdxLjNroo8YX6rECLzoJ8bvdkxxF/u0XJUa/a9IjMWFh6P/FZXgkYSLCwpG7PT666/nixVGn3Nm+4RN2T6zV1G8GZ8b8Xh8kRoXEY54OY7db37zmwYvUjkn4mVmT98pfr/jMzkS8fH7Hcc0Phfib3Mc40ceeSR/6fLrX/86z7gQy8OGG26YP8/josGxzZgiKi5e3hz5pPbGJySklDsqEYRE4jo6JHGl4vjQ6t279yy/ZiTHY5qC+BCLuchi6F0EKI0NvRw+fHgOpqMaM75V3mabbXJQNDNTq8QHZzw3gvH4xrFuNUpR9XzMxx7BWFRBRXVDdNZiyGZZXKE9grj4dtvwXaBSfH7GZ1d8bsRn6I477pgrKWM4cCSKooMWnzOnn356ng+9UlQ9xNQE5c/e+Oy86KKL8mMR/A0ZMiQdffTRuZNQ/nIvKjZjXtjoPESFZHToo0MZnfzZ/R4BZkbEel999VWODeOzL5LogwYNyrFVJD9vuummXD0Wn3MxZUulSLRHoUZ8nv70pz/N0wHGNA/lazBEwUPEjb/85S/z51QkS2LKmJjLujnMjm20ZZGYjr5A/K2K4xeJ9Zhr/IYbbpip14kkSfztjJFcMV91+RbnUog+RMyZHufPyiuvnP7yl7/kfkYkUZqqob+/kVyN8y2moozpXKIIKZL5zJrYxzFNU3yhEnNfx/GM36eo+C+LLz/i9zw+E8rTPcV0nPH7F3FIzIccVaeRFJ/ZPmFTts/s11i8GZ+/Eet++umnae21106/+tWv8siQCy64oNHXmhPxMi3fd4oRKfH7Gs+J3+9IjIf4nI/p17bccsuce4rK8/gdL0/PFNuJPlYk0ON3Pn73637BOqv5pPamQ1xxdE43AgAAAAAAqpWKdAAAAAAAKCCRDgC0azFUeoEFFmj0Fo8DAADQvpnaBQBo1+Iq93ENiMbEhXcau74FAAAA7YNEOgAAAAAAFDC1CwAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXQAAAAAACggkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAAFJBIBwAAAACAAhLpAAAAAABQQCIdAAAAAAAKSKQDAAAAAEABiXSg3bvyyitThw4d0jvvvJOqVbTvj3/8Y6veV//5z3/yc+N/Wvf5CAAwJ+Kjp556aobrbrjhhvnWFuy+++5pgQUWaFf9jbbC/oS2SSIdqOpguXzr1KlTWmqppXIw+cEHH8zp5lWd6CxU7q/Gbu05mHvhhRfSr371q7TsssumeeaZJ59PP//5z9P5558/S6937bXXpnPOOafJ63/zzTfp3HPPTWussUZaaKGF0sILL5xWXnnlNGjQoPTqq6/OUhsAABqKnevennjiiTndxFYr+h+xDyN+++qrr+o9/sYbb9Ts5z//+c8z/fpffvlljtHbWrHJW2+9lfbZZ5/0ve99L8fesf/69euX4+GG9iNAa9BpTjcAoMiJJ56Yevfunb7++uvcAYhOwiOPPJJefPHFHJDx/x1zzDHpt7/9bc39UaNGpfPOOy/94Q9/SCuuuGLN8lVXXfU7bec3v/lN2mmnnVKXLl1m+rk//elPc9DcuXPnNLs99thj6Wc/+1laZpll0t5775169OiRxowZk8+pCOYPPPDAWUqkx3l4yCGHNGn97bbbLv3zn/9MO++8c27D1KlTcwL9rrvuSuuvv35aYYUVvvM+BgDat3LsXNf3v//9OdKetiKKeiLh/fe//z3tsMMOtR675pprcr8k+iuzIl53yJAh+ee2Ukl/9913p+233z7Hs7vttltaZZVVclFJ9OOOPPLI9NJLL6VLLrkktWXR74nzBmhb/FYDVW2zzTZLa621Vv45EsWLL754Ov3009Odd95ZL4htz6KyulIE85FIj+VFAfnkyZPT/PPP3+TtzDXXXPk2Kzp27DjHvvw45ZRTUteuXfMXDFEJXmn8+PEtvv3YbiTMox3x5UalCy64IE2YMKFZ9jEA0L5Vxs40n0gIRzX1ddddV68PEsUVW2yxRbrlllvmWPuqyejRo3NRSIwCvf/++1PPnj1rHtt///3Tm2++mRPtbdH06dPzFwbR51H0BW2TqV2AVuUnP/lJzVDBSlHZG9N2LLroojloiQ5EJNvriuqHjTbaKM0777xp6aWXTieffHIOeOpqbBqU5ZZbLg/vrBRJ0EMPPTQ/FkF2vG5UXnzyySc160yZMiWdcMIJuRoo1unVq1c66qij8vJKcT9ea4kllkgLLrhg+r//+7/0/vvvp+YQ7yfe18svv5x22WWXtMgii6T+/fvnx/773//m91UeehkV23vuuWf63//+N8P5u+N9b7nllrnC5Mc//nF+frzOVVddNcM50iPJHxUq0aaoGJ9vvvnylCtnnHFGvfa/++67eX9E4r9bt255P91zzz1Nmnc9zpeYRqVuEj3Ea9X1t7/9La255pr5PIlzKjoDUcFe2e7oAESbykN5Yz8UbT9EB6yuSJovtthije7j8nFr6FZ5LsZ5HFPNxPuMY9C9e/c8nPazzz4r3DcAQPsR8UV5CpKoCF5++eVzbLr22mvnL/4rjR07Nu2xxx45to11IiG69dZb17uOS4y4ixg9YrSIXyOpHDF3Q3N9v/feezlujJ8j5rvwwgtrpuCLGD1eIxKwkZxurHo74puInWKqkIi5mxLrNDUWLxLxc7zXygKI2GcxtUs81pBYN0YvxvZiu7H9KAoq9z9iX0bcH6IqvbHpGGNqy2222Sbvt1j/iCOOSNOmTatXIHP44YfXbOuHP/xhPs6lUmmW+huff/55bnu5jxMxcxTpPPPMM4X7KeL4L774Il1++eW1kuhlsQ8OPvjgmvvffvttOumkk2rOxdheFJ7UPTblPkfE/dHXizi9b9++Nf2AW2+9Nd+PODji+GeffbbBc/Dtt99OAwYMyOfakksumUdx1N1Hsd9ixGicZ7GdeL2bb7653nuJY3XAAQfkUQkRg0f7R4wYUfNY5XFs6v686aabavohUUT261//ut7UpuX30pTzAmheKtKBVqUcuEcSuCwC9UhQRjB+9NFH56DoxhtvzEFFVIZsu+22NZ2BSNZGsFZeLzoQEaTMqggSo+Pwyiuv5MTzj370o5xAjyR+BKQR/ESgHAFqJJpjPuyYaiU6C2effXZ6/fXX0+23317zelF1H0ncCMYjeIsqjuiMNKcYZtmnT5906qmn1gSN9957bw4qo7MUSfTycMv4P6Y/iUCwSFSWxBcZe+21Vxo4cGC64oorcoAXQWAElUWi87PpppumX/7yl7nCJ4LU3//+9zkQjqqqcscgOlcfffRRDryjjdHBeuCBB5r0nqND9vjjj+epWCJxXySqxo877rjcljgeH3/8cZ5HPaamiYA8kvExlc7EiRPzMY7jGIouBBXbDxFkx7k6M8M8Y7/UHY799NNP56R55ZcA0amMJHwcw4MOOihXA0W1e7T50UcfTXPPPXeTtwkAtE4Rn1QWc4SI4yq/tA8RR0ViL+KHeDySnxFzRDxYjhliWrqIBWMKvEj+xSi+iBkjGV4uILj66qtz7BeJyUgQR6L74osvzsUaEYNUFhpEgi9iu4ipYnsRF0USMmLyiK123XXX3IZhw4blBPl6661Xb5qaWD9isUhQvvbaa3lbUdhQLthoyMzE4kWibb/73e9ywjbi/vJ+jOn5og9QV+yLDTbYICc7Yz/HFIMx3eDgwYNzTBuxXCQ/4z3su+++uc8S26g7HWPst9i/66yzTk7w/vvf/05nnnlmTjzH80LE9PEeIzaOeHz11VfPBScxjUpsvxyvzkx/I95rxOWxz1daaaVcYBP7MPo9Db3fspj+Jopq4rWbItrz17/+Nfcl4ouAkSNHpqFDh+bt3HbbbfX6HNHu2J+RYI79sdVWW+VzJpLv++23X14vnh+xfJwjMSq2cl9Gv2PdddfN52AkveMLlugfRkK9LKZ+jP0Z52RUmF9//fW5DxUjTOvuq9h/0feM/RR9v8aKa5qyP8uxfHyxFe9h3LhxuS0Ry5f7ITNzXgAtoARQhYYPHx4Z3tK///3v0scff1waM2ZM6eabby4tscQSpS5duuT7ZRtvvHGpb9++pa+//rpm2fTp00vrr79+qU+fPjXLDjnkkPyaI0eOrFk2fvz4UteuXfPy0aNH1yyP+yeccEK9di277LKlgQMH1tw//vjj87q33nprvXWjDeHqq68udezYsfTwww/XenzYsGH5uY8++mi+/9xzz+X7++23X631dtlll0bb05ibbropP+eBBx6oWRbPj2U777xzvfW//PLLesuuu+66vP5DDz1U77hU7qvYJ3XXi/0ax+nwww+vWRZtqdumDTbYIC+76qqrapZNmTKl1KNHj9J2221Xs+zMM8/M691+++01y7766qvSCiusUO81G/Kvf/2rNNdcc+XbeuutVzrqqKNK99xzT+mbb76ptd4777yT1znllFNqLX/hhRdKnTp1qrV8iy22yO+9KeJcKL/X7t2752Nw4YUXlt5999166za0jyvF78MyyyyTz/kvvvgiL4tzK55zzTXX1Fp3xIgRDS4HANqWcvzQ0C1isrKIL2LZYostVvr0009rlt9xxx15+d///vd8/7PPPsv3//SnPzW6zc8//7y08MILl/bee+9ay8eOHZvj68rlET/H65166qk1y2Ib8847b6lDhw6l66+/vmb5q6++Wi/2Lb+/Nddcs1b8dsYZZ+Tl0f6yiLniVtbUWLwx0fb5558///yrX/0q9z3CtGnTcsw6ZMiQmv1aub9OOumk/LzXX3+91usdffTROd587733amK7xmL98n478cQTay1fY4018r4oixg51jv55JNrrRftjf375ptvznR/I47h/vvvX5oZEydOzK+z9dZbN2n9cnt++9vf1lp+xBFH5OX3339/vT7HY489VrMs4vlYFudRZVz9l7/8pV4fobwvDzzwwFoxesT0nTt3zsehsb5RnHOrrLJKaaONNqq1PF4vzq2XXnqp3nub2f0Z2+jWrVveTvRzyu666678WtHvnNnzAmh+pnYBqtomm2ySKzViiGJUKUTFSlR7xxDT8Omnn+YqgKg4iKqaqMCJW3zDH9/Qx1DL8lC4f/zjH7n6IKYfKYvXjkqDWRUV76uttlpN1XulclVMDM+LypeoVim3L25RYR3KVdXRvhDVxJWaejHLpopqiLoqq/LjQknRvthXYUbDN0NUVZSn3Snv1xhOGlVNMxKV3FFRUhYXI41jVPncqBaJEQdRGVIWwzbjop1NEcMmoyI9nv/888/nCpQ4P+I1K6cAigqjqFqK86nyWEUFfFTxN7UCvqFzIaqCYiqhGE0R82vGHJFRqb7jjjvWGiJcJCpP4mKlca5HhU55fvs4x2IO+Hifle2OEQGxf2e13QBA6xJTpUTVeOUtpiOpK+KPyhGe5TiuHH9FbBgxWVR6NzZ1Srx2xDARm1TGHzFtXVTJNhR/RPVxWVTXRrwY8UzlvOOxLB5rKI6MivLKUXZReRsj/cpxdEOaGos3RVRDxz6Jka7RB4n/G5vWJbYb+zX2c+V2o38TMd1DDz00y/F7vG7l/on3H/u9bj8iKrwjp1s+B2amvxHHIKrDP/zwwya3c9KkSfn/mDKmKcrtOeyww+q1O9SdSz36HDFSoSzOsxDHMir+6y5v6ByKivC6U7NE1XlUdDfUN4rzP0Z6xD5vqF8Uow6iXTMyo/351FNP5VEfUVVfOb96VMDHudvQvPIzOi+A5mdqF6DqOwM/+MEPcvAS04VEwBlzylUO74vgMKbiiFtDIiCJhGkM+ywHVZUiWJ9VMfd1DHstEsn8GLJXnv+wofaFaF8MPYzheM3VvobUHSJb/kIi5mWMYYt1L74Z+35GKgPXsug0NGXOyvhSpO5Q3HhuzNteFvsm9kvd9epOeVIkhkhGojwC5UimRyI6hrnGFzTPPfdcDoDjWMX5FEnzhnyX6VHivI1hy3GL4bwPPvhgHqoZQ0HjdWOI7Ywce+yxudMWgXTleRLtjuPU0Hzvs+uCqgDAnBfFCE252Gjd2K2cVC/HbhG3xFQtkdCM665EgUXMTx1TrkSBQTn+COWEdF0xh3mlSA7WjYejEKChWDCWNxRH1o3RomAg5uGuO2/7rMTiTbH55pvnJPENN9yQ48eILyMebWj7sd2IZ7/rdhvab3Xj7IiVY77vugns+AKh/PjM9jei8CSm7YmCpijOiPcexz+mbWlM+ZhH0UdTlNtTN6aPcywSz+V2N3bexnkSoo0NLa97DsW26rY/+pqh8hjGFC5RABPHuHKu9oamD2qob9WQGe3P8ntt6FhEIj2mgZnZ8wJofhLpQKvpDMSc5zHfYlR9xHx3ETiXL9QTF1aJCuOGzEyydUZm5eIt0caY7/uss85q8PG6gV9La2hO+KgCijkbYx7FmFOxvG9jDsGGLsZaV1TANKTuhXua+7mzIqqrotMTtwicYx7CqBiK+RHjvUaAHFU7DbWraB70mREdvriAaXwJE3PIRzI95kQsmjs95u+MDm1cjCmOS6VodyTRY67RhjTWgQMA2qemxF9RpRzzT0cMEiPromgl5m2OL/XXWGONmhgx5kkvJ9cr1Y1rGttmS8eCzRmLxxcMMY95zOkdlb91Lwpad7sxWjAuatqQcgJ3RhrbPy0t+gdR4RzFJ//617/Sn/70pxyLRmFK+TpGDSXSI6Ef1yWaGTO6HtPsPIcefvjhPIo15vK/6KKLctweRS/Dhw9v8CK4Tb3e1qzsz2o8L6C9k0gHWo0IFiJ4jwuGxkUU44Kh5W/wI7iJYZJFYhqNcuVMpUjK1xXf5tedbiMqmaOSuFJUc8woUIx1ogJ64403LgwSo30RcEeVe2UlQkPta05RtXDfffflivTjjz++ZnlD+2pOiX3z8ssv52C4ch/GiITvovwlTfm4xrGKbURlyYw6N00N+IvEeRsXk4p9XZ5CpiFxIayoYIkvk+JCSnVFu2M4alzI9LtcPBcAoG6MEVXpcYt4JQou4oKGMZKuXNUcX+bPKA5vLtGG6AuUffHFFzmOi+re7xqLN1UU9cRI2ahujsKIou1G+2a0b5qjTRErRywYleCVVemvvvpqzeOz0t+IJHJMNRK3qKCPi2KecsophYnfGLlwySWX5GkVK6dhaazd0Z44ruXq+RAX2Yy+WLndzSW2FV+AVMb5EWeH8kVCY+rOqPaOL48qR0JHIv27Ktqf5fcax6LuKI9Y1tz7Apg15kgHWpUNN9wwV6nHVe5jLu8I3GPZX/7yl3pJ7vDxxx/X/BwB9hNPPJGefPLJWo83VMUbgW/deQsjIKxbkR4VxeVpQhqrgIjqg5in/dJLL623zldffZUmT56cfy4HpOedd16tdeK9tqRyNUPdio2W3u7MiNEGsQ8r5zOP49/QPm1IzH3ZUEVKeV7GckciKoxif8SXCnXXj/sx935ZzOfZlGlvQnQO3nvvvXrLo4MQnYz44qaxqvHogMUc/DE9UVQ/NdTZinMszs2oVq/r22+/bfIc7AAA4csvv8yxVt34OJK05akuIj6LCuRTTz01TZ06tTAOby4Rj1du6+KLL86xTlFit6mxeFNFIj9irijsaawIorzdiPMiIVtXxGbR7jDffPPVLJtV0c+JWDDaVCmmMYzYsbx/mtrfiNeqG+dGvyuqzSunOmlIVOBHnBzz4UdCvK5I4sf0huV2N7T98uiBmB+8uVXuo4jv434Ut8QXLSH6ArHPKvt9Me1LjMyYVU3Zn1HgE8uGDRtWax/HSNmYmqgl9gUw81SkA61OTD+y/fbb56kw4gIrMY96TPkSQzbj4pNRpR5BWwSu77//fk50l4O6GHoa02IcfPDBOcCLYDy+3a+cjztE4BevHYnyGJIZrxFB8OKLL16vLTfffHNuz5577pnnu4v5xiPhG0FQXIj0N7/5TZ66I14vErpRNRzBVFSIxPJ43QicosInLtYUQwgj0Fp//fVzpfh3rbqekegAxdDFmLcvOiaRsI3hhqNHj07VYp999slBbuyfOHZRzRFfgJQvxDOjSp4DDzwwdwgjIR1zDMbogpjKJua3jOqTmN6l3EGM+RAHDx6cA+aoAI8OY+yL+LIkLnAV0wiFONbx/Lg4UkwTE9O+xPDnhsT5E9VL0XmJIZ2LLrpo7tBFYjwuOBSdh8aGZ0ZSP6rxY370O+64o9Zj0d6o9ImLHMU+ihEbMZfjL37xi9whiAR+TFsTnZWYCx4AaNsi6VauQq4UcWXR3NZ1RZVuJBYjGRzXkYlpWiIWihi7XIUdMWQksiPWjcraWB6FAVE8ENdziZi3bmL3u4oYrtyuqNKNuDn6AZUXpK+rqbF4U0UlesRlMxL9hOgTRIX27rvvnmPHSNq/8MILuf8QsWb0LWI0YezjiCujUjrixFVWWSXfmipi0Ejwx7V44nWjDxLxfMSOMUVPefRAU/sbUdkec9dH/BivFXFuVLyPGjUqj0goEtuKKVDigrZRZR7zgMd7KcffEZvG/gjx2jHqMvpk8UVCxLRR9BQxcsThlaMPmkP0HUaMGJG3GdfOit+XOFdjxGe5qCUS1pHIjz5jxO9ROR79zZgutG6fsamasj8jdo+pXqJfEvshjlP8vkUcH/2VQw89tFn3BTCLSgBVaPjw4VEOXBo1alS9x6ZNm1Zafvnl8+3bb7/Ny956663SbrvtVurRo0dp7rnnLi211FKlLbfcsnTzzTfXeu5///vf0gYbbFCaZ5558jonnXRS6fLLL8/bGj16dK1t/P73vy8tvvjipfnmm680YMCA0ptvvlladtllSwMHDqz1mv/73/9KBxxwQH69zp07l5Zeeum8zieffFKzzjfffFM6/fTTSyuvvHKpS5cupUUWWaS05pprloYMGVKaOHFizXpfffVV6aCDDiottthipfnnn7+01VZblcaMGZPbd8IJJzR5/9100035OQ888EDNsnh+LPv444/rrf/++++Xtt1229LCCy9c6tq1a2n77bcvffjhh/W2Wz4ulfsq9skWW2xR7zVjP8etLNpSt03xeOyTumL/xetWevvtt/N25p133tISSyxROvzww0u33HJLfs0nnniicH/885//LO25556lFVZYobTAAgvk4/T973+/dOCBB5bGjRtXb/143f79++djELd43v7771967bXXatb54osvSrvsskveZ9GGuu2tFNs47bTT8vvt2bNnqVOnTvkc2Gijjeqdo3X3ceyLuN/Qre65eMkll+TzKvbRggsuWOrbt2/pqKOOyscSAGi7yvFDY7d4PER8Eff/9Kc/1XuNyrgv4tiIfSIGilgo4sN11lmndOONN9Z7XsR2ESvHOhFjR4y+++67l5566qmadSJmidepq7FYsG58WX5/Dz74YGnQoEE5joqYbtddd82xeFEMOjOxeEMaa3ulxvbr559/Xho8eHCOOyP+jL7F+uuvX/rzn/+c21T22GOP5fbEOpXHobFtl+P6uts69NBDS0suuWTuD/Xp0ye3Z/r06bXWa0p/Y8qUKaUjjzyytNpqq+WYMtaLny+66KJSU73++uulvffeu7Tccsvl9xWv069fv9L5559f+vrrr2vWmzp1aj4OvXv3zu3u1atX3meV6xT1OaLdca7O6HiU92X0G3/xi1/kPl737t3ze46+X6XoH8b+i3Mlfgfi/Gtonze07crHZmV/3nDDDaU11lgjb3vRRRfN53j01SrNzHkBNK8O8c+sJuEBYE6KSu6ozoiRB1FJDwAAUFdUwcdIgJg2EWBWmSMdgFYh5rCsFPN2xtz4ffr0kUQHAAAAWpQ50gFoFeJCoMsss0ye2zHmdPzb3/6W57Zs6GKxAAAAAM1JIh2AVmHAgAHpsssuy4nzuEBUXJTp+uuvzxcyAgAAAGizU7s89NBD+erSSy65ZOrQoUO6/fbbaz0e07cff/zxqWfPnvlK1ptsskl64403aq3z6aefpl133TVfMXzhhRdOe+21lzmvANqgQw45JL344ov5Mz6meXn66acl0QGakdgcgLbqyiuv9PcIaN2J9MmTJ6fVVlstXXjhhQ0+fsYZZ6TzzjsvDRs2LI0cOTLNP//8uSIx5sUti0D9pZdeSvfee2+66667cgdg0KBBs/FdAABA6yc2BwCAxnUoRWlJFYiql9tuuy1ts802+X40K6phDj/88HTEEUfkZTEnbvfu3fM3iTvttFN65ZVX8tD+UaNGpbXWWiuvM2LEiLT55pun999/Pz8fAACYOWJzAABoJXOkjx49Oo0dOzYPGS3r2rVrWmedddLjjz+eg/X4P4aMlgP1EOt37NgxV8lsu+22Db72lClT8q1s+vTpeRjqYostljsNAADQkiIx/fnnn+fkcsSu1a6lYnNxOQAArSUur9pEegTqIapcKsX98mPxf7du3Wo93qlTp7TooovWrNOQoUOHpiFDhrRIuwEAoKnGjBmTll566VTtWio2F5cDANBa4vKqTaS3pMGDB6fDDjus5n4MS11mmWXyDosLIwEAQEuaNGlS6tWrV1pwwQVTeyYuBwCgtcTlVZtI79GjR/5/3LhxqWfPnjXL4/7qq69es8748eNrPe/bb7/Nw0HLz29Ily5d8q2uCNYF7AAAzC6tZfqSlorNxeUAALSWuLxqJ2Ts3bt3Drjvu+++Wt8QxPyK6623Xr4f/0+YMCE9/fTTNevcf//9eW7FmK8RAAD47sTmAAC0d3O0Iv2LL75Ib775Zq2LGD333HN5HsUY0nnIIYekk08+OfXp0ycH78cdd1ye+H2bbbbJ66+44opp0003TXvvvXcaNmxYmjp1ajrggAPyxY5iPQAAoGnE5gAAUKWJ9Keeeir97Gc/q7lfnh9x4MCB6corr0xHHXVUmjx5cho0aFCubunfv38aMWJEmmeeeWqec8011+QAfeONN85XVt1uu+3SeeedN0feDwAAtFZicwAAaFyHUqlUSu1cDEvt2rVrvriRuRgBAGhp4s+G2S8AAFRr/Fm1c6QDAAAAAEA1kEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKCCRDgAAAAAABSTSAQAAAACggEQ6AAAAAAAUkEgHAAAAAIACEukAAAAAAFBAIh0AAAAAAApIpAMAAAAAQAGJdAAAAAAAKNCp6EFa3nJH3z2nmwCz5J3TtpjTTQAAAADqkGuiNXqnFeSZJNKBNk8QQWvVGgIJAAAAaA9M7QIAAAAAAK01kT5t2rR03HHHpd69e6d55503Lb/88umkk05KpVKpZp34+fjjj089e/bM62yyySbpjTfemKPtBgCAtkZsDgBAe1bVifTTTz89XXzxxemCCy5Ir7zySr5/xhlnpPPPP79mnbh/3nnnpWHDhqWRI0em+eefPw0YMCB9/fXXc7TtAADQlojNAQBoz6p6jvTHHnssbb311mmLLf7/HLHLLbdcuu6669KTTz5ZU/FyzjnnpGOPPTavF6666qrUvXv3dPvtt6eddtppjrYfAADaCrE5AADtWVVXpK+//vrpvvvuS6+//nq+//zzz6dHHnkkbbbZZvn+6NGj09ixY/OQ0bKuXbumddZZJz3++OONvu6UKVPSpEmTat0AAIDZG5uLywEAaC2quiL96KOPzsH0CiuskOaaa648L+Mpp5ySdt111/x4BOohqlwqxf3yYw0ZOnRoGjJkSAu3HgAA2o6WiM3F5QAAtBZVXZF+4403pmuuuSZde+216Zlnnkl//etf05///Of8/3cxePDgNHHixJrbmDFjmq3NAADQFrVEbC4uBwCgtajqivQjjzwyV76U51Ps27dvevfdd3PlysCBA1OPHj3y8nHjxqWePXvWPC/ur7766o2+bpcuXfINAACYc7G5uBwAgNaiqivSv/zyy9SxY+0mxjDS6dOn55979+6dA/aYq7EshpuOHDkyrbfeerO9vQAA0FaJzQEAaM+quiJ9q622yvMuLrPMMmnllVdOzz77bDrrrLPSnnvumR/v0KFDOuSQQ9LJJ5+c+vTpk4P34447Li255JJpm222mdPNBwCANkNsDgBAe1bVifTzzz8/B9/77bdfGj9+fA7C99lnn3T88cfXrHPUUUelyZMnp0GDBqUJEyak/v37pxEjRqR55plnjrYdAADaErE5AADtWYdSqVRK7VwMOe3atWu+wNFCCy00W7e93NF3z9btQXN557QtUmvh94zWyu8ZtN3fszkZf1Yz+wUAvjuxOa3RO60gLq/qOdIBAAAAAGBOk0gHAAAAAIACEukAAAAAAFBAIh0AAAAAAAp0KnoQAACgvXBxNlqj1nRx8uD3jNaotf2eAS1DRToAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFJNIBAAAAAKCARDoAAAAAABSQSAcAAAAAgAIS6QAAAAAAUEAiHQAAAAAACkikAwAAAABAAYl0AAAAAAAoIJEOAAAAAAAFOqVZ8N5776V33303ffnll2mJJZZIK6+8curSpcusvBQAAPAdiM0BAKCKEunvvPNOuvjii9P111+f3n///VQqlWoe69y5c/rJT36SBg0alLbbbrvUsaNCdwAAaClicwAAmL2aFFUfdNBBabXVVkujR49OJ598cnr55ZfTxIkT0zfffJPGjh2b/vGPf6T+/fun448/Pq266qpp1KhRLd9yAABoh8TmAABQpRXp888/f3r77bfTYostVu+xbt26pY022ijfTjjhhDRixIg0ZsyYtPbaa7dEewEAoF0TmwMAQJUm0ocOHdrkF9x0002/S3sAAIACYnMAAGglFxst++STT9LIkSPTtGnTcpVLz549m69lAABAk4nNAQCgChPpt9xyS9prr73SD37wgzR16tT02muvpQsvvDDtsccezdtCAACgkNgcAACq4GKj4Ysvvqh1f8iQIenJJ5/Mt2effTbddNNN6ZhjjmmJNgIAABXE5gAAUKWJ9DXXXDPdcccdNfc7deqUxo8fX3N/3LhxqXPnzs3fQgAAoBaxOQAAVOnULvfcc0/af//905VXXpmHiZ577rlpxx13zHMwfvvtt6ljx475MQAAoGWJzQEAoEoT6cstt1y6++6703XXXZc22GCDdNBBB6U333wz3yJgX2GFFdI888zTsq0FAADE5gAAUK1Tu5TtvPPOadSoUen5559PG264YZo+fXpaffXVBeoAADCbic0BAKDKKtLDP/7xj/TKK6+k1VZbLV122WXpwQcfTLvuumvabLPN0oknnpjmnXfelmspAABQQ2wOAABVWJF++OGHpz322CNXvOyzzz7ppJNOysNIn3nmmVzxssYaa6R//vOfzd7ADz74IP36179Oiy22WO4M9O3bNz311FM1j5dKpXT88cennj175sc32WST9MYbbzR7OwAAoFqIzQEAoEoT6XGxoqh6uf7663PAfvXVV+flnTt3zoH7rbfemk499dRmbdxnn32W+vXrl+aee+7cEXj55ZfTmWeemRZZZJGadc4444x03nnnpWHDhqWRI0em+eefPw0YMCB9/fXXzdoWAACoFmJzAACo0qldIggePXp0WnPNNdOYMWPqzbu40korpYcffrhZG3f66aenXr16peHDh9cs6927d62Kl3POOScde+yxaeutt87LrrrqqtS9e/d0++23p5122qlZ2wMAANVAbA4AAFVakT506NC02267pSWXXDIPG41Kl5Z25513prXWWittv/32qVu3bnmI6qWXXlrzeHQexo4dm4eMlnXt2jWts8466fHHH2/x9gEAwJwgNgcAgCqtSI8LF2266abp7bffTn369EkLL7xwy7Yspbytiy++OB122GHpD3/4Qx62etBBB+UhqwMHDsyBeogql0pxv/xYQ6ZMmZJvZZMmTWrBdwEAAM2rrcTm4nIAANpcIj3ERYXiNrtMnz49V72U53eMqpcXX3wxz7kYwfp3qeAZMmRIM7YUAABmr7YQm4vLAQBoU1O7/O53v0vvv/9+k17whhtuSNdcc01qDj179szzO1ZaccUV03vvvZd/7tGjR/5/3LhxtdaJ++XHGjJ48OA0ceLEmlvMKwkAAK1BW4rNxeUAALSpivQlllgirbzyyqlfv35pq622ypUoMR9jXNTos88+Sy+//HJ65JFH0vXXX5+XX3LJJc3SuNjea6+9VmvZ66+/npZddtmaixtFUH7fffel1VdfvWY46MiRI9O+++7b6Ot26dIl3wAAoLVpS7G5uBwAgDaVSI+LFx1wwAHpsssuSxdddFEOzistuOCC+aJCEaTHXI3N5dBDD03rr79+Hj66ww47pCeffDJvo9wZ6NChQzrkkEPSySefnOeGjOD9uOOOyx2GbbbZptnaAQAA1UJsDgAAVTxHelwk6Jhjjsm3qHSJIZxfffVVWnzxxdPyyy+fA+fmtvbaa6fbbrstD/k88cQTczB+zjnn5IsrlR111FFp8uTJadCgQWnChAmpf//+acSIEbkiBwAA2iKxOQAAVPHFRssWWWSRfJsdttxyy3xrTHQSIpCPGwAAtDdicwAAqJKLjQIAAAAAQHslkQ4AAAAAAAUk0gEAAAAAoIBEOgAAAAAANGci/YQTTkjvvvvuzD4NAABoZmJzAACo0kT6HXfckZZffvm08cYbp2uvvTZNmTKlZVoGAAAUEpsDAECVJtKfe+65NGrUqLTyyiungw8+OPXo0SPtu+++eRkAADD7iM0BAKCK50hfY4010nnnnZc+/PDDdPnll6f3338/9evXL6266qrp3HPPTRMnTmz+lgIAAPWIzQEAoMovNloqldLUqVPTN998k39eZJFF0gUXXJB69eqVbrjhhuZrJQAAUEhsDgAAVZZIf/rpp9MBBxyQevbsmQ499NBcBfPKK6+kBx98ML3xxhvplFNOSQcddFDztxYAAKhFbA4AAFWYSO/bt29ad9110+jRo/PQ0TFj/l979wEuVXE2DnxAqkoRERQrKvbegmKLGntBjQVNRDEaezfGL/aGmlgSYwsqRmOLsWtiwxYVS+wm0RgDigp2wBIRYf/PO99/77e3cGj3XvZefr/nWdg9e3Z3zt4z58y+552ZMencc89Nyy67bM06gwYNSh9//HFjlxUAAKigbQ4AAM2j3cy+YPfdd09DhgxJiy666DTX6dmzZ5o6derslg0AACigbQ4AAFUaSD/55JObpiQAAMBM0TYHAIAqHdpl1113Teedd1695eeff37abbfdGqtcAADAdGibAwBAlQbSn3jiibTtttvWW77NNtvk5wAAgOahbQ4AAFUaSP/yyy9Thw4d6i1v3759mjhxYmOVCwAAmA5tcwAAqNJA+qqrrppuueWWestvvvnmtNJKKzVWuQAAgOnQNgcAgCqebHSXXXZJb7/9dtpss83yshEjRqSbbrop3XrrrU1RRgAAoAHa5gAAUKWB9B122CHdeeed6Zxzzkl/+tOfUufOndNqq62WHn744bTJJps0TSkBAIB6tM0BAKBKA+lhu+22yzcAAGDO0jYHAIAqHCMdAAAAAADmJjOdkT5lypR00UUXpT/+8Y/p3XffTd9++22t5z/77LPGLB8AADAN2uYAAFClGemnn356uvDCC9Mee+yRJkyYkI455pg8wVHbtm3Taaed1jSlBAAA6tE2BwCAKg2k33DDDWnYsGHp2GOPTe3atUuDBg1KV111VTrllFPSM8880zSlBAAA6tE2BwCAKg2kjxs3Lq266qr5/vzzz58zX8L222+f7rvvvsYvIQAA0CBtcwAAqNJA+mKLLZbGjh2b7y+zzDLpwQcfzPeff/751LFjx8YvIQAA0CBtcwAAqNJA+s4775xGjBiR7x9++OHp5JNPTv369Uv77LNPGjJkSFOUEQAAaIC2OQAANI92M/uCc889t+Z+TGq05JJLpqeffjo32HfYYYfGLh8AADAN2uYAAFCFgfTJkyenn/70pznTpW/fvnlZ//798w0AAGg+2uYAAFClQ7u0b98+3XbbbU1XGgAAYIZomwMAQBWPkT5w4MB05513Nk1pAACAGaZtDgAAVTpGeoy3eMYZZ6Snnnoqrb322mm++ear9fwRRxzRmOUDAACmQdscAACqNJB+9dVXp+7du6cXXngh3yq1adNGYx0AAJqJtjkAAFRpIH3UqFFNUxIAAGCmaJsDAECVjpEOAAAAAABzk5nOSB8yZEjh89dcc83slAcAAJhB2uYAAFClgfTPP/+81uPJkyen119/PY0fPz5tttlmjVk2AACggLY5AABUaSD9jjvuqLds6tSp6eCDD07LLLNMY5ULAACYDm1zAABoQWOkt23bNh1zzDHpoosuaoy3AwAAZpG2OQAAVPFko2+//Xb67rvvGuvtAACAWaRtDgAAc3hol8huqVQqldLYsWPTfffdlwYPHtyYZQMAAApomwMAQJUG0l966aV6XUcXWmihdMEFF6QhQ4Y0ZtkAAIAC2uYAAFClgfRHH320aUoCAADMFG1zAACo0jHSR40ald566616y2PZ6NGjG6tcAADAdGibAwBAlQbS99133/T000/XW/7ss8/m5wAAgOahbQ4AAFUaSI9xGAcMGFBvef/+/dPLL7/cWOUCAACmQ9scAACqNJDepk2b9MUXX9RbPmHChDRlypTGKhcAADAd2uYAAFClgfSNN944DR06tFbDPO7Hsg033LCxywcAAEyDtjkAADSPdjP7gvPOOy832Jdffvm00UYb5WV//etf08SJE9MjjzzSFGUEAAAaoG0OAABVmpG+0korpVdffTXtvvvu6aOPPspdSffZZ5/0xhtvpFVWWaVpSgkAANSjbQ4AAFWakR769OmTzjnnnMYvDQAAMFO0zQEAoAoz0ocPH55uvfXWestj2e9///vGKhcAADAd2uYAAFClgfSYuKhnz571lvfq1UsmDAAANCNtcwAAqNJA+rvvvpv69u1bb/mSSy6ZnwMAAJqHtjkAAFRpID2yW2JCo7peeeWVtOCCCzZWuQAAgOnQNgcAgCoNpA8aNCgdccQR6dFHH01TpkzJt0ceeSQdeeSRac8992yaUgIAAPVomwMAQPNoN7MvOPPMM9Po0aPT5ptvntq1+9+XT506Ne2zzz7p7LPPbooyAgAADdA2BwCAKg2kd+jQId1yyy3prLPOSi+//HLq3LlzWnXVVfM4jAAAQPPRNgcAgCoNpJf169cv38LEiRPT5Zdfnq6++ur0t7/9rTHLBwAATIe2OQAAVGkgPcRYjNdcc026/fbbU7du3dLOO+/ceCUDAABmmLY5AABUUSD9/fffT9dee20aPnx4Gj9+fPr888/TjTfemHbffffUpk2bpiklAABQj7Y5AAA0j7YzuuJtt92Wtt1227T88svn8RcvuOCC9MEHH6S2bdvmcRg11AEAoHlomwMAQJVmpO+xxx7phBNOyJMZdenSpWlLBQAATJO2OQAAVGlG+v77758uvfTStPXWW6crrrgidxsFAACan7Y5AABUaSD9yiuvTGPHjk0HHnhguummm9IiiyySdtppp1QqldLUqVObtpQAAEANbXMAAKjSQHro3LlzGjx4cHr88cfTa6+9llZeeeXUu3fvNGDAgLTXXnul22+/velKCgAA1NA2BwCAKg2kV+rXr18655xz0pgxY9If/vCH9PXXX6dBgwY1bukAAIDp0jYHAIAqmWx0Wtq2bZt22GGHfPvoo48ap1QAAMBM0zYHAIAqy0hvSK9evRrz7QAAgFmkbQ4AAFUaSAcAAAAAgNZGIB0AAAAAAAoIpAMAAAAAQGMG0pdeeun06aef1ls+fvz4/BwAANA8tM0BAKBKA+mjR49OU6ZMqbd80qRJ6f3332+scgEAANOhbQ4AAM2j3YyuePfdd9fcf+CBB1K3bt1qHkfjfcSIEWmppZZKTencc89NJ554YjryyCPTxRdfnJd988036dhjj00333xz/sGw1VZbpcsuuyz17t27ScsCAABzirY5AABUaSB94MCB+f82bdqkwYMH13quffv2uaF+wQUXpKby/PPPpyuvvDKtttpqtZYfffTR6b777ku33npr/gFx2GGHpV122SU99dRTTVYWAACYk7TNAQCgSgPpU6dOzf/37ds3N5x79uyZmsuXX36Z9t577zRs2LB01lln1SyfMGFCuvrqq9ONN96YNttss7xs+PDhacUVV0zPPPNM6t+/f7OVEQAAmou2OQAAVPkY6aNGjarXUI/JjJrSoYcemrbbbru0xRZb1Fr+wgsvpMmTJ9davsIKK6QlllgijRw5cprvF91MJ06cWOsGAAAtTUtvm2uXAwDQagPp5513XrrllltqHu+2226pR48eadFFF02vvPJKY5cvj6/44osvpqFDh9Z7bty4calDhw6pe/futZbHGIzx3LTEe0VX0/Jt8cUXb/RyAwBAU2vpbXPtcgAAWm0g/Yorrqhp4D700EPp4YcfTvfff3/aZptt0vHHH9+ohRszZkyevOiGG25InTp1arT3jUmRoutp+RafAwAALU1Lb5trlwMA0OrGSC+LbJJyY/3ee+9Nu+++e9pyyy3zhEbf+973GrVw0T30o48+SmuttVbNsilTpqQnnngi/fa3v00PPPBA+vbbb3P31crMlw8//DAtvPDC03zfjh075hsAALRkLb1trl0OAECrzUhfYIEFajJFItulPAZiqVTKDenGtPnmm6fXXnstvfzyyzW3ddZZJ09uVL7fvn37NGLEiJrXvPnmm+ndd99N66+/fqOWBQAAqo22OQAAVGlG+i677JL22muv1K9fv/Tpp5/mbqPhpZdeSssuu2yjFq5Lly5plVVWqbVsvvnmSwsuuGDN8v333z8dc8wxeSzIrl27psMPPzw31Pv379+oZQEAgGqjbQ4AAFUaSL/oootyV9HIfDn//PPT/PPPn5ePHTs2HXLIIU1RxumWp23btmnXXXdNkyZNSltttVW67LLLmr0cAADQ3LTNAQCgSgPp0V3zuOOOq7f86KOPTs3hscceq/U4Jjq69NJL8w0AAOYm2uYAAFClY6SH66+/Pm244YapT58+6Z133snLLr744nTXXXc1dvkAAIAC2uYAAFCFgfTLL788j3sY4y+OHz++ZhKj7t275wY7AADQPLTNAQCgSgPpl1xySRo2bFj6xS9+keaZZ56a5euss0567bXXGrt8AADANGibAwBAlQbSR40aldZcc816yzt27Ji++uqrxioXAAAwHdrmAABQpYH0vn37ppdffrne8vvvvz+tuOKKjVUuAABgOrTNAQCgebSb0RXPOOOMdNxxx+UxGA899ND0zTffpFKplJ577rl00003paFDh6arrrqqaUsLAABomwMAQLUG0k8//fR00EEHpZ/85Cepc+fO6aSTTkpff/112muvvVKfPn3Sr3/967Tnnns2bWkBAABtcwAAqNZAemS4lO299975Fo31L7/8MvXq1aupygcAANShbQ4AAFUaSA9t2rSp9XjeeefNNwAAoHlpmwMAQJUG0pdbbrl6Dfa6Pvvss9ktEwAAMB3a5gAAUKWB9BiLsVu3bk1XGgAAYIZomwMAQJUG0mPCImMuAgDAnKdtDgAAzaftjK44vW6jAABA89A2BwCAKg2kl0qlpi0JAAAwQ7TNAQCgSod2mTp1atOWBAAAmCHa5gAAUKUZ6QAAAAAAMDcSSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0AAAAAAAoIJAOAAAAAAAFBNIBAAAAAKCAQDoAAAAAABQQSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0AAAAAAAoIJAOAAAAAAAFBNIBAAAAAKCAQDoAAAAAABQQSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0AAAAAAAoIJAOAAAAAAAFBNIBAAAAAKCAQDoAAAAAABQQSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0AAAAAAAoIJAOAAAAAAAFBNIBAAAAAKCAQDoAAAAAABQQSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0AAAAAAAoIJAOAAAAAAAFBNIBAAAAAKCAQDoAAAAAABQQSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0AAAAAAAoIJAOAAAAAAAFBNIBAAAAAKCAQDoAAAAAABQQSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0AAAAAAAoIJAOAAAAAAAFBNIBAAAAAKCAQDoAAAAAABQQSAcAAAAAgJYaSB86dGhad911U5cuXVKvXr3SwIED05tvvllrnW+++SYdeuihacEFF0zzzz9/2nXXXdOHH344x8oMAACtkbY5AABzs6oOpD/++OO5If7MM8+khx56KE2ePDltueWW6auvvqpZ5+ijj0733HNPuvXWW/P6H3zwQdpll13maLkBAKC10TYHAGBu1i5Vsfvvv7/W42uvvTZnv7zwwgtp4403ThMmTEhXX311uvHGG9Nmm22W1xk+fHhaccUVcwO/f//+c6jkAADQumibAwAwN6vqjPS6onEeevTokf+PRntkwmyxxRY166ywwgppiSWWSCNHjpzm+0yaNClNnDix1g0AAGjetrl2OQAALUWLCaRPnTo1HXXUUWnAgAFplVVWycvGjRuXOnTokLp3715r3d69e+fnisZ37NatW81t8cUXb/LyAwBAa9FYbXPtcgAAWooWE0iP8Rhff/31dPPNN8/2e5144ok5g6Z8GzNmTKOUEQAA5gaN1TbXLgcAoKWo6jHSyw477LB07733pieeeCIttthiNcsXXnjh9O2336bx48fXynz58MMP83PT0rFjx3wDAADmXNtcuxwAgJaiqjPSS6VSbqjfcccd6ZFHHkl9+/at9fzaa6+d2rdvn0aMGFGz7M0330zvvvtuWn/99edAiQEAoHXSNgcAYG7Wrtq7jN54443prrvuSl26dKkZWzHGT+zcuXP+f//990/HHHNMnuSoa9eu6fDDD88N9f79+8/p4gMAQKuhbQ4AwNysqgPpl19+ef5/0003rbV8+PDhad999833L7rootS2bdu06667pkmTJqWtttoqXXbZZXOkvAAA0FppmwMAMDdrV+3dR6enU6dO6dJLL803AACgaWibAwAwN6vqMdIBAAAAAGBOE0gHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAAAUEEgHAAAAAIACAukAAAAAAFBAIB0AAAAAAAoIpAMAAAAAQAGBdAAAAAAAKCCQDgAAAAAABQTSAQAAAACggEA6AAAAAADMDYH0Sy+9NC211FKpU6dO6Xvf+1567rnn5nSRAABgrqRtDgBAa9MqAum33HJLOuaYY9Kpp56aXnzxxbT66qunrbbaKn300UdzumgAADBX0TYHAKA1ahWB9AsvvDAdcMABab/99ksrrbRSuuKKK9K8886brrnmmjldNAAAmKtomwMA0Bq1+ED6t99+m1544YW0xRZb1Cxr27Ztfjxy5Mg5WjYAAJibaJsDANBatUst3CeffJKmTJmSevfuXWt5PH7jjTcafM2kSZPyrWzChAn5/4kTJ6bmNnXS183+mdAY5kR9mVXqGS2Vegatt56VP7dUKqXWZGbb5tXULg+OZbRELam9ENQzWiL1DJpeS2iXt/hA+qwYOnRoOv300+stX3zxxedIeaAl6nbxnC4BtH7qGbT+evbFF1+kbt26pbmVdjm0/OMYzA3UM2h6LaFd3uID6T179kzzzDNP+vDDD2stj8cLL7xwg6858cQT8wRIZVOnTk2fffZZWnDBBVObNm2avMw0z9Wk+AE2ZsyY1LVr1zldHGi11DVoeupZ6xQZL9FY79OnT2pNZrZtrl0+d3Acg6annkHTU89ap5lpl7f4QHqHDh3S2muvnUaMGJEGDhxY0wCPx4cddliDr+nYsWO+VerevXuzlJfmFQc2BzdoeuoaND31rPVpjZnoM9s21y6fuziOQdNTz6DpqWdzb7u8xQfSQ2SxDB48OK2zzjppvfXWSxdffHH66quv0n777TeniwYAAHMVbXMAAFqjVhFI32OPPdLHH3+cTjnllDRu3Li0xhprpPvvv7/eJEcAAEDT0jYHAKA1ahWB9BBdRac1lAtzn+gifOqpp9brKgw0LnUNmp56RkukbU4lxzFoeuoZND31jDalGFEdAAAAAABoUNuGFwMAAAAAAEEgHQAAAAAACgikAwAAMNMee+yx1KZNmzR+/Phm/+x99903DRw4sNk/Fxrb7373u7T44ountm3bposvvnhOFyeddtppeZJoaI2WWmqpRq9n1157berevXuqdqNHj87n7JdffnmGX7Ppppumo446qknL1dIIpNNinHvuubnSV1bib775Jh166KFpwQUXTPPPP3/adddd04cffljrde+++27abrvt0rzzzpt69eqVjj/++PTdd9/V+xGw1lpr5Qkjll122XwghLnB0KFD07rrrpu6dOmS60f8IH3zzTdrraOeweyZMmVKOvnkk1Pfvn1T586d0zLLLJPOPPPMVDlNTdw/5ZRT0iKLLJLX2WKLLdJbb71V630+++yztPfee6euXbvmxvr++++fvvzyy1rrvPrqq2mjjTZKnTp1yj/Kzz///GbbTmDOmlZgeU4Fu7/99tvUs2fP3IZvSBwHe/funSZPnjxLP/x//etfa0swR3388cfp4IMPTksssURu3y688MJpq622Sk899dQMv8fEiRPzxMwnnHBCev/999OBBx44Q4GrVVddNR100EENPnf99dfn8nzyySfT/fyoW3feeWetZccdd1waMWLEDG8Dc7c498R+VL7Fb8att946t0mb++LO119/nU488cTc1o628EILLZQ22WSTdNddd9Ws8/zzz+d6Vm1iG+P7i++url/+8pf5uTg2MOcJpNMixMHuyiuvTKuttlqt5UcffXS655570q233poef/zx9MEHH6RddtmlVvAignvRkH/66afT73//+9zgjmBF2ahRo/I63//+93MDPRotP/nJT9IDDzzQrNsIc0LUmwiSP/PMM+mhhx7KP2a33HLL9NVXX9Wso57B7DnvvPPS5Zdfnn7729+mf/7zn/lxBLgvueSSmnXi8W9+85t0xRVXpGeffTbNN998+cd4XMgqiyD63//+91xX77333vTEE0/U+iEQP8aj/i655JLphRdeyI3uaJRHphvA7Ihz/Mzq0KFD+tGPfpSGDx9e77m4eBhthX322Se1b99+lsrUrVu3FpEBSOsVySUvvfRSbvv+61//SnfffXcOdH366acz/B6RjBLt72gnx8X0SEqZEXEx/eabb07//e9/6z0XdW7HHXfMF7JmRSTORDAUZlQEf8eOHZtvcRGmXbt2afvtt2/2csTFpdtvvz23sd944410//33px/+8Ie16mQE12e0njW3OAY8+uij6b333qu1/JprrskX7KgSJahyX3zxRalfv36lhx56qLTJJpuUjjzyyLx8/Pjxpfbt25duvfXWmnX/+c9/RnpfaeTIkfnxn//851Lbtm1L48aNq1nn8ssvL3Xt2rU0adKk/PhnP/tZaeWVV671mXvssUdpq622aqYthOrx0Ucf5Tr0+OOP58fqGcy+7bbbrjRkyJBay3bZZZfS3nvvne9PnTq1tPDCC5d++ctf1jwfda9jx46lm266KT/+xz/+kevd888/X7POX/7yl1KbNm1K77//fn582WWXlRZYYIGaehdOOOGE0vLLL9/k2wjMeYMHDy7ttNNO9ZY/+uij+fjx+eef58effPJJac899yz16dOn1Llz59Iqq6xSuvHGG2u9Jtrchx56aG53L7jggqVNN900L7/vvvtyu7xTp0552fDhw2u9d12vvvpqfv6vf/1rg2WKNsWUKVNKp59+emnRRRctdejQobT66qvn41tZrFd5i7I1tL2x/PDDDy8df/zx+VjYu3fv0qmnnlrrc+PzBgwYkI+vK664Yv59Ee95xx13zMI3ztws9vnYdx577LHC9d55553SjjvuWJpvvvlKXbp0Ke222241beZy/am8xX5dd9moUaPqve/HH3+c68v1119fa/l//vOf3DYo16FoGyy99NK5Pb/ccsuVrrvuupp1l1xyyVqfE49D1Juoh2XluhbtlGiv9OjRo3TIIYeUvv3225p1Pvjgg9K2226bjw1LLbVU6YYbbsjvd9FFF83yd0zLPffEMT/2qfhtWfbuu+/m/b9bt275GB31onLfjvPCuuuuW5p33nnzOhtssEFp9OjRDdaTWNaQeN21115bWN66+2W837Bhw0oDBw7M58Rll122dNddd9V6TTyO5XHuiHNffEbluS/KE59d6c477yytueaa+TV9+/YtnXbaaaXJkydPs1zlerf99tuXzjrrrJrlTz31VKlnz56lgw8+uOb8F6Z37gzPPvtsaY011shlWHvttUu33357LvdLL71Us85rr71W2nrrrfMxqlevXqUf/ehH+fhSVhmD43/JSKfqRbZsXKGPbu6VItsurt5XLl9hhRXylbqRI0fmx/F/dHuLbqNlkeEXWXuR1Vdep+57xzrl94C5yYQJE/L/PXr0yP+rZzD7Nthgg5ydE9lq4ZVXXklPPvlk2mabbWp6bIwbN65WHYlMy+9973u16llkXq6zzjo168T6MZ5qZLCX19l4441zFmhlPYvhmj7//PNm216gukVPl7XXXjvdd9996fXXX889W3784x+n5557rtZ6kWUbx5MYpiJ6y4wZMyb3SNthhx1y77LoWfbzn/+88LOifRBDyEU2Xd2M2Tg2Rpsihmi54IIL0q9+9as8FEActyKbtjy8VblcDz/8cM52jGzDaYkyR4+eOC5GT58zzjgj9+Ip96CLoW8iEzGej946v/jFL2b5e2TuFlnbcYthUSZNmtTgOlOnTk077bRTHpotenXGvvif//wn7bHHHvn5+D/26/J+Hvt31If1118/HXDAATUZvjFUW12RbR7vXbduRU+PxRZbLPdQu+OOO9KRRx6Zjj322FzXf/rTn6b99tsvZ7yWe32X62N8TvlxQ+I1b7/9dv6/3Pu0cmil6F0SvVZjKKnbbrst16+PPvpolr5bWrYYdvAPf/hDHsqz3LMhfk/GsT2GE/3rX/+azytRfyKTPXo8xZCgcXyOYVjiPBBt2jg3xXAmUU9iH1555ZVr6kS5DtUVwyv9+c9/Tl988cVMlfn0009Pu+++e/7sbbfdNvcCjXpbbqdHVnuUL9rwUY+md+6IbYw6EfXvH//4Rx5dIerL2WefPd2yDBkypFbdijoe5als34fpnTvj7xC9AlZaaaX8mz56qcawTZViyLfNNtssrbnmmulvf/tbzuCPIVzju6DA/w+oQ1WKTLzIkvnvf/9b72pYXOWOK291xVXMyH4NBxxwQGnLLbes9fxXX32Vr8JFFm2IrJpzzjmn1jqRbRPrfP311022bVBt4qp2ZM5GplaZegaNU7ciMzwyxNq1a5f/r6wPkWkSdSGyuSpF1s7uu++e75999tk5k6yuhRZaKGebhR/84AelAw88sNbzf//73/N7R0Y70PqzAueZZ56cVVZ5iwzRoqzxEOf/Y489tuZxtLkjk67SiSeeWFpppZVqLYtj2/Te+4orrijNP//8uZdpmDhxYs44vOqqq/LjyIyPY1zddkZkvIbIWKybQTetjPQNN9yw3vtEGUNk6sUxeOzYsTXPy0hndvzpT3/KmbVRxyJ7NurIK6+8UvP8gw8+mOtkZOLWPS8/99xz+XHs13Wzzmc0A/T+++/PbYrIQi/3cIts25NOOik/jjJFO71u2yIyx8sa2v8bykiP9/3uu+9qvU/0Lq3srVrZa+6tt97Ky2Skz33nnvi7L7LIIqUXXnihZp3oORE9JGMfLYselJEB/sADD5Q+/fTTwh4edffJaYle1YsttljugbHOOuuUjjrqqNKTTz453Yz0cp0JX375ZV5Wzu6Oc0jEpCr94he/KMxI33zzzev99o3vIL6XaSlvY/T0iMzw2JYoS/RkieNKHBMqM9Knd+688sorc4+yciyt3Gu88nx65pln1vsdP2bMmLzOm2++mR/LSK9PRjpVK7Je4greDTfckCeKAJq+90dkq8R4i0Dj+eMf/5jPZTfeeGN68cUXcyZXZI/E/wCNqTwXSeXtqquuqrVOZGbHRJ+RLR490CIrMOYsibGaK0XWeqWY4yF6ylSKzNnpGTRoUP7MOBaGW265JfemiYzC6L0WWawDBgyo9Zp4HJ83s+rOpxTjzZazYqN3TmT2RsZi2XrrrTfTnwGVY6TH/htjo0dmbWRjr7XWWjXZpLEPxz5XmVEe2aHRw2xW9u+6fvCDH+Ts8/I8BNH7LepxZJ2XP7+x6lZkA88zzzzTrFsxJnZse1lkIy+wwAKzvG203HNP9K6I7OjoefnOO+/k5yOT+9///nfOSC/35ojzT/SQip4OcT8mLY3XRa+nyLaOzPOZFT0zo9dH1IXIIo/e0RtttFE+583ouSN6NXXt2rXW/h09qypN79wR2xs9osrbGrdyL5OYELVIzBtSnl8k5ihbbrnl6p3bZuTcGf/H6ypjaXXP2VHO6GVSWc7oKRbi70LDBNKpWtH9JA5ecUKOE3PcoktcTMYW92MYiegGFN1RKkVXlHIDOf6Px3WfLz9XtE4cPDt37tzEWwnV4bDDDsuTF8aJNBrkZVE/1DOYPccff3we/mDPPffMgasYQiEm8R06dGitetJQHamsQ3W7SEc32Oh2OjN1EWjdIgAQAazK26KLLlprnZiIOIIUJ5xwQj7vR+Ajghd1JxSN92oMca6PgEY52Bf/R7fx+MHe2OpOXBrDAsTwGtBUIkgVAe2TTz45Pf300zkYeOqppzbLZ8cFqfi8uDAf+3nUrQhoLr300o3+WeoWM3ruiaBzXMD96quv0rBhw2qGGYmLs3Uv9Mawh3vttVdeJ/bfGNIlhv2KC64RQH7mmWdmaV+N4Hmc4x588MEc0I5AetGk2Y29f8f2xnAxldv62muv5WFXZiRJNIZ3iSD6pZdemu83lShnebi2yluUMy5K0DCBdKrW5ptvng82lRU6xoaN8aHK9+OAF1cby+JqYVyFL19pi//jPSqDDzE2XTToIxugvE7le5TXmZEMG2jpojdbBNFjDMVHHnkk9e3bt9bz0eBRz2D2ROZJ/NitFFld5QZ61LsIdFfWkcg0iTF8K+tZXNCKi8xlUWfjPcoZorHOE088kcehrKxnyy+/vKwwoEaMTRtjK0fG2+qrr56DbuU5HIqsuOKK9cZRn9Egx/7775/nhoiL9hFsjMch2gp9+vTJZapbxnIbojwubGS1z444FkaP18oLjkVjQsOsiP02AojlOhP7XNzKYrzkOJ+X9++GxD4/o/t7ZJ/H+8fcAdGeL9et8ucX1a0Q7fzGqFtxcf+ll16qWRbZx+ZnmXtFIDravv/973/z40iOjOBsr1696l3sjXmBymKs7hNPPDGfJ1ZZZZXcm3Nm60Rdsb/H/hnZ77O6f8f44ZWmd+6I7Y3fzHW3NW51fxNMqwdI3KK3ePlCQ6UZOXdG/Y+x0yu3u+45O8oZWftLLbVUvXI21sX01kggnaoV3X7i4Fl5i8ocE1bE/TjgRkPhmGOOydk0EVyIhkQEEvr375/fIyZZiQNJZP9Ft5XotnrSSSflISw6duyY1znooINy95+f/exn6Y033kiXXXZZ7noa2YLQ2kVdiMlgopESdS4mPIxbudGjnsHsi0yPmFwoJvYbPXp0/qF74YUXpp133rnmx8ZRRx2VzjrrrNw9PC5MxQRF0UCOiY3KjeHoNh7dQiOQFQ3luAgWWe6xXoiGdvzQiDobjeLI5oms06i/AGX9+vXLF9kiUBFdv2PitLq9WRoS5/IIhEQvmwgQRNuhckK0IpHZFj/M49gW3cYj47As3u+8887Lx6x43+jBE0kzMcRjiMBL9F4rT4JWnhh9ZkXW8DLLLJMGDx6cgwtxHI32Svk4DDPj008/zZP0RTs69qeYkDAySGOS27hQVZ4UPHqiRSJYDO0W5++oAzGhYuXk4XVFUCsupkeb4ZNPPinMjI2L8VGOmJgx2t0xIXBl3Yo6evnll+e6G22PCLhXTjgYnxUX8qP9P6uB76jTsa1RhtjGCKjH/ai36tbcISbcLf+OjPPK4YcfXpPtHKIOlCfIjYk4o77EUEhHHHFEeu+99/LjCKBHRnoMBxOZ5LHPRvu3vJ/GOnFuiDoxrQl+N9100zyxZ/xmjfoTE4/+z//8T+6pEcHnWRHnyPj9GhnucdE5fsOWz33T2r9POeWUdN111+Ws9GiTx3cSw6eWzzkzIhJmYiiYGAqqIdM7d8bvgihf/HaIC3jxXcTQkpXi93r0bo0h2OLiQAznEr/l4/f+7F5ga9UaGDcdqlbdiQ5i4oSYTCEmeYlJi3beeedaEwiF0aNHl7bZZps8kUXPnj3zREqTJ0+utc6jjz5aWmONNfKkiksvvXSeLALmBnEaaOhWWQfUM5g9MbFenLuWWGKJPCFZ7P8xSVFMslQWky+dfPLJpd69e5c6duyYJykqT/JTFhMxDRo0KE/a17Vr19J+++1XM3lfWUxGFJPtxXssuuiipXPPPbfZthOYs+pOvll5/q2cFC2OJbFeHEtiQrOYZG2fffapN3FnQ5OL3XPPPaVll102H2M22mij0jXXXDPdyUbLYuK1WPf888+vNyHzaaedlo9ZMUFcTLZWnuStbNiwYaXFF1+81LZt25rJ1hqabLRumeP5WK8sJkWMSdWjLbLCCivk7YkyxaSNMDO++eab0s9//vPSWmutlScZjDZyTKYY9enrr7+uWe+dd94p7bjjjnkSxpg0MCbpHDduXM3zDU02Guf//v3753Z13ecacuONN+b1ypMMVooJyaPdEXUrJi2/7rrraj1/99135zodE/HGJIzTmmy07rGl7sSHMWF6/BaIY0O8T5Qpji8x2TCtW+wflb8jYz+PSS9jMt5K8fsxzjXxWzH2k9gvYzLcCRMm5DoxcODAPBlnHJ9jHzrllFPy+aFc33bddddS9+7d6/1WrXueWX/99Us9evSoaXMfccQRpU8++aRwstG6E+5Gna78jLvuuqvm3LfpppvWTNpZnsiz7mSjIc4rMeFv1ONot6+33nql3/3ud9P8Hqc3oWrdOjcj586RI0fm5fGdxu/w2267rd7k3f/617/y7/v4bqOscW6MSVrLE8OabLS+NvHPnA7mAwAAQHOKrPQNN9wwD0MR2epA44gs45hk9eGHH85DtkJrEj1Nr7jiilrDNjH3aDenCwAAAABNLYbWiklOY3ibCJ5HF/gBAwYIosNsimEoYiiPGMomhqOI4RxjOA4TFtIaxLCkMYlqDDMcF2Bj0u4YYpG5k0A6AAAArd4XX3yRx7mNSdNjvN4Y1/mCCy6Y08WCFi8mOo+xqGNOpJh3KeZBuOGGG/JkptDSxXjtMZdRjCe+xBJLpGOPPTaP6c7cydAuAAAAAABQoG3RkwAAAAAAMLcTSAcAAAAAgAIC6QAAAAAAUEAgHQAAAAAACgikAwAAAABAAYF0gFk0evTo1KZNm/Tyyy+navHGG2+k/v37p06dOqU11lij2T53qaWWShdffPEMr//YY4/l7278+PFpbrbvvvumgQMHzuliAAAAANMhkA606CBkBGPPPffcWsvvvPPOvHxudOqpp6b55psvvfnmm2nEiBH1no/vpeh22mmnzdLnPv/88+nAAw+c4fU32GCDNHbs2NStW7fU1IYNG5ZWX331NP/886fu3bunNddcMw0dOrTJPxcAAABoPdrN6QIAzI7IvD7vvPPST3/607TAAguk1uDbb79NHTp0mKXXvv3222m77bZLSy65ZIPPR/C67JZbbkmnnHJKDrqXRbC5rFQqpSlTpqR27aZ/qlhooYVmqpyxfQsvvHBqatdcc0066qij0m9+85u0ySabpEmTJqVXX301vf76603+2QAAAEDrISMdaNG22GKLHJAtyjCOLOu6w5zEMCQxHEndITbOOeec1Lt375y5fMYZZ6TvvvsuHX/88alHjx5pscUWS8OHD29wOJXIsI6g/iqrrJIef/zxWs9H0HabbbbJQep47x//+Mfpk08+qXl+0003TYcddlgO+Pbs2TNttdVWDW7H1KlTc5miHB07dszbdP/999c8HxnlL7zwQl5nWtnl8V2Vb5ENHuuVH8d2dOnSJf3lL39Ja6+9dv6MJ598Mgfnd9ppp1z22IZ11103Pfzww4VDu8T7XnXVVWnnnXdO8847b+rXr1+6++67pzm0y7XXXpu/8wceeCCtuOKK+XO23nrrWoH/+FscccQReb0FF1wwnXDCCWnw4MGFQ6PEZ+6+++5p//33T8suu2xaeeWV06BBg9LZZ59dK5v+Bz/4Qf7u4zuJgPuLL75Y632irFdeeWXafvvt8/ZEGUeOHJn+/e9/579f9AKIfSC+q7r7Xbxu8cUXz6+LskyYMGGa5Y2/cezLffv2TZ07d86Z9H/6059qnv/888/T3nvvnS9cxPPxvTa0TwIAAACNSyAdaNHmmWeeHPy+5JJL0nvvvTdb7/XII4+kDz74ID3xxBPpwgsvzMOkROA0Mt2fffbZdNBBB+XM97qfE4H2Y489Nr300ktp/fXXTzvssEP69NNP83MRKN5ss83ycCJ/+9vfcuD7ww8/zAHVSr///e9zlvZTTz2VrrjiigbL9+tf/zpdcMEF6Ve/+lXOqo6A+4477pjeeuut/HwEnSNQHGWJ+8cdd9wsfQ8///nP83A5//znP9Nqq62Wvvzyy7TtttvmoWJiGyPAHdv47rvvFr7P6aefnrczyhqvjwDwZ599Ns31v/7667xt119/ff4bxPtXbkP0PLjhhhty4Di+p4kTJ+ZhfIrEBYJnnnkmvfPOO9Nc54svvsgB+bhoEOtGcDrKG8srnXnmmWmfffbJY+KvsMIKaa+99sr7w4knnpj/tpHBHxdEKkWg/Y9//GO655578t8+vr9DDjlkmmWJIPp1112X94G///3v6eijj04/+tGPai7OnHzyyekf//hHvtgRf5/LL788XwAAAAAAmlgJoIUaPHhwaaeddsr3+/fvXxoyZEi+f8cdd5QqD2+nnnpqafXVV6/12osuuqi05JJL1nqveDxlypSaZcsvv3xpo402qnn83Xffleabb77STTfdlB+PGjUqf865555bs87kyZNLiy22WOm8887Lj88888zSlltuWeuzx4wZk1/35ptv5sebbLJJac0115zu9vbp06d09tln11q27rrrlg455JCax7Gdsb0zYvjw4aVu3brVPH700Udzue68887pvnbllVcuXXLJJTWP47uL77Qs3uekk06qefzll1/mZX/5y19qfdbnn39eU5Z4/O9//7vmNZdeemmpd+/eNY/j/i9/+ctaf48llliiZh9oyAcffJD3jXjv5ZZbLv+db7nlllp/57riuS5dupTuueeeaW7PyJEj87Krr766ZlnsF506dap5HH+HeeaZp/Tee+/VLIvtb9u2bWns2LH19uFvvvmmNO+885aefvrpWuXZf//9S4MGDcr3d9hhh9J+++03zbIDAAAATUNGOtAqRLZyZHVHlu6simzutm3/77AYQ5msuuqqtbLfY0iRjz76qNbrIgu9LMYTX2eddWrK8corr6RHH300D1VSvkU2c6gcBiSGUikS2deRLT9gwIBay+Px7GxzQ6L8lSIjPTLDYziTGFYltiE+c3oZ6ZHNXhZDn3Tt2rXed1cphj5ZZpllah4vssgiNevHcCiRyb/eeuvV+ntM73uL94ghWF577bV05JFH5uFhIvs8supjGJUQ73vAAQfkTPQY2iXKGdtcd/sqtyf2jVC5f8Syb775Jv+typZYYom06KKL1tpX4nMrx6WvzF6PrPwYZqZyf4kM9fK+cvDBB6ebb745Dxnzs5/9LD399NOF2w8AAAA0DpONAq3CxhtvnIc6iWE2YrzzShEc/9+k4v8zefLkeu/Rvn37euNiN7SsHICdERGQjWFQItDfUJC3MtBcLeqWJYLoDz30UB52JcYZj7G5f/jDH+ZJUYvM7HfX0Pp1/26zKsauj1sMqxJD9Gy00UZ5uJTvf//7ObAeQ/HE0DkxSWuMDR8B77rbV1m+KNu0ls3M/lF3Xwn33XdfreB7iDKFGGs/hqn585//nP8mm2++eTr00EPz3wYAAABoOjLSgVYjxvWOsagjA7lSTMw4bty4WkHZGOe6scS42mWR8RwTfkb2dlhrrbXyWNcxGWcEoStvMxM8jyzpPn365LHBK8XjlVZaKTWl+Iy4OBETh0YGdow7Pnr06NScIlM8Mr5jYtCyKVOm1JsUdEaUv6+vvvqqZvtiEtMYFz16JUTQunIy2NkRWe3Rk6ByX4kLO8svv3yD5YrPjtfU3VdistLK/TmC/3/4wx/yBK+/+93vGqWsAAAAwLTJSAdajQjyxoSWv/nNb2ot33TTTdPHH3+czj///JxJHZM+xmSNEZxuDJdeemkeFiSC5xdddFH6/PPP05AhQ/JzkS08bNiwNGjQoDwUR48ePfIQHjE8x1VXXZWHJ5lRMalpTIAaw5/E0B4x6WZcEIgJOJtSbNvtt9+eM+sj6zomvJzVrOvZcfjhh+fJOCOwHMPjxASz8V2XM8EbEkOhxAWImPB1scUWy5OwnnXWWTkYXR6SJ7YvJjiNIW1iWJb4niPrvjF06tQpB70jYzzeOwL2MQFrXIyoq0uXLjn7PyYYje93ww03zEPaRKA/9tV4n1NOOSUPZxMB/0mTJqV777235qINAAAA0HRkpAOtyhlnnFEvyBuBxssuuywHvFdfffX03HPP5YBlY2bCxy3e+8knn0x333136tmzZ36unEUe2dNbbrllDvYfddRReazxyvHYZ0QEYY855ph07LHH5veJCwLxWREIbkoXXnhhWmCBBdIGG2yQg+kxhE5k2je3E044IV+Q2GeffXIQPMYPj7JEsHpatthii5wFvttuu6Xlllsu7brrrnn9ESNG5PHuw9VXX50D8rFNP/7xj/P33KtXr0YpcwT9d9lll5ztHn//GGc99sVpOfPMM/OFirhgEPttjOUeQ7307ds3P9+hQ4c8fFG8TwxnFBdi4qIMAAAA0LTaxIyjTfwZANDo4oJJBJsjwzsC0NXmtNNOS3feeWejDiMEAAAAzBmGdgGgRYhJNh988MG0ySab5GFNfvvb36ZRo0alvfbaa04XDQAAAGjlDO0CQIsQQ+Fce+21ad11100DBgxIr732Wnr44YeNEQ4AAAA0OUO7AAAAAABAARnpAAAAAABQQCAdAAAAAAAKCKQDAAAAAEABgXQAAAAAACggkA4AAAAAAAUE0gEAAAAAoIBAOgAAAAAAFBBIBwAAAACAAgLpAAAAAACQpu3/AX9NVqlmOjmHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations\n",
    "\n",
    "# 1. Plot test accuracies\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Architecture comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "arch_names = list(architecture_results.keys())\n",
    "arch_accs = [architecture_results[n]['test_accuracy'] for n in arch_names]\n",
    "plt.bar(arch_names, arch_accs)\n",
    "plt.title('Architecture Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Augmentation comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "aug_names = [name.split('_')[1] for name in augmentation_results.keys()]\n",
    "aug_accs = [augmentation_results[name]['test_accuracy'] for name in augmentation_results.keys()]\n",
    "plt.bar(aug_names, aug_accs)\n",
    "plt.title('Data Augmentation Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Reduced training set size\n",
    "plt.subplot(2, 2, 3)\n",
    "sizes = [name.split('_')[-1] for name in reduction_results.keys()]\n",
    "size_accs = [reduction_results[name]['test_accuracy'] for name in reduction_results.keys()]\n",
    "# Add the full dataset result\n",
    "sizes.append(str(TRAIN_SUBSET_SIZE))\n",
    "size_accs.append(all_results['Architecture_efficientnet']['test_accuracy'])\n",
    "plt.bar(sizes, size_accs)\n",
    "plt.title('Reduced Training Set Size')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Ensemble comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Hard Voting', 'Soft Voting', 'Best Single Model']\n",
    "accuracies = [\n",
    "    ensemble_results['hard_voting']['accuracy'],\n",
    "    ensemble_results['soft_voting']['accuracy'],\n",
    "    max([results['test_accuracy'] for name, results in all_results.items() if 'test_accuracy' in results])\n",
    "]\n",
    "plt.bar(methods, accuracies)\n",
    "plt.title('Ensemble Methods Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiment_results_summary.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment results saved to 'experiment_results.json'\n",
      "Summary visualizations saved to 'experiment_results_summary.png'\n",
      "Full results including model states saved to 'full_experiment_results.pkl'\n",
      "\n",
      "============================== EXPERIMENTS COMPLETED ==============================\n"
     ]
    }
   ],
   "source": [
    "# Save all results to file\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy arrays to lists for JSON serialization\n",
    "def convert_numpy_to_list(obj):\n",
    "    # Handle NumPy scalars (int64, float32, etc.)\n",
    "    if isinstance(obj, np.number):\n",
    "        return obj.item()  # Convert to native Python type\n",
    "    # Handle NumPy arrays\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    # Handle dictionaries\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_numpy_to_list(v) for k, v in obj.items()}\n",
    "    # Handle lists and tuples\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return [convert_numpy_to_list(item) for item in obj]\n",
    "    # Return other objects unchanged\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Convert all results\n",
    "serializable_results = convert_numpy_to_list(all_results)\n",
    "\n",
    "# Remove model states which can't be serialized easily\n",
    "for key in serializable_results:\n",
    "    if isinstance(serializable_results[key], dict) and 'model_state' in serializable_results[key]:\n",
    "        del serializable_results[key]['model_state']\n",
    "\n",
    "# Save as JSON for easy viewing\n",
    "with open('experiment_results.json', 'w') as f:\n",
    "    try:\n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "        print(\"\\nExperiment results saved to 'experiment_results.json'\")\n",
    "    except TypeError as e:\n",
    "        print(f\"Error saving JSON: {e}\")\n",
    "        print(\"Trying to identify problematic fields...\")\n",
    "        # Try to identify problematic fields\n",
    "        for key in serializable_results:\n",
    "            try:\n",
    "                json.dumps(serializable_results[key])\n",
    "            except TypeError as e:\n",
    "                print(f\"Problematic field: {key}, Error: {e}\")\n",
    "                # Try to remove or fix this field\n",
    "                if isinstance(serializable_results[key], dict):\n",
    "                    for subkey in list(serializable_results[key].keys()):\n",
    "                        try:\n",
    "                            json.dumps(serializable_results[key][subkey])\n",
    "                        except TypeError:\n",
    "                            print(f\"Removing problematic subfield: {key}.{subkey}\")\n",
    "                            serializable_results[key][subkey] = str(serializable_results[key][subkey])\n",
    "        \n",
    "        # Try again with the fixed data\n",
    "        try:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "            print(\"Successfully saved JSON after fixing problematic fields\")\n",
    "        except TypeError:\n",
    "            print(\"Could not save JSON, falling back to simple format\")\n",
    "            # Save in a simpler format\n",
    "            with open('experiment_results_simple.txt', 'w') as f:\n",
    "                for key, value in serializable_results.items():\n",
    "                    f.write(f\"{key}: {str(value)}\\n\")\n",
    "\n",
    "print(\"Summary visualizations saved to 'experiment_results_summary.png'\")\n",
    "\n",
    "# Save full results including model states with pickle\n",
    "try:\n",
    "    with open('full_experiment_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    print(\"Full results including model states saved to 'full_experiment_results.pkl'\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save full results with model states. Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \" EXPERIMENTS COMPLETED \" + \"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
