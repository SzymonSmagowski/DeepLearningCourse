{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "import copy\n",
    "from PIL import Image, ImageFilter\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a smaller subset of data for quicker experiments\n",
    "TRAIN_SUBSET_SIZE = 8000  # Reduced from 10000\n",
    "VALID_SUBSET_SIZE = 8000\n",
    "TEST_SUBSET_SIZE = 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seeds for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tensor created on MPS successfully: mps:0\n",
      "MPS is working properly\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Function for checking device\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        try:\n",
    "            # Try creating a tensor on MPS\n",
    "            test_tensor = torch.zeros(1, device=\"mps\")\n",
    "            print(f\"Test tensor created on MPS successfully: {test_tensor.device}\")\n",
    "            print(\"MPS is working properly\")\n",
    "            return torch.device(\"mps\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing MPS: {e}\")\n",
    "    \n",
    "    print(\"Using CPU\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset subset function\n",
    "def create_subset_dataset(original_dataset, num_samples=10000, balanced=True):\n",
    "    \"\"\"\n",
    "    Create a subset of the original dataset with equal class distribution\n",
    "    \"\"\"\n",
    "    if balanced:\n",
    "        # Get class labels\n",
    "        targets = torch.tensor([target for _, target in original_dataset.samples])\n",
    "        classes = torch.unique(targets)\n",
    "        num_classes = len(classes)\n",
    "        samples_per_class = num_samples // num_classes\n",
    "        \n",
    "        indices = []\n",
    "        for cls in classes:\n",
    "            cls_indices = torch.where(targets == cls)[0]\n",
    "            # If we have fewer samples than requested, take all of them\n",
    "            if len(cls_indices) <= samples_per_class:\n",
    "                indices.extend(cls_indices.tolist())\n",
    "            else:\n",
    "                # Otherwise randomly sample\n",
    "                selected = cls_indices[torch.randperm(len(cls_indices))[:samples_per_class]]\n",
    "                indices.extend(selected.tolist())\n",
    "        \n",
    "        return Subset(original_dataset, indices)\n",
    "    else:\n",
    "        # Simple random subset\n",
    "        return Subset(original_dataset, torch.randperm(len(original_dataset))[:num_samples].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data augmentation techniques\n",
    "def cutout_transform(img, n_holes=1, length=16):\n",
    "    \"\"\"Apply cutout augmentation to a tensor image\"\"\"\n",
    "    h = img.size(1)\n",
    "    w = img.size(2)\n",
    "    \n",
    "    mask = torch.ones((h, w))\n",
    "    \n",
    "    for n in range(n_holes):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        \n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "        \n",
    "        mask[y1: y2, x1: x2] = 0.\n",
    "    \n",
    "    mask = mask.expand_as(img)\n",
    "    return img * mask\n",
    "\n",
    "class CutoutTransform:\n",
    "    \"\"\"Wrapper class for the cutout transform to use in torchvision transforms\"\"\"\n",
    "    def __init__(self, n_holes=1, length=16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return cutout_transform(img, self.n_holes, self.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries of transforms for our experiments\n",
    "standard_transforms = {\n",
    "    'baseline': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'horizontal_flip': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'rotation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'color_jitter': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'combined_standard': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Advanced augmentation with Cutout\n",
    "advanced_transforms = {\n",
    "    'cutout': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        CutoutTransform(n_holes=1, length=32)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original datasets...\n",
      "Creating subsets...\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Training samples: 8000\n",
      "Validation samples: 8000\n",
      "Test samples: 8000\n"
     ]
    }
   ],
   "source": [
    "# Load full datasets first\n",
    "print(\"Loading original datasets...\")\n",
    "full_train_dataset = ImageFolder(root='data/train', transform=standard_transforms['baseline'])\n",
    "full_valid_dataset = ImageFolder(root='data/valid', transform=standard_transforms['baseline'])\n",
    "full_test_dataset = ImageFolder(root='data/test', transform=standard_transforms['baseline'])\n",
    "\n",
    "# Create reduced subsets\n",
    "print(\"Creating subsets...\")\n",
    "train_dataset = create_subset_dataset(full_train_dataset, num_samples=TRAIN_SUBSET_SIZE)\n",
    "valid_dataset = create_subset_dataset(full_valid_dataset, num_samples=VALID_SUBSET_SIZE)\n",
    "test_dataset = create_subset_dataset(full_test_dataset, num_samples=TEST_SUBSET_SIZE)\n",
    "\n",
    "# Save class names\n",
    "class_names = full_train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(valid_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architectures\n",
    "def create_efficientnet_model(num_classes=10, pretrained=True):\n",
    "    \"\"\"Create EfficientNet B0 model\"\"\"\n",
    "    if pretrained:\n",
    "        weights = EfficientNet_B0_Weights.DEFAULT\n",
    "        model = efficientnet_b0(weights=weights)\n",
    "    else:\n",
    "        model = efficientnet_b0(weights=None)\n",
    "    \n",
    "    # Replace classifier\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=in_features, out_features=num_classes),\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom CNN as a third architecture option\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Third conv block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # Calculate input size to the classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False) as t:\n",
    "        for images, labels in t:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to conduct an experiment\n",
    "def run_experiment(experiment_name, model, train_dataset, valid_dataset, test_dataset, \n",
    "                  hyperparams, batch_size=64, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Run a full training experiment with given hyperparameters\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} Running experiment: {experiment_name} {'='*20}\")\n",
    "    for key, value in hyperparams.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    if hyperparams['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'], \n",
    "                              weight_decay=hyperparams['weight_decay'])\n",
    "    elif hyperparams['optimizer'] == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=hyperparams['learning_rate'], \n",
    "                             momentum=0.9, weight_decay=hyperparams['weight_decay'])\n",
    "    \n",
    "    # Initialize criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize scheduler\n",
    "    if hyperparams['scheduler'] == 'plateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    elif hyperparams['scheduler'] == 'cosine':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    best_val_acc = 0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train and validate\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        valid_loss, valid_acc = validate(model, valid_loader, criterion, device)\n",
    "        \n",
    "        # Scheduler step\n",
    "        if hyperparams['scheduler'] == 'plateau':\n",
    "            scheduler.step(valid_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if valid_acc > best_val_acc:\n",
    "            best_val_acc = valid_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time/60:.2f} minutes\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_acc, all_preds, all_labels = evaluate(model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'name': experiment_name,\n",
    "        'hyperparams': hyperparams,\n",
    "        'train_losses': train_losses,\n",
    "        'valid_losses': valid_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'valid_accuracies': valid_accuracies,\n",
    "        'test_accuracy': test_acc,\n",
    "        'confusion_matrix': cm,\n",
    "        'model_state': best_model_wts,\n",
    "        'all_preds': all_preds,\n",
    "        'all_labels': all_labels\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Few-shot learning implementation =======\n",
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "    \n",
    "    def forward(self, support_images, support_labels, query_images):\n",
    "        \"\"\"\n",
    "        Implements the forward pass of Prototypical Networks\n",
    "        \n",
    "        Args:\n",
    "            support_images: support set images [n_classes * n_shots, channels, height, width]\n",
    "            support_labels: support set labels [n_classes * n_shots]\n",
    "            query_images: query set images [n_queries, channels, height, width]\n",
    "        \n",
    "        Returns:\n",
    "            query_logits: classification logits for the query images\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        support_features = self.backbone(support_images)  # [n_classes * n_shots, feature_dim]\n",
    "        query_features = self.backbone(query_images)      # [n_queries, feature_dim]\n",
    "        \n",
    "        # Compute class prototypes\n",
    "        n_classes = len(torch.unique(support_labels))\n",
    "        prototypes = torch.zeros(n_classes, support_features.shape[1], device=support_features.device)\n",
    "        \n",
    "        for c in range(n_classes):\n",
    "            # Select features of class c\n",
    "            class_mask = (support_labels == c)\n",
    "            class_features = support_features[class_mask]\n",
    "            # Average features to get the prototype\n",
    "            prototypes[c] = class_features.mean(dim=0)\n",
    "        \n",
    "        # Compute distances between query features and prototypes\n",
    "        # Expand dimensions for broadcasting\n",
    "        query_features = query_features.unsqueeze(1)  # [n_queries, 1, feature_dim]\n",
    "        prototypes = prototypes.unsqueeze(0)          # [1, n_classes, feature_dim]\n",
    "        \n",
    "        # Compute Euclidean distances\n",
    "        distances = torch.sum((query_features - prototypes)**2, dim=2)\n",
    "        \n",
    "        # Convert distances to logits (negative distances)\n",
    "        return -distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_evaluation(backbone, test_dataset, device, n_way=5, n_shot=5, n_query=15, n_episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluates the backbone on few-shot classification tasks\n",
    "    \"\"\"\n",
    "    backbone.eval()\n",
    "    \n",
    "    # Function to create few-shot tasks\n",
    "    def create_episode(dataset, n_way, n_shot, n_query):\n",
    "        # Sample n_way classes\n",
    "        classes = random.sample(range(len(dataset.classes)), n_way)\n",
    "        \n",
    "        # Initialize tensors to store images and labels\n",
    "        support_images = []\n",
    "        support_labels = []\n",
    "        query_images = []\n",
    "        query_labels = []\n",
    "        \n",
    "        # For each class, sample n_shot and n_query examples\n",
    "        for i, cls in enumerate(classes):\n",
    "            # Get indices of all examples from this class\n",
    "            class_indices = [idx for idx, (_, label) in enumerate(dataset) if label == cls]\n",
    "            # Sample support and query sets\n",
    "            support_indices = random.sample(class_indices, n_shot)\n",
    "            remaining_indices = [idx for idx in class_indices if idx not in support_indices]\n",
    "            query_indices = random.sample(remaining_indices, min(n_query, len(remaining_indices)))\n",
    "            \n",
    "            # Add to support and query sets\n",
    "            for idx in support_indices:\n",
    "                image, _ = dataset[idx]\n",
    "                support_images.append(image)\n",
    "                support_labels.append(i)  # Use an index from 0 to n_way-1 as the label\n",
    "            \n",
    "            for idx in query_indices:\n",
    "                image, _ = dataset[idx]\n",
    "                query_images.append(image)\n",
    "                query_labels.append(i)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "        \n",
    "        return support_images, support_labels, query_images, query_labels\n",
    "    \n",
    "    # Create prototypical network\n",
    "    proto_net = PrototypicalNetworks(backbone).to(device)\n",
    "    \n",
    "    # List to store accuracies\n",
    "    accuracies = []\n",
    "    \n",
    "    # Evaluate over multiple episodes\n",
    "    for episode in tqdm(range(n_episodes), desc=\"Few-shot evaluation\"):\n",
    "        # Create an episode (task)\n",
    "        support_images, support_labels, query_images, query_labels = create_episode(\n",
    "            test_dataset, n_way, n_shot, n_query\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        support_images = support_images.to(device)\n",
    "        support_labels = support_labels.to(device)\n",
    "        query_images = query_images.to(device)\n",
    "        query_labels = query_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            query_logits = proto_net(support_images, support_labels, query_images)\n",
    "            _, query_preds = torch.max(query_logits, dim=1)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (query_preds == query_labels).float().mean().item() * 100\n",
    "            accuracies.append(accuracy)\n",
    "    \n",
    "    # Return average accuracy\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    \n",
    "    print(f\"Few-shot learning ({n_way}-way, {n_shot}-shot): {avg_accuracy:.2f}% Â± {std_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor for few-shot learning\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Use a pre-trained model but remove the final layer\n",
    "        self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        # Remove the classifier\n",
    "        self.features = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        # Add a flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement ensemble prediction\n",
    "def ensemble_prediction(models, test_loader, device, method='hard'):\n",
    "    \"\"\"\n",
    "    Implement ensemble prediction using multiple models\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained models\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Device to run on\n",
    "        method: 'hard' for majority voting or 'soft' for probability averaging\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Ensemble accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    if not models:\n",
    "        return 0.0, [], []\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                probabilities.append(probs.cpu())\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        all_probs.append(torch.cat(probabilities, dim=0).numpy())\n",
    "    \n",
    "    # Get true labels\n",
    "    true_labels = []\n",
    "    for _, labels in test_loader:\n",
    "        true_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Create ensemble predictions\n",
    "    if method == 'hard':\n",
    "        # Majority voting\n",
    "        ensemble_preds = []\n",
    "        for i in range(len(true_labels)):\n",
    "            votes = [all_predictions[j][i] for j in range(len(models))]\n",
    "            # Count occurrences of each class\n",
    "            vote_counts = np.bincount(votes, minlength=num_classes)\n",
    "            # Select class with most votes\n",
    "            ensemble_preds.append(np.argmax(vote_counts))\n",
    "    else:  # 'soft' voting\n",
    "        # Average probabilities\n",
    "        ensemble_probs = np.mean(all_probs, axis=0)\n",
    "        ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(ensemble_preds) == np.array(true_labels)) * 100\n",
    "    \n",
    "    return accuracy, ensemble_preds, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIGURATIONS\n",
    "# 1. Architecture Comparison (removed ResNet)\n",
    "architectures = {\n",
    "    'efficientnet': create_efficientnet_model(num_classes),\n",
    "    'custom_cnn': CustomCNN(num_classes)\n",
    "}\n",
    "\n",
    "# 2. Hyperparameter Configurations for Training Process\n",
    "training_hyperparams = [\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'sgd', 'learning_rate': 0.01, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'cosine', 'weight_decay': 0.0001}\n",
    "]\n",
    "\n",
    "# 3. Hyperparameter Configurations for Regularization\n",
    "regularization_hyperparams = [\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# 4. Data Augmentation Experiments\n",
    "# We'll use a modified version of the train_dataset for each transform\n",
    "augmentation_datasets = {}\n",
    "\n",
    "# Apply each transform to create new datasets\n",
    "for name, transform in standard_transforms.items():\n",
    "    augmentation_datasets[name] = ImageFolder(\n",
    "        root='data/train', \n",
    "        transform=transform\n",
    "    )\n",
    "    # Create a subset of the data\n",
    "    augmentation_datasets[name] = create_subset_dataset(augmentation_datasets[name], num_samples=TRAIN_SUBSET_SIZE)\n",
    "\n",
    "# Add advanced augmentation\n",
    "for name, transform in advanced_transforms.items():\n",
    "    augmentation_datasets[name] = ImageFolder(\n",
    "        root='data/train', \n",
    "        transform=transform\n",
    "    )\n",
    "    # Create a subset of the data\n",
    "    augmentation_datasets[name] = create_subset_dataset(augmentation_datasets[name], num_samples=TRAIN_SUBSET_SIZE)\n",
    "\n",
    "# Dictionary to store results of all experiments\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ARCHITECTURE COMPARISON ==============================\n",
      "\n",
      "Training efficientnet...\n",
      "\n",
      "==================== Running experiment: Architecture_efficientnet ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5628999800a41649067b3b51018938a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.9279 | Train Acc: 68.56%\n",
      "Valid Loss: 0.6850 | Valid Acc: 76.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ce7e33ecb84f629b9deb81c091feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.4403 | Train Acc: 84.61%\n",
      "Valid Loss: 0.7002 | Valid Acc: 76.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa3b69817da4ce18b0335db857bf95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.3044 | Train Acc: 89.42%\n",
      "Valid Loss: 0.7406 | Valid Acc: 77.71%\n",
      "Training completed in 3.67 minutes\n",
      "Test Accuracy: 78.67%\n",
      "\n",
      "Training custom_cnn...\n",
      "\n",
      "==================== Running experiment: Architecture_custom_cnn ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8038145db118458eb01ed4ecb10b57bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 2.1121 | Train Acc: 20.19%\n",
      "Valid Loss: 2.1781 | Valid Acc: 19.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616fe47b2736477bb72995393c6639f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 1.9828 | Train Acc: 23.55%\n",
      "Valid Loss: 1.9764 | Valid Acc: 24.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7b5a5aa6b446b4b9cb6f05540a5d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 1.9205 | Train Acc: 26.07%\n",
      "Valid Loss: 1.8664 | Valid Acc: 28.95%\n",
      "Training completed in 4.00 minutes\n",
      "Test Accuracy: 28.48%\n"
     ]
    }
   ],
   "source": [
    "# ==== RUN EXPERIMENTS ====\n",
    "# 1. Architecture Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" ARCHITECTURE COMPARISON \" + \"=\"*30)\n",
    "architecture_results = {}\n",
    "\n",
    "for arch_name, model in architectures.items():\n",
    "    print(f\"\\nTraining {arch_name}...\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    hyperparams = {\n",
    "        'optimizer': 'adam',\n",
    "        'learning_rate': 0.001,\n",
    "        'scheduler': 'plateau',\n",
    "        'weight_decay': 0.0001\n",
    "    }\n",
    "    \n",
    "    results = run_experiment(\n",
    "        f\"Architecture_{arch_name}\",\n",
    "        model, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,  # Larger batch size for faster training\n",
    "        num_epochs=3  # Further reduced epochs for faster comparison\n",
    "    )\n",
    "    \n",
    "    architecture_results[arch_name] = results\n",
    "    all_results[f\"Architecture_{arch_name}\"] = results\n",
    "    \n",
    "    # Save model state\n",
    "    torch.save(model.state_dict(), f\"{arch_name}_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TRAINING HYPERPARAMETERS COMPARISON ==============================\n",
      "Using best architecture: efficientnet\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_1 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d291227e85e4ff3a0c69c4cf1e8fb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.2789 | Train Acc: 90.33%\n",
      "Valid Loss: 0.7669 | Valid Acc: 77.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbcfa196ea14255ac0acdc8511908eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1761 | Train Acc: 94.04%\n",
      "Valid Loss: 0.8718 | Valid Acc: 77.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2086fb97febc4ed5852da980905b6220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1405 | Train Acc: 95.34%\n",
      "Valid Loss: 1.0005 | Valid Acc: 76.54%\n",
      "Training completed in 3.64 minutes\n",
      "Test Accuracy: 77.96%\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_2 ====================\n",
      "optimizer: sgd\n",
      "learning_rate: 0.01\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df95fb03c8549a99cf373c5875f546f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.010000\n",
      "Train Loss: 0.0840 | Train Acc: 97.38%\n",
      "Valid Loss: 0.7036 | Valid Acc: 81.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b688a2632054507928a7a3dae55f79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.010000\n",
      "Train Loss: 0.0436 | Train Acc: 98.76%\n",
      "Valid Loss: 0.7085 | Valid Acc: 81.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9d9a65f2014a7eb8448ddfd2de798f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.010000\n",
      "Train Loss: 0.0280 | Train Acc: 99.21%\n",
      "Valid Loss: 0.7164 | Valid Acc: 82.04%\n",
      "Training completed in 3.64 minutes\n",
      "Test Accuracy: 81.65%\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_3 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: cosine\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb86916d6df14cda9b869ea586ae368e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.000750\n",
      "Train Loss: 0.1856 | Train Acc: 93.92%\n",
      "Valid Loss: 0.8499 | Valid Acc: 77.79%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35843dd922d34dafb3903baa1a45b563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.000250\n",
      "Train Loss: 0.0929 | Train Acc: 97.03%\n",
      "Valid Loss: 0.8195 | Valid Acc: 80.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af152968d16c4a39bc6aba0fba2d6570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.000000\n",
      "Train Loss: 0.0386 | Train Acc: 98.89%\n",
      "Valid Loss: 0.7621 | Valid Acc: 81.89%\n",
      "Training completed in 3.62 minutes\n",
      "Test Accuracy: 81.79%\n"
     ]
    }
   ],
   "source": [
    "# 2. Training Hyperparameters Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" TRAINING HYPERPARAMETERS COMPARISON \" + \"=\"*30)\n",
    "training_results = {}\n",
    "\n",
    "# Use the best architecture from the previous experiment\n",
    "best_arch = max(architecture_results, key=lambda k: architecture_results[k]['test_accuracy'])\n",
    "print(f\"Using best architecture: {best_arch}\")\n",
    "\n",
    "for i, hyperparams in enumerate(training_hyperparams):\n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model = model.to(device)\n",
    "    \n",
    "    experiment_name = f\"Training_Hyperparams_{i+1}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    training_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== REGULARIZATION HYPERPARAMETERS COMPARISON ==============================\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_1 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171909ab275f4214947b7f417eb94230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.2837 | Train Acc: 89.97%\n",
      "Valid Loss: 0.7890 | Valid Acc: 77.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13ad5065a494d32bee3fb6bc05cc95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1899 | Train Acc: 93.56%\n",
      "Valid Loss: 0.8499 | Valid Acc: 76.26%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6772b6657013465ea08dcb1bb40b3142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1632 | Train Acc: 94.66%\n",
      "Valid Loss: 0.9644 | Valid Acc: 76.46%\n",
      "Training completed in 3.04 minutes\n",
      "Test Accuracy: 77.79%\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_2 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3287e600b93b4e8d83f7a6b4f3a0ce6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Regularization Hyperparameters Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" REGULARIZATION HYPERPARAMETERS COMPARISON \" + \"=\"*30)\n",
    "regularization_results = {}\n",
    "\n",
    "for i, hyperparams in enumerate(regularization_hyperparams):\n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model = model.to(device)\n",
    "    \n",
    "    experiment_name = f\"Regularization_Hyperparams_{i+1}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    regularization_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== DATA AUGMENTATION COMPARISON ==============================\n",
      "\n",
      "Testing standard augmentation: baseline\n",
      "\n",
      "==================== Running experiment: Augmentation_baseline ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b72bd9cc06b49e98a60983ed7b6ebe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6271 | Train Acc: 79.83%\n",
      "Valid Loss: 0.5596 | Valid Acc: 80.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47fda125d91464190d68a0e74480163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.2833 | Train Acc: 90.66%\n",
      "Valid Loss: 0.6234 | Valid Acc: 79.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5059eab3e5498c8148447f15c620d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1711 | Train Acc: 94.10%\n",
      "Valid Loss: 0.7159 | Valid Acc: 79.97%\n",
      "Training completed in 3.65 minutes\n",
      "Test Accuracy: 79.97%\n",
      "\n",
      "Testing standard augmentation: horizontal_flip\n",
      "\n",
      "==================== Running experiment: Augmentation_horizontal_flip ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb9eb6b307c4da584868b96b1611b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5946 | Train Acc: 79.95%\n",
      "Valid Loss: 0.5288 | Valid Acc: 81.36%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a3a266251d4e529798731a999bd3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3255 | Train Acc: 88.34%\n",
      "Valid Loss: 0.6226 | Valid Acc: 79.64%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5088614b8e6b4c80ad86e2f8da0ff1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2498 | Train Acc: 91.33%\n",
      "Valid Loss: 0.6889 | Valid Acc: 79.74%\n",
      "Training completed in 3.61 minutes\n",
      "Test Accuracy: 81.31%\n",
      "\n",
      "Testing standard augmentation: rotation\n",
      "\n",
      "==================== Running experiment: Augmentation_rotation ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c365757577435c9c6a0839f89c5299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6151 | Train Acc: 78.47%\n",
      "Valid Loss: 0.5297 | Valid Acc: 81.31%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14f26330f314b148d4f2061ec98ea76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3593 | Train Acc: 87.11%\n",
      "Valid Loss: 0.5764 | Valid Acc: 80.91%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd579cffa6249c1bb0ec6306ff32c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2685 | Train Acc: 90.42%\n",
      "Valid Loss: 0.6821 | Valid Acc: 79.61%\n",
      "Training completed in 3.63 minutes\n",
      "Test Accuracy: 81.64%\n",
      "\n",
      "Testing standard augmentation: color_jitter\n",
      "\n",
      "==================== Running experiment: Augmentation_color_jitter ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27236d3ff6c4f4a9e8d692ee9d8790c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5929 | Train Acc: 79.61%\n",
      "Valid Loss: 0.5431 | Valid Acc: 81.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5c4c3cb66b4eb8b11c7a2f6ad28bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3470 | Train Acc: 87.94%\n",
      "Valid Loss: 0.5692 | Valid Acc: 81.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aaaeefe88544aca3b71f50ad99c73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2310 | Train Acc: 92.05%\n",
      "Valid Loss: 0.7042 | Valid Acc: 79.19%\n",
      "Training completed in 3.64 minutes\n",
      "Test Accuracy: 80.99%\n"
     ]
    }
   ],
   "source": [
    "# This code contains the completion of the comprehensive experiments\n",
    "\n",
    "# 4. Data Augmentation Experiments\n",
    "print(\"\\n\" + \"=\"*30 + \" DATA AUGMENTATION COMPARISON \" + \"=\"*30)\n",
    "augmentation_results = {}\n",
    "\n",
    "# Create a new model with the best architecture\n",
    "best_arch = 'efficientnet'  # Default to efficientnet since we removed resnet\n",
    "model = architectures[best_arch]\n",
    "model = model.to(device)\n",
    "\n",
    "# Baseline hyperparameters\n",
    "hyperparams = {\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 0.001,\n",
    "    'scheduler': 'plateau',\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "# Standard augmentations\n",
    "for aug_name in ['baseline', 'horizontal_flip', 'rotation', 'color_jitter']:\n",
    "    print(f\"\\nTesting standard augmentation: {aug_name}\")\n",
    "    \n",
    "    experiment_name = f\"Augmentation_{aug_name}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model,\n",
    "        augmentation_datasets[aug_name],\n",
    "        valid_dataset,\n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    augmentation_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing advanced augmentation: cutout\n",
      "\n",
      "==================== Running experiment: Augmentation_cutout ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7bfde8931a46d0a108cb1b8d3cad58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5497 | Train Acc: 80.76%\n",
      "Valid Loss: 0.4944 | Valid Acc: 82.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acee4be641104da7bff6aaaaf95c3622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3231 | Train Acc: 88.62%\n",
      "Valid Loss: 0.5369 | Valid Acc: 82.15%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ad241ab1354ced9faec9c160b59e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2323 | Train Acc: 91.91%\n",
      "Valid Loss: 0.5816 | Valid Acc: 81.72%\n",
      "Training completed in 2.89 minutes\n",
      "Test Accuracy: 82.30%\n"
     ]
    }
   ],
   "source": [
    "# Advanced augmentation (cutout)\n",
    "print(\"\\nTesting advanced augmentation: cutout\")\n",
    "experiment_name = \"Augmentation_cutout\"\n",
    "results = run_experiment(\n",
    "    experiment_name,\n",
    "    model,\n",
    "    augmentation_datasets['cutout'],\n",
    "    valid_dataset,\n",
    "    test_dataset,\n",
    "    hyperparams,\n",
    "    batch_size=128,\n",
    "    num_epochs=3\n",
    ")\n",
    "augmentation_results[experiment_name] = results\n",
    "all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Few-shot Learning Experiment\n",
    "print(\"\\n\" + \"=\"*30 + \" FEW-SHOT LEARNING \" + \"=\"*30)\n",
    "\n",
    "# Create a feature extractor for few-shot learning\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "\n",
    "print(\"Evaluating few-shot learning capabilities...\")\n",
    "few_shot_acc, few_shot_std = few_shot_evaluation(\n",
    "    feature_extractor, \n",
    "    test_dataset, \n",
    "    device, \n",
    "    n_way=5,    # 5-way classification \n",
    "    n_shot=5,   # 5-shot learning\n",
    "    n_query=15, # 15 query samples per class\n",
    "    n_episodes=20  # 20 episodes for quick evaluation\n",
    ")\n",
    "\n",
    "few_shot_results = {\n",
    "    'name': 'Few-shot Learning (5-way, 5-shot)',\n",
    "    'accuracy': few_shot_acc,\n",
    "    'std': few_shot_std\n",
    "}\n",
    "all_results['few_shot'] = few_shot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== REDUCED TRAINING SET EXPERIMENT ==============================\n",
      "\n",
      "Testing with reduced training set size: 4000 samples\n",
      "\n",
      "==================== Running experiment: Reduced_Train_Size_4000 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d192d6ff1c4efa975219eb35c3be76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5170 | Train Acc: 82.25%\n",
      "Valid Loss: 0.5129 | Valid Acc: 81.71%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85106a238e0469c8bb93cc36df1b9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.2074 | Train Acc: 93.03%\n",
      "Valid Loss: 0.5711 | Valid Acc: 81.25%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa570ff6a0424612b2c500167de9487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1077 | Train Acc: 96.62%\n",
      "Valid Loss: 0.6575 | Valid Acc: 81.09%\n",
      "Training completed in 1.81 minutes\n",
      "Test Accuracy: 81.36%\n",
      "\n",
      "Testing with reduced training set size: 2000 samples\n",
      "\n",
      "==================== Running experiment: Reduced_Train_Size_2000 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff951db8db8f4760a3036e3e58db4c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5268 | Train Acc: 81.25%\n",
      "Valid Loss: 0.5779 | Valid Acc: 80.15%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a62f079cf9d473da0e2012701b9b6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.2129 | Train Acc: 93.55%\n",
      "Valid Loss: 0.5439 | Valid Acc: 81.56%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7048e764d44477d9e77f0fb89ca839d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.0760 | Train Acc: 97.90%\n",
      "Valid Loss: 0.6482 | Valid Acc: 80.59%\n",
      "Training completed in 1.29 minutes\n",
      "Test Accuracy: 81.90%\n"
     ]
    }
   ],
   "source": [
    "# 6. Reduced Training Set Size Experiment\n",
    "print(\"\\n\" + \"=\"*30 + \" REDUCED TRAINING SET EXPERIMENT \" + \"=\"*30)\n",
    "\n",
    "# Create even smaller training subsets\n",
    "smaller_train_sizes = [TRAIN_SUBSET_SIZE // 2, TRAIN_SUBSET_SIZE // 4]\n",
    "reduction_results = {}\n",
    "\n",
    "for size in smaller_train_sizes:\n",
    "    print(f\"\\nTesting with reduced training set size: {size} samples\")\n",
    "    \n",
    "    # Create reduced training dataset\n",
    "    reduced_train_dataset = create_subset_dataset(full_train_dataset, num_samples=size)\n",
    "    \n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model = model.to(device)\n",
    "    \n",
    "    experiment_name = f\"Reduced_Train_Size_{size}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model,\n",
    "        reduced_train_dataset,\n",
    "        valid_dataset,\n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    reduction_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ENSEMBLE METHODS ==============================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"features.0.0.weight\", \"features.0.1.weight\", \"features.0.1.bias\", \"features.0.1.running_mean\", \"features.0.1.running_var\", \"features.1.0.block.0.0.weight\", \"features.1.0.block.0.1.weight\", \"features.1.0.block.0.1.bias\", \"features.1.0.block.0.1.running_mean\", \"features.1.0.block.0.1.running_var\", \"features.1.0.block.1.fc1.weight\", \"features.1.0.block.1.fc1.bias\", \"features.1.0.block.1.fc2.weight\", \"features.1.0.block.1.fc2.bias\", \"features.1.0.block.2.0.weight\", \"features.1.0.block.2.1.weight\", \"features.1.0.block.2.1.bias\", \"features.1.0.block.2.1.running_mean\", \"features.1.0.block.2.1.running_var\", \"features.2.0.block.0.0.weight\", \"features.2.0.block.0.1.weight\", \"features.2.0.block.0.1.bias\", \"features.2.0.block.0.1.running_mean\", \"features.2.0.block.0.1.running_var\", \"features.2.0.block.1.0.weight\", \"features.2.0.block.1.1.weight\", \"features.2.0.block.1.1.bias\", \"features.2.0.block.1.1.running_mean\", \"features.2.0.block.1.1.running_var\", \"features.2.0.block.2.fc1.weight\", \"features.2.0.block.2.fc1.bias\", \"features.2.0.block.2.fc2.weight\", \"features.2.0.block.2.fc2.bias\", \"features.2.0.block.3.0.weight\", \"features.2.0.block.3.1.weight\", \"features.2.0.block.3.1.bias\", \"features.2.0.block.3.1.running_mean\", \"features.2.0.block.3.1.running_var\", \"features.2.1.block.0.0.weight\", \"features.2.1.block.0.1.weight\", \"features.2.1.block.0.1.bias\", \"features.2.1.block.0.1.running_mean\", \"features.2.1.block.0.1.running_var\", \"features.2.1.block.1.0.weight\", \"features.2.1.block.1.1.weight\", \"features.2.1.block.1.1.bias\", \"features.2.1.block.1.1.running_mean\", \"features.2.1.block.1.1.running_var\", \"features.2.1.block.2.fc1.weight\", \"features.2.1.block.2.fc1.bias\", \"features.2.1.block.2.fc2.weight\", \"features.2.1.block.2.fc2.bias\", \"features.2.1.block.3.0.weight\", \"features.2.1.block.3.1.weight\", \"features.2.1.block.3.1.bias\", \"features.2.1.block.3.1.running_mean\", \"features.2.1.block.3.1.running_var\", \"features.3.0.block.0.0.weight\", \"features.3.0.block.0.1.weight\", \"features.3.0.block.0.1.bias\", \"features.3.0.block.0.1.running_mean\", \"features.3.0.block.0.1.running_var\", \"features.3.0.block.1.0.weight\", \"features.3.0.block.1.1.weight\", \"features.3.0.block.1.1.bias\", \"features.3.0.block.1.1.running_mean\", \"features.3.0.block.1.1.running_var\", \"features.3.0.block.2.fc1.weight\", \"features.3.0.block.2.fc1.bias\", \"features.3.0.block.2.fc2.weight\", \"features.3.0.block.2.fc2.bias\", \"features.3.0.block.3.0.weight\", \"features.3.0.block.3.1.weight\", \"features.3.0.block.3.1.bias\", \"features.3.0.block.3.1.running_mean\", \"features.3.0.block.3.1.running_var\", \"features.3.1.block.0.0.weight\", \"features.3.1.block.0.1.weight\", \"features.3.1.block.0.1.bias\", \"features.3.1.block.0.1.running_mean\", \"features.3.1.block.0.1.running_var\", \"features.3.1.block.1.0.weight\", \"features.3.1.block.1.1.weight\", \"features.3.1.block.1.1.bias\", \"features.3.1.block.1.1.running_mean\", \"features.3.1.block.1.1.running_var\", \"features.3.1.block.2.fc1.weight\", \"features.3.1.block.2.fc1.bias\", \"features.3.1.block.2.fc2.weight\", \"features.3.1.block.2.fc2.bias\", \"features.3.1.block.3.0.weight\", \"features.3.1.block.3.1.weight\", \"features.3.1.block.3.1.bias\", \"features.3.1.block.3.1.running_mean\", \"features.3.1.block.3.1.running_var\", \"features.4.0.block.0.0.weight\", \"features.4.0.block.0.1.weight\", \"features.4.0.block.0.1.bias\", \"features.4.0.block.0.1.running_mean\", \"features.4.0.block.0.1.running_var\", \"features.4.0.block.1.0.weight\", \"features.4.0.block.1.1.weight\", \"features.4.0.block.1.1.bias\", \"features.4.0.block.1.1.running_mean\", \"features.4.0.block.1.1.running_var\", \"features.4.0.block.2.fc1.weight\", \"features.4.0.block.2.fc1.bias\", \"features.4.0.block.2.fc2.weight\", \"features.4.0.block.2.fc2.bias\", \"features.4.0.block.3.0.weight\", \"features.4.0.block.3.1.weight\", \"features.4.0.block.3.1.bias\", \"features.4.0.block.3.1.running_mean\", \"features.4.0.block.3.1.running_var\", \"features.4.1.block.0.0.weight\", \"features.4.1.block.0.1.weight\", \"features.4.1.block.0.1.bias\", \"features.4.1.block.0.1.running_mean\", \"features.4.1.block.0.1.running_var\", \"features.4.1.block.1.0.weight\", \"features.4.1.block.1.1.weight\", \"features.4.1.block.1.1.bias\", \"features.4.1.block.1.1.running_mean\", \"features.4.1.block.1.1.running_var\", \"features.4.1.block.2.fc1.weight\", \"features.4.1.block.2.fc1.bias\", \"features.4.1.block.2.fc2.weight\", \"features.4.1.block.2.fc2.bias\", \"features.4.1.block.3.0.weight\", \"features.4.1.block.3.1.weight\", \"features.4.1.block.3.1.bias\", \"features.4.1.block.3.1.running_mean\", \"features.4.1.block.3.1.running_var\", \"features.4.2.block.0.0.weight\", \"features.4.2.block.0.1.weight\", \"features.4.2.block.0.1.bias\", \"features.4.2.block.0.1.running_mean\", \"features.4.2.block.0.1.running_var\", \"features.4.2.block.1.0.weight\", \"features.4.2.block.1.1.weight\", \"features.4.2.block.1.1.bias\", \"features.4.2.block.1.1.running_mean\", \"features.4.2.block.1.1.running_var\", \"features.4.2.block.2.fc1.weight\", \"features.4.2.block.2.fc1.bias\", \"features.4.2.block.2.fc2.weight\", \"features.4.2.block.2.fc2.bias\", \"features.4.2.block.3.0.weight\", \"features.4.2.block.3.1.weight\", \"features.4.2.block.3.1.bias\", \"features.4.2.block.3.1.running_mean\", \"features.4.2.block.3.1.running_var\", \"features.5.0.block.0.0.weight\", \"features.5.0.block.0.1.weight\", \"features.5.0.block.0.1.bias\", \"features.5.0.block.0.1.running_mean\", \"features.5.0.block.0.1.running_var\", \"features.5.0.block.1.0.weight\", \"features.5.0.block.1.1.weight\", \"features.5.0.block.1.1.bias\", \"features.5.0.block.1.1.running_mean\", \"features.5.0.block.1.1.running_var\", \"features.5.0.block.2.fc1.weight\", \"features.5.0.block.2.fc1.bias\", \"features.5.0.block.2.fc2.weight\", \"features.5.0.block.2.fc2.bias\", \"features.5.0.block.3.0.weight\", \"features.5.0.block.3.1.weight\", \"features.5.0.block.3.1.bias\", \"features.5.0.block.3.1.running_mean\", \"features.5.0.block.3.1.running_var\", \"features.5.1.block.0.0.weight\", \"features.5.1.block.0.1.weight\", \"features.5.1.block.0.1.bias\", \"features.5.1.block.0.1.running_mean\", \"features.5.1.block.0.1.running_var\", \"features.5.1.block.1.0.weight\", \"features.5.1.block.1.1.weight\", \"features.5.1.block.1.1.bias\", \"features.5.1.block.1.1.running_mean\", \"features.5.1.block.1.1.running_var\", \"features.5.1.block.2.fc1.weight\", \"features.5.1.block.2.fc1.bias\", \"features.5.1.block.2.fc2.weight\", \"features.5.1.block.2.fc2.bias\", \"features.5.1.block.3.0.weight\", \"features.5.1.block.3.1.weight\", \"features.5.1.block.3.1.bias\", \"features.5.1.block.3.1.running_mean\", \"features.5.1.block.3.1.running_var\", \"features.5.2.block.0.0.weight\", \"features.5.2.block.0.1.weight\", \"features.5.2.block.0.1.bias\", \"features.5.2.block.0.1.running_mean\", \"features.5.2.block.0.1.running_var\", \"features.5.2.block.1.0.weight\", \"features.5.2.block.1.1.weight\", \"features.5.2.block.1.1.bias\", \"features.5.2.block.1.1.running_mean\", \"features.5.2.block.1.1.running_var\", \"features.5.2.block.2.fc1.weight\", \"features.5.2.block.2.fc1.bias\", \"features.5.2.block.2.fc2.weight\", \"features.5.2.block.2.fc2.bias\", \"features.5.2.block.3.0.weight\", \"features.5.2.block.3.1.weight\", \"features.5.2.block.3.1.bias\", \"features.5.2.block.3.1.running_mean\", \"features.5.2.block.3.1.running_var\", \"features.6.0.block.0.0.weight\", \"features.6.0.block.0.1.weight\", \"features.6.0.block.0.1.bias\", \"features.6.0.block.0.1.running_mean\", \"features.6.0.block.0.1.running_var\", \"features.6.0.block.1.0.weight\", \"features.6.0.block.1.1.weight\", \"features.6.0.block.1.1.bias\", \"features.6.0.block.1.1.running_mean\", \"features.6.0.block.1.1.running_var\", \"features.6.0.block.2.fc1.weight\", \"features.6.0.block.2.fc1.bias\", \"features.6.0.block.2.fc2.weight\", \"features.6.0.block.2.fc2.bias\", \"features.6.0.block.3.0.weight\", \"features.6.0.block.3.1.weight\", \"features.6.0.block.3.1.bias\", \"features.6.0.block.3.1.running_mean\", \"features.6.0.block.3.1.running_var\", \"features.6.1.block.0.0.weight\", \"features.6.1.block.0.1.weight\", \"features.6.1.block.0.1.bias\", \"features.6.1.block.0.1.running_mean\", \"features.6.1.block.0.1.running_var\", \"features.6.1.block.1.0.weight\", \"features.6.1.block.1.1.weight\", \"features.6.1.block.1.1.bias\", \"features.6.1.block.1.1.running_mean\", \"features.6.1.block.1.1.running_var\", \"features.6.1.block.2.fc1.weight\", \"features.6.1.block.2.fc1.bias\", \"features.6.1.block.2.fc2.weight\", \"features.6.1.block.2.fc2.bias\", \"features.6.1.block.3.0.weight\", \"features.6.1.block.3.1.weight\", \"features.6.1.block.3.1.bias\", \"features.6.1.block.3.1.running_mean\", \"features.6.1.block.3.1.running_var\", \"features.6.2.block.0.0.weight\", \"features.6.2.block.0.1.weight\", \"features.6.2.block.0.1.bias\", \"features.6.2.block.0.1.running_mean\", \"features.6.2.block.0.1.running_var\", \"features.6.2.block.1.0.weight\", \"features.6.2.block.1.1.weight\", \"features.6.2.block.1.1.bias\", \"features.6.2.block.1.1.running_mean\", \"features.6.2.block.1.1.running_var\", \"features.6.2.block.2.fc1.weight\", \"features.6.2.block.2.fc1.bias\", \"features.6.2.block.2.fc2.weight\", \"features.6.2.block.2.fc2.bias\", \"features.6.2.block.3.0.weight\", \"features.6.2.block.3.1.weight\", \"features.6.2.block.3.1.bias\", \"features.6.2.block.3.1.running_mean\", \"features.6.2.block.3.1.running_var\", \"features.6.3.block.0.0.weight\", \"features.6.3.block.0.1.weight\", \"features.6.3.block.0.1.bias\", \"features.6.3.block.0.1.running_mean\", \"features.6.3.block.0.1.running_var\", \"features.6.3.block.1.0.weight\", \"features.6.3.block.1.1.weight\", \"features.6.3.block.1.1.bias\", \"features.6.3.block.1.1.running_mean\", \"features.6.3.block.1.1.running_var\", \"features.6.3.block.2.fc1.weight\", \"features.6.3.block.2.fc1.bias\", \"features.6.3.block.2.fc2.weight\", \"features.6.3.block.2.fc2.bias\", \"features.6.3.block.3.0.weight\", \"features.6.3.block.3.1.weight\", \"features.6.3.block.3.1.bias\", \"features.6.3.block.3.1.running_mean\", \"features.6.3.block.3.1.running_var\", \"features.7.0.block.0.0.weight\", \"features.7.0.block.0.1.weight\", \"features.7.0.block.0.1.bias\", \"features.7.0.block.0.1.running_mean\", \"features.7.0.block.0.1.running_var\", \"features.7.0.block.1.0.weight\", \"features.7.0.block.1.1.weight\", \"features.7.0.block.1.1.bias\", \"features.7.0.block.1.1.running_mean\", \"features.7.0.block.1.1.running_var\", \"features.7.0.block.2.fc1.weight\", \"features.7.0.block.2.fc1.bias\", \"features.7.0.block.2.fc2.weight\", \"features.7.0.block.2.fc2.bias\", \"features.7.0.block.3.0.weight\", \"features.7.0.block.3.1.weight\", \"features.7.0.block.3.1.bias\", \"features.7.0.block.3.1.running_mean\", \"features.7.0.block.3.1.running_var\", \"features.8.0.weight\", \"features.8.1.weight\", \"features.8.1.bias\", \"features.8.1.running_mean\", \"features.8.1.running_var\". \n\tUnexpected key(s) in state_dict: \"features.10.weight\", \"features.10.bias\", \"features.11.weight\", \"features.11.bias\", \"features.11.running_mean\", \"features.11.running_var\", \"features.11.num_batches_tracked\", \"features.14.weight\", \"features.14.bias\", \"features.15.weight\", \"features.15.bias\", \"features.15.running_mean\", \"features.15.running_var\", \"features.15.num_batches_tracked\", \"features.17.weight\", \"features.17.bias\", \"features.18.weight\", \"features.18.bias\", \"features.18.running_mean\", \"features.18.running_var\", \"features.18.num_batches_tracked\", \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.1.num_batches_tracked\", \"features.3.weight\", \"features.3.bias\", \"features.4.weight\", \"features.4.bias\", \"features.4.running_mean\", \"features.4.running_var\", \"features.4.num_batches_tracked\", \"features.7.weight\", \"features.7.bias\", \"features.8.weight\", \"features.8.bias\", \"features.8.running_mean\", \"features.8.running_var\", \"features.8.num_batches_tracked\", \"classifier.4.weight\", \"classifier.4.bias\". \n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([10, 1280]).\n\tsize mismatch for classifier.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, state_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model_states[:\u001b[32m3\u001b[39m]):  \u001b[38;5;66;03m# Use top 3 models\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Create a new model with the best architecture\u001b[39;00m\n\u001b[32m     19\u001b[39m     model = architectures[best_arch]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     model = model.to(device)\n\u001b[32m     22\u001b[39m     ensemble_models.append(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/university/DeepLearningCourse/deep_learning/lib/python3.11/site-packages/torch/nn/modules/module.py:2581\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2573\u001b[39m         error_msgs.insert(\n\u001b[32m   2574\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2575\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2576\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2577\u001b[39m             ),\n\u001b[32m   2578\u001b[39m         )\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2583\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2584\u001b[39m         )\n\u001b[32m   2585\u001b[39m     )\n\u001b[32m   2586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"features.0.0.weight\", \"features.0.1.weight\", \"features.0.1.bias\", \"features.0.1.running_mean\", \"features.0.1.running_var\", \"features.1.0.block.0.0.weight\", \"features.1.0.block.0.1.weight\", \"features.1.0.block.0.1.bias\", \"features.1.0.block.0.1.running_mean\", \"features.1.0.block.0.1.running_var\", \"features.1.0.block.1.fc1.weight\", \"features.1.0.block.1.fc1.bias\", \"features.1.0.block.1.fc2.weight\", \"features.1.0.block.1.fc2.bias\", \"features.1.0.block.2.0.weight\", \"features.1.0.block.2.1.weight\", \"features.1.0.block.2.1.bias\", \"features.1.0.block.2.1.running_mean\", \"features.1.0.block.2.1.running_var\", \"features.2.0.block.0.0.weight\", \"features.2.0.block.0.1.weight\", \"features.2.0.block.0.1.bias\", \"features.2.0.block.0.1.running_mean\", \"features.2.0.block.0.1.running_var\", \"features.2.0.block.1.0.weight\", \"features.2.0.block.1.1.weight\", \"features.2.0.block.1.1.bias\", \"features.2.0.block.1.1.running_mean\", \"features.2.0.block.1.1.running_var\", \"features.2.0.block.2.fc1.weight\", \"features.2.0.block.2.fc1.bias\", \"features.2.0.block.2.fc2.weight\", \"features.2.0.block.2.fc2.bias\", \"features.2.0.block.3.0.weight\", \"features.2.0.block.3.1.weight\", \"features.2.0.block.3.1.bias\", \"features.2.0.block.3.1.running_mean\", \"features.2.0.block.3.1.running_var\", \"features.2.1.block.0.0.weight\", \"features.2.1.block.0.1.weight\", \"features.2.1.block.0.1.bias\", \"features.2.1.block.0.1.running_mean\", \"features.2.1.block.0.1.running_var\", \"features.2.1.block.1.0.weight\", \"features.2.1.block.1.1.weight\", \"features.2.1.block.1.1.bias\", \"features.2.1.block.1.1.running_mean\", \"features.2.1.block.1.1.running_var\", \"features.2.1.block.2.fc1.weight\", \"features.2.1.block.2.fc1.bias\", \"features.2.1.block.2.fc2.weight\", \"features.2.1.block.2.fc2.bias\", \"features.2.1.block.3.0.weight\", \"features.2.1.block.3.1.weight\", \"features.2.1.block.3.1.bias\", \"features.2.1.block.3.1.running_mean\", \"features.2.1.block.3.1.running_var\", \"features.3.0.block.0.0.weight\", \"features.3.0.block.0.1.weight\", \"features.3.0.block.0.1.bias\", \"features.3.0.block.0.1.running_mean\", \"features.3.0.block.0.1.running_var\", \"features.3.0.block.1.0.weight\", \"features.3.0.block.1.1.weight\", \"features.3.0.block.1.1.bias\", \"features.3.0.block.1.1.running_mean\", \"features.3.0.block.1.1.running_var\", \"features.3.0.block.2.fc1.weight\", \"features.3.0.block.2.fc1.bias\", \"features.3.0.block.2.fc2.weight\", \"features.3.0.block.2.fc2.bias\", \"features.3.0.block.3.0.weight\", \"features.3.0.block.3.1.weight\", \"features.3.0.block.3.1.bias\", \"features.3.0.block.3.1.running_mean\", \"features.3.0.block.3.1.running_var\", \"features.3.1.block.0.0.weight\", \"features.3.1.block.0.1.weight\", \"features.3.1.block.0.1.bias\", \"features.3.1.block.0.1.running_mean\", \"features.3.1.block.0.1.running_var\", \"features.3.1.block.1.0.weight\", \"features.3.1.block.1.1.weight\", \"features.3.1.block.1.1.bias\", \"features.3.1.block.1.1.running_mean\", \"features.3.1.block.1.1.running_var\", \"features.3.1.block.2.fc1.weight\", \"features.3.1.block.2.fc1.bias\", \"features.3.1.block.2.fc2.weight\", \"features.3.1.block.2.fc2.bias\", \"features.3.1.block.3.0.weight\", \"features.3.1.block.3.1.weight\", \"features.3.1.block.3.1.bias\", \"features.3.1.block.3.1.running_mean\", \"features.3.1.block.3.1.running_var\", \"features.4.0.block.0.0.weight\", \"features.4.0.block.0.1.weight\", \"features.4.0.block.0.1.bias\", \"features.4.0.block.0.1.running_mean\", \"features.4.0.block.0.1.running_var\", \"features.4.0.block.1.0.weight\", \"features.4.0.block.1.1.weight\", \"features.4.0.block.1.1.bias\", \"features.4.0.block.1.1.running_mean\", \"features.4.0.block.1.1.running_var\", \"features.4.0.block.2.fc1.weight\", \"features.4.0.block.2.fc1.bias\", \"features.4.0.block.2.fc2.weight\", \"features.4.0.block.2.fc2.bias\", \"features.4.0.block.3.0.weight\", \"features.4.0.block.3.1.weight\", \"features.4.0.block.3.1.bias\", \"features.4.0.block.3.1.running_mean\", \"features.4.0.block.3.1.running_var\", \"features.4.1.block.0.0.weight\", \"features.4.1.block.0.1.weight\", \"features.4.1.block.0.1.bias\", \"features.4.1.block.0.1.running_mean\", \"features.4.1.block.0.1.running_var\", \"features.4.1.block.1.0.weight\", \"features.4.1.block.1.1.weight\", \"features.4.1.block.1.1.bias\", \"features.4.1.block.1.1.running_mean\", \"features.4.1.block.1.1.running_var\", \"features.4.1.block.2.fc1.weight\", \"features.4.1.block.2.fc1.bias\", \"features.4.1.block.2.fc2.weight\", \"features.4.1.block.2.fc2.bias\", \"features.4.1.block.3.0.weight\", \"features.4.1.block.3.1.weight\", \"features.4.1.block.3.1.bias\", \"features.4.1.block.3.1.running_mean\", \"features.4.1.block.3.1.running_var\", \"features.4.2.block.0.0.weight\", \"features.4.2.block.0.1.weight\", \"features.4.2.block.0.1.bias\", \"features.4.2.block.0.1.running_mean\", \"features.4.2.block.0.1.running_var\", \"features.4.2.block.1.0.weight\", \"features.4.2.block.1.1.weight\", \"features.4.2.block.1.1.bias\", \"features.4.2.block.1.1.running_mean\", \"features.4.2.block.1.1.running_var\", \"features.4.2.block.2.fc1.weight\", \"features.4.2.block.2.fc1.bias\", \"features.4.2.block.2.fc2.weight\", \"features.4.2.block.2.fc2.bias\", \"features.4.2.block.3.0.weight\", \"features.4.2.block.3.1.weight\", \"features.4.2.block.3.1.bias\", \"features.4.2.block.3.1.running_mean\", \"features.4.2.block.3.1.running_var\", \"features.5.0.block.0.0.weight\", \"features.5.0.block.0.1.weight\", \"features.5.0.block.0.1.bias\", \"features.5.0.block.0.1.running_mean\", \"features.5.0.block.0.1.running_var\", \"features.5.0.block.1.0.weight\", \"features.5.0.block.1.1.weight\", \"features.5.0.block.1.1.bias\", \"features.5.0.block.1.1.running_mean\", \"features.5.0.block.1.1.running_var\", \"features.5.0.block.2.fc1.weight\", \"features.5.0.block.2.fc1.bias\", \"features.5.0.block.2.fc2.weight\", \"features.5.0.block.2.fc2.bias\", \"features.5.0.block.3.0.weight\", \"features.5.0.block.3.1.weight\", \"features.5.0.block.3.1.bias\", \"features.5.0.block.3.1.running_mean\", \"features.5.0.block.3.1.running_var\", \"features.5.1.block.0.0.weight\", \"features.5.1.block.0.1.weight\", \"features.5.1.block.0.1.bias\", \"features.5.1.block.0.1.running_mean\", \"features.5.1.block.0.1.running_var\", \"features.5.1.block.1.0.weight\", \"features.5.1.block.1.1.weight\", \"features.5.1.block.1.1.bias\", \"features.5.1.block.1.1.running_mean\", \"features.5.1.block.1.1.running_var\", \"features.5.1.block.2.fc1.weight\", \"features.5.1.block.2.fc1.bias\", \"features.5.1.block.2.fc2.weight\", \"features.5.1.block.2.fc2.bias\", \"features.5.1.block.3.0.weight\", \"features.5.1.block.3.1.weight\", \"features.5.1.block.3.1.bias\", \"features.5.1.block.3.1.running_mean\", \"features.5.1.block.3.1.running_var\", \"features.5.2.block.0.0.weight\", \"features.5.2.block.0.1.weight\", \"features.5.2.block.0.1.bias\", \"features.5.2.block.0.1.running_mean\", \"features.5.2.block.0.1.running_var\", \"features.5.2.block.1.0.weight\", \"features.5.2.block.1.1.weight\", \"features.5.2.block.1.1.bias\", \"features.5.2.block.1.1.running_mean\", \"features.5.2.block.1.1.running_var\", \"features.5.2.block.2.fc1.weight\", \"features.5.2.block.2.fc1.bias\", \"features.5.2.block.2.fc2.weight\", \"features.5.2.block.2.fc2.bias\", \"features.5.2.block.3.0.weight\", \"features.5.2.block.3.1.weight\", \"features.5.2.block.3.1.bias\", \"features.5.2.block.3.1.running_mean\", \"features.5.2.block.3.1.running_var\", \"features.6.0.block.0.0.weight\", \"features.6.0.block.0.1.weight\", \"features.6.0.block.0.1.bias\", \"features.6.0.block.0.1.running_mean\", \"features.6.0.block.0.1.running_var\", \"features.6.0.block.1.0.weight\", \"features.6.0.block.1.1.weight\", \"features.6.0.block.1.1.bias\", \"features.6.0.block.1.1.running_mean\", \"features.6.0.block.1.1.running_var\", \"features.6.0.block.2.fc1.weight\", \"features.6.0.block.2.fc1.bias\", \"features.6.0.block.2.fc2.weight\", \"features.6.0.block.2.fc2.bias\", \"features.6.0.block.3.0.weight\", \"features.6.0.block.3.1.weight\", \"features.6.0.block.3.1.bias\", \"features.6.0.block.3.1.running_mean\", \"features.6.0.block.3.1.running_var\", \"features.6.1.block.0.0.weight\", \"features.6.1.block.0.1.weight\", \"features.6.1.block.0.1.bias\", \"features.6.1.block.0.1.running_mean\", \"features.6.1.block.0.1.running_var\", \"features.6.1.block.1.0.weight\", \"features.6.1.block.1.1.weight\", \"features.6.1.block.1.1.bias\", \"features.6.1.block.1.1.running_mean\", \"features.6.1.block.1.1.running_var\", \"features.6.1.block.2.fc1.weight\", \"features.6.1.block.2.fc1.bias\", \"features.6.1.block.2.fc2.weight\", \"features.6.1.block.2.fc2.bias\", \"features.6.1.block.3.0.weight\", \"features.6.1.block.3.1.weight\", \"features.6.1.block.3.1.bias\", \"features.6.1.block.3.1.running_mean\", \"features.6.1.block.3.1.running_var\", \"features.6.2.block.0.0.weight\", \"features.6.2.block.0.1.weight\", \"features.6.2.block.0.1.bias\", \"features.6.2.block.0.1.running_mean\", \"features.6.2.block.0.1.running_var\", \"features.6.2.block.1.0.weight\", \"features.6.2.block.1.1.weight\", \"features.6.2.block.1.1.bias\", \"features.6.2.block.1.1.running_mean\", \"features.6.2.block.1.1.running_var\", \"features.6.2.block.2.fc1.weight\", \"features.6.2.block.2.fc1.bias\", \"features.6.2.block.2.fc2.weight\", \"features.6.2.block.2.fc2.bias\", \"features.6.2.block.3.0.weight\", \"features.6.2.block.3.1.weight\", \"features.6.2.block.3.1.bias\", \"features.6.2.block.3.1.running_mean\", \"features.6.2.block.3.1.running_var\", \"features.6.3.block.0.0.weight\", \"features.6.3.block.0.1.weight\", \"features.6.3.block.0.1.bias\", \"features.6.3.block.0.1.running_mean\", \"features.6.3.block.0.1.running_var\", \"features.6.3.block.1.0.weight\", \"features.6.3.block.1.1.weight\", \"features.6.3.block.1.1.bias\", \"features.6.3.block.1.1.running_mean\", \"features.6.3.block.1.1.running_var\", \"features.6.3.block.2.fc1.weight\", \"features.6.3.block.2.fc1.bias\", \"features.6.3.block.2.fc2.weight\", \"features.6.3.block.2.fc2.bias\", \"features.6.3.block.3.0.weight\", \"features.6.3.block.3.1.weight\", \"features.6.3.block.3.1.bias\", \"features.6.3.block.3.1.running_mean\", \"features.6.3.block.3.1.running_var\", \"features.7.0.block.0.0.weight\", \"features.7.0.block.0.1.weight\", \"features.7.0.block.0.1.bias\", \"features.7.0.block.0.1.running_mean\", \"features.7.0.block.0.1.running_var\", \"features.7.0.block.1.0.weight\", \"features.7.0.block.1.1.weight\", \"features.7.0.block.1.1.bias\", \"features.7.0.block.1.1.running_mean\", \"features.7.0.block.1.1.running_var\", \"features.7.0.block.2.fc1.weight\", \"features.7.0.block.2.fc1.bias\", \"features.7.0.block.2.fc2.weight\", \"features.7.0.block.2.fc2.bias\", \"features.7.0.block.3.0.weight\", \"features.7.0.block.3.1.weight\", \"features.7.0.block.3.1.bias\", \"features.7.0.block.3.1.running_mean\", \"features.7.0.block.3.1.running_var\", \"features.8.0.weight\", \"features.8.1.weight\", \"features.8.1.bias\", \"features.8.1.running_mean\", \"features.8.1.running_var\". \n\tUnexpected key(s) in state_dict: \"features.10.weight\", \"features.10.bias\", \"features.11.weight\", \"features.11.bias\", \"features.11.running_mean\", \"features.11.running_var\", \"features.11.num_batches_tracked\", \"features.14.weight\", \"features.14.bias\", \"features.15.weight\", \"features.15.bias\", \"features.15.running_mean\", \"features.15.running_var\", \"features.15.num_batches_tracked\", \"features.17.weight\", \"features.17.bias\", \"features.18.weight\", \"features.18.bias\", \"features.18.running_mean\", \"features.18.running_var\", \"features.18.num_batches_tracked\", \"features.0.weight\", \"features.0.bias\", \"features.1.weight\", \"features.1.bias\", \"features.1.running_mean\", \"features.1.running_var\", \"features.1.num_batches_tracked\", \"features.3.weight\", \"features.3.bias\", \"features.4.weight\", \"features.4.bias\", \"features.4.running_mean\", \"features.4.running_var\", \"features.4.num_batches_tracked\", \"features.7.weight\", \"features.7.bias\", \"features.8.weight\", \"features.8.bias\", \"features.8.running_mean\", \"features.8.running_var\", \"features.8.num_batches_tracked\", \"classifier.4.weight\", \"classifier.4.bias\". \n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([10, 1280]).\n\tsize mismatch for classifier.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "# 7. Ensemble Methods\n",
    "print(\"\\n\" + \"=\"*30 + \" ENSEMBLE METHODS \" + \"=\"*30)\n",
    "\n",
    "# We'll use the models we've already trained\n",
    "# Collect all saved models from previous experiments\n",
    "model_states = [\n",
    "    all_results[k]['model_state'] \n",
    "    for k in all_results \n",
    "    if 'model_state' in all_results[k]\n",
    "]\n",
    "\n",
    "# Create test data loader for ensemble evaluation\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# Create ensemble models\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(model_states[:3]):  # Use top 3 models\n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "print(\"Testing ensemble methods...\")\n",
    "# Hard voting\n",
    "hard_accuracy, hard_preds, hard_labels = ensemble_prediction(\n",
    "    ensemble_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    method='hard'\n",
    ")\n",
    "print(f\"Hard voting ensemble accuracy: {hard_accuracy:.2f}%\")\n",
    "\n",
    "# Soft voting\n",
    "soft_accuracy, soft_preds, soft_labels = ensemble_prediction(\n",
    "    ensemble_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    method='soft'\n",
    ")\n",
    "print(f\"Soft voting ensemble accuracy: {soft_accuracy:.2f}%\")\n",
    "\n",
    "ensemble_results = {\n",
    "    'hard_voting': {\n",
    "        'accuracy': hard_accuracy,\n",
    "        'predictions': hard_preds,\n",
    "        'labels': hard_labels\n",
    "    },\n",
    "    'soft_voting': {\n",
    "        'accuracy': soft_accuracy,\n",
    "        'predictions': soft_preds,\n",
    "        'labels': soft_labels\n",
    "    }\n",
    "}\n",
    "all_results['ensemble'] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Summarize and Visualize Results\n",
    "print(\"\\n\" + \"=\"*30 + \" RESULTS SUMMARY \" + \"=\"*30)\n",
    "\n",
    "# 1. Architecture Comparison\n",
    "print(\"\\nArchitecture Comparison:\")\n",
    "for arch_name, results in architecture_results.items():\n",
    "    print(f\"{arch_name}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 2. Training Hyperparameters\n",
    "print(\"\\nTraining Hyperparameters Comparison:\")\n",
    "for name, results in training_results.items():\n",
    "    print(f\"{name} - {results['hyperparams']}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 3. Regularization Hyperparameters\n",
    "print(\"\\nRegularization Hyperparameters Comparison:\")\n",
    "for name, results in regularization_results.items():\n",
    "    print(f\"{name} - Weight Decay: {results['hyperparams']['weight_decay']}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 4. Data Augmentation\n",
    "print(\"\\nData Augmentation Comparison:\")\n",
    "for name, results in augmentation_results.items():\n",
    "    print(f\"{name}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 5. Few-shot Learning\n",
    "print(f\"\\nFew-shot Learning (5-way, 5-shot): {few_shot_results['accuracy']:.2f}% Â± {few_shot_results['std']:.2f}%\")\n",
    "\n",
    "# 6. Reduced Training Set Size\n",
    "print(\"\\nReduced Training Set Size Comparison:\")\n",
    "for name, results in reduction_results.items():\n",
    "    size = name.split('_')[-1]\n",
    "    print(f\"Size {size}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 7. Ensemble Methods\n",
    "print(f\"\\nEnsemble Hard Voting: {ensemble_results['hard_voting']['accuracy']:.2f}%\")\n",
    "print(f\"Ensemble Soft Voting: {ensemble_results['soft_voting']['accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "\n",
    "# 1. Plot test accuracies\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Architecture comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "arch_names = list(architecture_results.keys())\n",
    "arch_accs = [architecture_results[n]['test_accuracy'] for n in arch_names]\n",
    "plt.bar(arch_names, arch_accs)\n",
    "plt.title('Architecture Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Augmentation comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "aug_names = [name.split('_')[1] for name in augmentation_results.keys()]\n",
    "aug_accs = [augmentation_results[name]['test_accuracy'] for name in augmentation_results.keys()]\n",
    "plt.bar(aug_names, aug_accs)\n",
    "plt.title('Data Augmentation Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Reduced training set size\n",
    "plt.subplot(2, 2, 3)\n",
    "sizes = [name.split('_')[-1] for name in reduction_results.keys()]\n",
    "size_accs = [reduction_results[name]['test_accuracy'] for name in reduction_results.keys()]\n",
    "# Add the full dataset result\n",
    "sizes.append(str(TRAIN_SUBSET_SIZE))\n",
    "size_accs.append(all_results['Architecture_efficientnet']['test_accuracy'])\n",
    "plt.bar(sizes, size_accs)\n",
    "plt.title('Reduced Training Set Size')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Ensemble comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Hard Voting', 'Soft Voting', 'Best Single Model']\n",
    "accuracies = [\n",
    "    ensemble_results['hard_voting']['accuracy'],\n",
    "    ensemble_results['soft_voting']['accuracy'],\n",
    "    max([results['test_accuracy'] for name, results in all_results.items() if 'test_accuracy' in results])\n",
    "]\n",
    "plt.bar(methods, accuracies)\n",
    "plt.title('Ensemble Methods Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiment_results_summary.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save all results to file\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Convert numpy arrays to lists for JSON serialization\n",
    "def convert_numpy_to_list(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_numpy_to_list(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_to_list(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Convert all results\n",
    "serializable_results = convert_numpy_to_list(all_results)\n",
    "\n",
    "# Remove model states which can't be serialized easily\n",
    "for key in serializable_results:\n",
    "    if isinstance(serializable_results[key], dict) and 'model_state' in serializable_results[key]:\n",
    "        del serializable_results[key]['model_state']\n",
    "\n",
    "# Save as JSON for easy viewing\n",
    "with open('experiment_results.json', 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=2)\n",
    "\n",
    "print(\"\\nExperiment results saved to 'experiment_results.json'\")\n",
    "print(\"Summary visualizations saved to 'experiment_results_summary.png'\")\n",
    "\n",
    "# Save full results including model states with pickle\n",
    "try:\n",
    "    with open('full_experiment_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    print(\"Full results including model states saved to 'full_experiment_results.pkl'\")\n",
    "except:\n",
    "    print(\"Warning: Could not save full results with model states\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \" EXPERIMENTS COMPLETED \" + \"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
