{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "import copy\n",
    "from PIL import Image, ImageFilter\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a smaller subset of data for quicker experiments\n",
    "TRAIN_SUBSET_SIZE = 8000  # Reduced from 10000\n",
    "VALID_SUBSET_SIZE = 8000\n",
    "TEST_SUBSET_SIZE = 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seeds for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tensor created on MPS successfully: mps:0\n",
      "MPS is working properly\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Function for checking device\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        try:\n",
    "            # Try creating a tensor on MPS\n",
    "            test_tensor = torch.zeros(1, device=\"mps\")\n",
    "            print(f\"Test tensor created on MPS successfully: {test_tensor.device}\")\n",
    "            print(\"MPS is working properly\")\n",
    "            return torch.device(\"mps\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing MPS: {e}\")\n",
    "    \n",
    "    print(\"Using CPU\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset subset function\n",
    "def create_subset_dataset(original_dataset, num_samples=10000, balanced=True):\n",
    "    \"\"\"\n",
    "    Create a subset of the original dataset with equal class distribution\n",
    "    \"\"\"\n",
    "    if balanced:\n",
    "        # Get class labels\n",
    "        targets = torch.tensor([target for _, target in original_dataset.samples])\n",
    "        classes = torch.unique(targets)\n",
    "        num_classes = len(classes)\n",
    "        samples_per_class = num_samples // num_classes\n",
    "        \n",
    "        indices = []\n",
    "        for cls in classes:\n",
    "            cls_indices = torch.where(targets == cls)[0]\n",
    "            # If we have fewer samples than requested, take all of them\n",
    "            if len(cls_indices) <= samples_per_class:\n",
    "                indices.extend(cls_indices.tolist())\n",
    "            else:\n",
    "                # Otherwise randomly sample\n",
    "                selected = cls_indices[torch.randperm(len(cls_indices))[:samples_per_class]]\n",
    "                indices.extend(selected.tolist())\n",
    "        \n",
    "        return Subset(original_dataset, indices)\n",
    "    else:\n",
    "        # Simple random subset\n",
    "        return Subset(original_dataset, torch.randperm(len(original_dataset))[:num_samples].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data augmentation techniques\n",
    "def cutout_transform(img, n_holes=1, length=16):\n",
    "    \"\"\"Apply cutout augmentation to a tensor image\"\"\"\n",
    "    h = img.size(1)\n",
    "    w = img.size(2)\n",
    "    \n",
    "    mask = torch.ones((h, w))\n",
    "    \n",
    "    for n in range(n_holes):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        \n",
    "        y1 = np.clip(y - length // 2, 0, h)\n",
    "        y2 = np.clip(y + length // 2, 0, h)\n",
    "        x1 = np.clip(x - length // 2, 0, w)\n",
    "        x2 = np.clip(x + length // 2, 0, w)\n",
    "        \n",
    "        mask[y1: y2, x1: x2] = 0.\n",
    "    \n",
    "    mask = mask.expand_as(img)\n",
    "    return img * mask\n",
    "\n",
    "class CutoutTransform:\n",
    "    \"\"\"Wrapper class for the cutout transform to use in torchvision transforms\"\"\"\n",
    "    def __init__(self, n_holes=1, length=16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return cutout_transform(img, self.n_holes, self.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries of transforms for our experiments\n",
    "standard_transforms = {\n",
    "    'baseline': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'horizontal_flip': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'rotation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'color_jitter': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'combined_standard': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Advanced augmentation with Cutout\n",
    "advanced_transforms = {\n",
    "    'cutout': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        CutoutTransform(n_holes=1, length=32)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original datasets...\n",
      "Creating subsets...\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Training samples: 8000\n",
      "Validation samples: 8000\n",
      "Test samples: 8000\n"
     ]
    }
   ],
   "source": [
    "# Load full datasets first\n",
    "print(\"Loading original datasets...\")\n",
    "full_train_dataset = ImageFolder(root='data/train', transform=standard_transforms['baseline'])\n",
    "full_valid_dataset = ImageFolder(root='data/valid', transform=standard_transforms['baseline'])\n",
    "full_test_dataset = ImageFolder(root='data/test', transform=standard_transforms['baseline'])\n",
    "\n",
    "# Create reduced subsets\n",
    "print(\"Creating subsets...\")\n",
    "train_dataset = create_subset_dataset(full_train_dataset, num_samples=TRAIN_SUBSET_SIZE)\n",
    "valid_dataset = create_subset_dataset(full_valid_dataset, num_samples=VALID_SUBSET_SIZE)\n",
    "test_dataset = create_subset_dataset(full_test_dataset, num_samples=TEST_SUBSET_SIZE)\n",
    "\n",
    "# Save class names\n",
    "class_names = full_train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(valid_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architectures\n",
    "def create_efficientnet_model(num_classes=10, pretrained=True):\n",
    "    \"\"\"Create EfficientNet B0 model\"\"\"\n",
    "    if pretrained:\n",
    "        weights = EfficientNet_B0_Weights.DEFAULT\n",
    "        model = efficientnet_b0(weights=weights)\n",
    "    else:\n",
    "        model = efficientnet_b0(weights=None)\n",
    "    \n",
    "    # Replace classifier\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=in_features, out_features=num_classes),\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom CNN as a third architecture option\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Third conv block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # Calculate input size to the classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False) as t:\n",
    "        for images, labels in t:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            t.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to conduct an experiment\n",
    "def run_experiment(experiment_name, model, train_dataset, valid_dataset, test_dataset, \n",
    "                  hyperparams, batch_size=64, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Run a full training experiment with given hyperparameters\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} Running experiment: {experiment_name} {'='*20}\")\n",
    "    for key, value in hyperparams.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    if hyperparams['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'], \n",
    "                              weight_decay=hyperparams['weight_decay'])\n",
    "    elif hyperparams['optimizer'] == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=hyperparams['learning_rate'], \n",
    "                             momentum=0.9, weight_decay=hyperparams['weight_decay'])\n",
    "    \n",
    "    # Initialize criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize scheduler\n",
    "    if hyperparams['scheduler'] == 'plateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    elif hyperparams['scheduler'] == 'cosine':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    best_val_acc = 0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train and validate\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        valid_loss, valid_acc = validate(model, valid_loader, criterion, device)\n",
    "        \n",
    "        # Scheduler step\n",
    "        if hyperparams['scheduler'] == 'plateau':\n",
    "            scheduler.step(valid_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if valid_acc > best_val_acc:\n",
    "            best_val_acc = valid_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_time/60:.2f} minutes\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_acc, all_preds, all_labels = evaluate(model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'name': experiment_name,\n",
    "        'hyperparams': hyperparams,\n",
    "        'train_losses': train_losses,\n",
    "        'valid_losses': valid_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'valid_accuracies': valid_accuracies,\n",
    "        'test_accuracy': test_acc,\n",
    "        'confusion_matrix': cm,\n",
    "        'model_state': best_model_wts,\n",
    "        'all_preds': all_preds,\n",
    "        'all_labels': all_labels\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Few-shot learning implementation =======\n",
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "    \n",
    "    def forward(self, support_images, support_labels, query_images):\n",
    "        \"\"\"\n",
    "        Implements the forward pass of Prototypical Networks\n",
    "        \n",
    "        Args:\n",
    "            support_images: support set images [n_classes * n_shots, channels, height, width]\n",
    "            support_labels: support set labels [n_classes * n_shots]\n",
    "            query_images: query set images [n_queries, channels, height, width]\n",
    "        \n",
    "        Returns:\n",
    "            query_logits: classification logits for the query images\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        support_features = self.backbone(support_images)  # [n_classes * n_shots, feature_dim]\n",
    "        query_features = self.backbone(query_images)      # [n_queries, feature_dim]\n",
    "        \n",
    "        # Compute class prototypes\n",
    "        n_classes = len(torch.unique(support_labels))\n",
    "        prototypes = torch.zeros(n_classes, support_features.shape[1], device=support_features.device)\n",
    "        \n",
    "        for c in range(n_classes):\n",
    "            # Select features of class c\n",
    "            class_mask = (support_labels == c)\n",
    "            class_features = support_features[class_mask]\n",
    "            # Average features to get the prototype\n",
    "            prototypes[c] = class_features.mean(dim=0)\n",
    "        \n",
    "        # Compute distances between query features and prototypes\n",
    "        # Expand dimensions for broadcasting\n",
    "        query_features = query_features.unsqueeze(1)  # [n_queries, 1, feature_dim]\n",
    "        prototypes = prototypes.unsqueeze(0)          # [1, n_classes, feature_dim]\n",
    "        \n",
    "        # Compute Euclidean distances\n",
    "        distances = torch.sum((query_features - prototypes)**2, dim=2)\n",
    "        \n",
    "        # Convert distances to logits (negative distances)\n",
    "        return -distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_evaluation(backbone, test_dataset, device, n_way=5, n_shot=5, n_query=15, n_episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluates the backbone on few-shot classification tasks\n",
    "    \"\"\"\n",
    "    backbone.eval()\n",
    "    \n",
    "    # Function to create few-shot tasks\n",
    "    def create_episode(dataset, n_way, n_shot, n_query):\n",
    "        # Sample n_way classes\n",
    "        classes = random.sample(range(len(dataset.classes)), n_way)\n",
    "        \n",
    "        # Initialize tensors to store images and labels\n",
    "        support_images = []\n",
    "        support_labels = []\n",
    "        query_images = []\n",
    "        query_labels = []\n",
    "        \n",
    "        # For each class, sample n_shot and n_query examples\n",
    "        for i, cls in enumerate(classes):\n",
    "            # Get indices of all examples from this class\n",
    "            class_indices = [idx for idx, (_, label) in enumerate(dataset) if label == cls]\n",
    "            # Sample support and query sets\n",
    "            support_indices = random.sample(class_indices, n_shot)\n",
    "            remaining_indices = [idx for idx in class_indices if idx not in support_indices]\n",
    "            query_indices = random.sample(remaining_indices, min(n_query, len(remaining_indices)))\n",
    "            \n",
    "            # Add to support and query sets\n",
    "            for idx in support_indices:\n",
    "                image, _ = dataset[idx]\n",
    "                support_images.append(image)\n",
    "                support_labels.append(i)  # Use an index from 0 to n_way-1 as the label\n",
    "            \n",
    "            for idx in query_indices:\n",
    "                image, _ = dataset[idx]\n",
    "                query_images.append(image)\n",
    "                query_labels.append(i)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "        \n",
    "        return support_images, support_labels, query_images, query_labels\n",
    "    \n",
    "    # Create prototypical network\n",
    "    proto_net = PrototypicalNetworks(backbone).to(device)\n",
    "    \n",
    "    # List to store accuracies\n",
    "    accuracies = []\n",
    "    \n",
    "    # Evaluate over multiple episodes\n",
    "    for episode in tqdm(range(n_episodes), desc=\"Few-shot evaluation\"):\n",
    "        # Create an episode (task)\n",
    "        support_images, support_labels, query_images, query_labels = create_episode(\n",
    "            test_dataset, n_way, n_shot, n_query\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        support_images = support_images.to(device)\n",
    "        support_labels = support_labels.to(device)\n",
    "        query_images = query_images.to(device)\n",
    "        query_labels = query_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            query_logits = proto_net(support_images, support_labels, query_images)\n",
    "            _, query_preds = torch.max(query_logits, dim=1)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (query_preds == query_labels).float().mean().item() * 100\n",
    "            accuracies.append(accuracy)\n",
    "    \n",
    "    # Return average accuracy\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    \n",
    "    print(f\"Few-shot learning ({n_way}-way, {n_shot}-shot): {avg_accuracy:.2f}% ± {std_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor for few-shot learning\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Use a pre-trained model but remove the final layer\n",
    "        self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        # Remove the classifier\n",
    "        self.features = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        # Add a flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement ensemble prediction\n",
    "def ensemble_prediction(models, test_loader, device, method='hard'):\n",
    "    \"\"\"\n",
    "    Implement ensemble prediction using multiple models\n",
    "    \n",
    "    Args:\n",
    "        models: List of trained models\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Device to run on\n",
    "        method: 'hard' for majority voting or 'soft' for probability averaging\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Ensemble accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    if not models:\n",
    "        return 0.0, [], []\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "                probabilities.append(probs.cpu())\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        all_probs.append(torch.cat(probabilities, dim=0).numpy())\n",
    "    \n",
    "    # Get true labels\n",
    "    true_labels = []\n",
    "    for _, labels in test_loader:\n",
    "        true_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Create ensemble predictions\n",
    "    if method == 'hard':\n",
    "        # Majority voting\n",
    "        ensemble_preds = []\n",
    "        for i in range(len(true_labels)):\n",
    "            votes = [all_predictions[j][i] for j in range(len(models))]\n",
    "            # Count occurrences of each class\n",
    "            vote_counts = np.bincount(votes, minlength=num_classes)\n",
    "            # Select class with most votes\n",
    "            ensemble_preds.append(np.argmax(vote_counts))\n",
    "    else:  # 'soft' voting\n",
    "        # Average probabilities\n",
    "        ensemble_probs = np.mean(all_probs, axis=0)\n",
    "        ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(ensemble_preds) == np.array(true_labels)) * 100\n",
    "    \n",
    "    return accuracy, ensemble_preds, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIGURATIONS\n",
    "# 1. Architecture Comparison (removed ResNet)\n",
    "architectures = {\n",
    "    'efficientnet': create_efficientnet_model(num_classes),\n",
    "    'custom_cnn': CustomCNN(num_classes)\n",
    "}\n",
    "\n",
    "# 2. Hyperparameter Configurations for Training Process\n",
    "training_hyperparams = [\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'sgd', 'learning_rate': 0.01, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'cosine', 'weight_decay': 0.0001}\n",
    "]\n",
    "\n",
    "# 3. Hyperparameter Configurations for Regularization\n",
    "regularization_hyperparams = [\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.001},\n",
    "    {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# 4. Data Augmentation Experiments\n",
    "# We'll use a modified version of the train_dataset for each transform\n",
    "augmentation_datasets = {}\n",
    "\n",
    "# Apply each transform to create new datasets\n",
    "for name, transform in standard_transforms.items():\n",
    "    augmentation_datasets[name] = ImageFolder(\n",
    "        root='data/train', \n",
    "        transform=transform\n",
    "    )\n",
    "    # Create a subset of the data\n",
    "    augmentation_datasets[name] = create_subset_dataset(augmentation_datasets[name], num_samples=TRAIN_SUBSET_SIZE)\n",
    "\n",
    "# Add advanced augmentation\n",
    "for name, transform in advanced_transforms.items():\n",
    "    augmentation_datasets[name] = ImageFolder(\n",
    "        root='data/train', \n",
    "        transform=transform\n",
    "    )\n",
    "    # Create a subset of the data\n",
    "    augmentation_datasets[name] = create_subset_dataset(augmentation_datasets[name], num_samples=TRAIN_SUBSET_SIZE)\n",
    "\n",
    "# Dictionary to store results of all experiments\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ARCHITECTURE COMPARISON ==============================\n",
      "\n",
      "Training efficientnet...\n",
      "\n",
      "==================== Running experiment: Architecture_efficientnet ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c9b77717764bee9b6f6134b76edc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.9279 | Train Acc: 68.56%\n",
      "Valid Loss: 0.6850 | Valid Acc: 76.35%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504c04511e024c53baea2af02c56475a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.4403 | Train Acc: 84.61%\n",
      "Valid Loss: 0.7002 | Valid Acc: 76.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2fef615d9c43419a21b57dcdd4c2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.3044 | Train Acc: 89.41%\n",
      "Valid Loss: 0.7410 | Valid Acc: 77.75%\n",
      "Training completed in 2.85 minutes\n",
      "Test Accuracy: 78.66%\n",
      "\n",
      "Training custom_cnn...\n",
      "\n",
      "==================== Running experiment: Architecture_custom_cnn ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f6a965fac44c9880387995a1c0d0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 2.1121 | Train Acc: 20.19%\n",
      "Valid Loss: 2.1781 | Valid Acc: 19.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2c7f583e9f4fabbf87a04f801cdc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 1.9828 | Train Acc: 23.55%\n",
      "Valid Loss: 1.9764 | Valid Acc: 24.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804c6f61427e49dd83a2431695c10277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 1.9205 | Train Acc: 26.07%\n",
      "Valid Loss: 1.8664 | Valid Acc: 28.95%\n",
      "Training completed in 3.26 minutes\n",
      "Test Accuracy: 28.48%\n"
     ]
    }
   ],
   "source": [
    "# ==== RUN EXPERIMENTS ====\n",
    "# 1. Architecture Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" ARCHITECTURE COMPARISON \" + \"=\"*30)\n",
    "architecture_results = {}\n",
    "\n",
    "for arch_name, model in architectures.items():\n",
    "    print(f\"\\nTraining {arch_name}...\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    hyperparams = {\n",
    "        'optimizer': 'adam',\n",
    "        'learning_rate': 0.001,\n",
    "        'scheduler': 'plateau',\n",
    "        'weight_decay': 0.0001\n",
    "    }\n",
    "    \n",
    "    results = run_experiment(\n",
    "        f\"Architecture_{arch_name}\",\n",
    "        model, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,  # Larger batch size for faster training\n",
    "        num_epochs=3  # Further reduced epochs for faster comparison\n",
    "    )\n",
    "    \n",
    "    architecture_results[arch_name] = results\n",
    "    all_results[f\"Architecture_{arch_name}\"] = results\n",
    "    \n",
    "    # Save model state\n",
    "    torch.save(model.state_dict(), f\"{arch_name}_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TRAINING HYPERPARAMETERS COMPARISON ==============================\n",
      "Using best architecture: efficientnet\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_1 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c5fc7025064cb085d3eb7243cdd010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.2790 | Train Acc: 90.25%\n",
      "Valid Loss: 0.7471 | Valid Acc: 78.45%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db150823fbc24980bbb2db8451c7a360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1753 | Train Acc: 93.88%\n",
      "Valid Loss: 0.8772 | Valid Acc: 77.80%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6e53facdba410e8f4e6448fcdb8e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1549 | Train Acc: 94.74%\n",
      "Valid Loss: 0.9024 | Valid Acc: 77.64%\n",
      "Training completed in 2.94 minutes\n",
      "Test Accuracy: 78.65%\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_2 ====================\n",
      "optimizer: sgd\n",
      "learning_rate: 0.01\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c73d3826290438a81b31f9474c0427c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.010000\n",
      "Train Loss: 0.1160 | Train Acc: 96.08%\n",
      "Valid Loss: 0.6227 | Valid Acc: 81.69%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6931eaf9b674061aa97f2d9e9bb0bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.010000\n",
      "Train Loss: 0.0600 | Train Acc: 98.35%\n",
      "Valid Loss: 0.6534 | Valid Acc: 82.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed8db1c5cad4b95803415400af4f0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.010000\n",
      "Train Loss: 0.0407 | Train Acc: 98.81%\n",
      "Valid Loss: 0.6636 | Valid Acc: 82.34%\n",
      "Training completed in 2.93 minutes\n",
      "Test Accuracy: 82.46%\n",
      "\n",
      "==================== Running experiment: Training_Hyperparams_3 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: cosine\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5f2e322c914170ae1a15225104b069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.000750\n",
      "Train Loss: 0.2178 | Train Acc: 92.89%\n",
      "Valid Loss: 0.8940 | Valid Acc: 76.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0676f5251a974b33b3fbe6c72f8c360d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.000250\n",
      "Train Loss: 0.1307 | Train Acc: 95.79%\n",
      "Valid Loss: 0.7588 | Valid Acc: 80.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29c7e29a3514fd3b3226758b5daba09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.000000\n",
      "Train Loss: 0.0443 | Train Acc: 98.59%\n",
      "Valid Loss: 0.7204 | Valid Acc: 82.25%\n",
      "Training completed in 2.97 minutes\n",
      "Test Accuracy: 81.83%\n"
     ]
    }
   ],
   "source": [
    "# 2. Training Hyperparameters Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" TRAINING HYPERPARAMETERS COMPARISON \" + \"=\"*30)\n",
    "training_results = {}\n",
    "\n",
    "# Use the best architecture from the previous experiment\n",
    "best_arch = max(architecture_results, key=lambda k: architecture_results[k]['test_accuracy'])\n",
    "print(f\"Using best architecture: {best_arch}\")\n",
    "\n",
    "for i, hyperparams in enumerate(training_hyperparams):\n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model = model.to(device)\n",
    "    \n",
    "    experiment_name = f\"Training_Hyperparams_{i+1}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    training_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== REGULARIZATION HYPERPARAMETERS COMPARISON ==============================\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_1 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e83777ce8e4cb7af56da2a88ff4ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.1769 | Train Acc: 94.10%\n",
      "Valid Loss: 0.9045 | Valid Acc: 76.70%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cad1a0ab794e05abd689ca40fa5401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1319 | Train Acc: 95.69%\n",
      "Valid Loss: 0.8474 | Valid Acc: 78.41%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c62abc682124ca6b70eead894e15c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1040 | Train Acc: 96.41%\n",
      "Valid Loss: 0.8744 | Valid Acc: 78.56%\n",
      "Training completed in 3.03 minutes\n",
      "Test Accuracy: 78.22%\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_2 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ea6f1c50b146838caf1cd8a84b065a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.1489 | Train Acc: 94.94%\n",
      "Valid Loss: 0.8511 | Valid Acc: 77.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bfadc9c1de4de9a5352fb905b8dbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1294 | Train Acc: 95.78%\n",
      "Valid Loss: 0.8810 | Valid Acc: 75.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2b7d33247b442db4b7a129267ae5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1630 | Train Acc: 94.84%\n",
      "Valid Loss: 0.9844 | Valid Acc: 74.42%\n",
      "Training completed in 2.97 minutes\n",
      "Test Accuracy: 77.78%\n",
      "\n",
      "==================== Running experiment: Regularization_Hyperparams_3 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df014b5c36454894b9772f5c44509b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.1582 | Train Acc: 94.84%\n",
      "Valid Loss: 0.9525 | Valid Acc: 76.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce8b31beff34a1a89dff7bb70c6aac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.1014 | Train Acc: 96.65%\n",
      "Valid Loss: 0.9779 | Valid Acc: 76.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62569b0f3ea6479297e9cce23af7f267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.0718 | Train Acc: 97.49%\n",
      "Valid Loss: 1.1217 | Valid Acc: 76.29%\n",
      "Training completed in 2.99 minutes\n",
      "Test Accuracy: 76.92%\n"
     ]
    }
   ],
   "source": [
    "# 3. Regularization Hyperparameters Comparison\n",
    "print(\"\\n\" + \"=\"*30 + \" REGULARIZATION HYPERPARAMETERS COMPARISON \" + \"=\"*30)\n",
    "regularization_results = {}\n",
    "\n",
    "for i, hyperparams in enumerate(regularization_hyperparams):\n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model = model.to(device)\n",
    "    \n",
    "    experiment_name = f\"Regularization_Hyperparams_{i+1}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    regularization_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== DATA AUGMENTATION COMPARISON ==============================\n",
      "\n",
      "Testing standard augmentation: baseline\n",
      "\n",
      "==================== Running experiment: Augmentation_baseline ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6285287673c74716930b47778aaa39d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6595 | Train Acc: 78.45%\n",
      "Valid Loss: 0.5651 | Valid Acc: 79.39%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0289d43298a146d9ba50e1d67678f6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3136 | Train Acc: 89.44%\n",
      "Valid Loss: 0.6970 | Valid Acc: 77.54%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23cfc9caeaf4bdd95f3198f8b27871f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1880 | Train Acc: 93.26%\n",
      "Valid Loss: 0.7145 | Valid Acc: 79.96%\n",
      "Training completed in 3.05 minutes\n",
      "Test Accuracy: 79.24%\n",
      "\n",
      "Testing standard augmentation: horizontal_flip\n",
      "\n",
      "==================== Running experiment: Augmentation_horizontal_flip ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cc42e33ded41b29c5e9e2d61d5cabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6106 | Train Acc: 79.53%\n",
      "Valid Loss: 0.5582 | Valid Acc: 80.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4003b3e3b6a8436092b3a867e996b9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3274 | Train Acc: 88.10%\n",
      "Valid Loss: 0.5571 | Valid Acc: 81.12%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb8d05510ad430baddd33e0049c8214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2320 | Train Acc: 92.11%\n",
      "Valid Loss: 0.6991 | Valid Acc: 79.61%\n",
      "Training completed in 3.05 minutes\n",
      "Test Accuracy: 80.74%\n",
      "\n",
      "Testing standard augmentation: rotation\n",
      "\n",
      "==================== Running experiment: Augmentation_rotation ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d74ca4d64744bba50597f2cc6c43a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5986 | Train Acc: 79.36%\n",
      "Valid Loss: 0.5277 | Valid Acc: 81.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24e35b3e91e430da4b3a3fb12e6d39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3567 | Train Acc: 87.35%\n",
      "Valid Loss: 0.5881 | Valid Acc: 80.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f35db8cbf54cdbbc29378ab707b119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2661 | Train Acc: 90.38%\n",
      "Valid Loss: 0.6514 | Valid Acc: 79.33%\n",
      "Training completed in 3.08 minutes\n",
      "Test Accuracy: 81.08%\n",
      "\n",
      "Testing standard augmentation: color_jitter\n",
      "\n",
      "==================== Running experiment: Augmentation_color_jitter ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bac0afd0c0c4fdb8372a3dee53cf387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5736 | Train Acc: 80.39%\n",
      "Valid Loss: 0.5433 | Valid Acc: 81.20%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf789ef1d0074bc38d7dfae457d40751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3257 | Train Acc: 88.75%\n",
      "Valid Loss: 0.5960 | Valid Acc: 80.45%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59aed02b1ddf45c5b95810e9faf587ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2436 | Train Acc: 91.50%\n",
      "Valid Loss: 0.6208 | Valid Acc: 80.53%\n",
      "Training completed in 3.52 minutes\n",
      "Test Accuracy: 80.99%\n"
     ]
    }
   ],
   "source": [
    "# This code contains the completion of the comprehensive experiments\n",
    "\n",
    "# 4. Data Augmentation Experiments\n",
    "print(\"\\n\" + \"=\"*30 + \" DATA AUGMENTATION COMPARISON \" + \"=\"*30)\n",
    "augmentation_results = {}\n",
    "\n",
    "# Create a new model with the best architecture\n",
    "best_arch = 'efficientnet'  # Default to efficientnet since we removed resnet\n",
    "model = architectures[best_arch]\n",
    "model = model.to(device)\n",
    "\n",
    "# Baseline hyperparameters\n",
    "hyperparams = {\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 0.001,\n",
    "    'scheduler': 'plateau',\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "# Standard augmentations\n",
    "for aug_name in ['baseline', 'horizontal_flip', 'rotation', 'color_jitter']:\n",
    "    print(f\"\\nTesting standard augmentation: {aug_name}\")\n",
    "    \n",
    "    experiment_name = f\"Augmentation_{aug_name}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model,\n",
    "        augmentation_datasets[aug_name],\n",
    "        valid_dataset,\n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    augmentation_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing advanced augmentation: cutout\n",
      "\n",
      "==================== Running experiment: Augmentation_cutout ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfae0dc09ac440ed87e23cb5fdbbb9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.5382 | Train Acc: 81.51%\n",
      "Valid Loss: 0.4904 | Valid Acc: 81.97%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86fe3edbfc8415a8348ab5e66cc9f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3339 | Train Acc: 88.00%\n",
      "Valid Loss: 0.5744 | Valid Acc: 80.79%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9b4bd4223b4f629ab65c73854b759a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.2485 | Train Acc: 91.15%\n",
      "Valid Loss: 0.5690 | Valid Acc: 81.30%\n",
      "Training completed in 3.06 minutes\n",
      "Test Accuracy: 82.64%\n"
     ]
    }
   ],
   "source": [
    "# Advanced augmentation (cutout)\n",
    "print(\"\\nTesting advanced augmentation: cutout\")\n",
    "experiment_name = \"Augmentation_cutout\"\n",
    "results = run_experiment(\n",
    "    experiment_name,\n",
    "    model,\n",
    "    augmentation_datasets['cutout'],\n",
    "    valid_dataset,\n",
    "    test_dataset,\n",
    "    hyperparams,\n",
    "    batch_size=128,\n",
    "    num_epochs=3\n",
    ")\n",
    "augmentation_results[experiment_name] = results\n",
    "all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== FEW-SHOT LEARNING ==============================\n",
      "Evaluating few-shot learning capabilities...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3aa26be9d024f0f87a163e10faf0f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Few-shot evaluation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot learning (5-way, 5-shot): 73.60% ± 7.98%\n"
     ]
    }
   ],
   "source": [
    "# 5. Few-shot Learning Experiment\n",
    "print(\"\\n\" + \"=\"*30 + \" FEW-SHOT LEARNING \" + \"=\"*30)\n",
    "\n",
    "# Create a feature extractor for few-shot learning\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "\n",
    "# Modify few_shot_evaluation to handle Subset objects\n",
    "def few_shot_evaluation(backbone, dataset, device, n_way=5, n_shot=5, n_query=15, n_episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluates the backbone on few-shot classification tasks\n",
    "    \"\"\"\n",
    "    backbone.eval()\n",
    "    \n",
    "    # Get the original dataset if this is a subset\n",
    "    original_dataset = dataset\n",
    "    if isinstance(dataset, Subset):\n",
    "        # Get the original dataset\n",
    "        original_dataset = dataset.dataset\n",
    "        # Get the class mapping from the original dataset\n",
    "        class_indices = {}\n",
    "        for idx in dataset.indices:\n",
    "            _, label = original_dataset[idx]\n",
    "            if label not in class_indices:\n",
    "                class_indices[label] = []\n",
    "            class_indices[label].append(idx)\n",
    "    else:\n",
    "        # If not a subset, create the mapping directly\n",
    "        class_indices = {}\n",
    "        for idx, (_, label) in enumerate(dataset):\n",
    "            if label not in class_indices:\n",
    "                class_indices[label] = []\n",
    "            class_indices[label].append(idx)\n",
    "    \n",
    "    # Create few-shot tasks function\n",
    "    def create_episode(n_way, n_shot, n_query):\n",
    "        # Sample n_way classes\n",
    "        available_classes = list(class_indices.keys())\n",
    "        if len(available_classes) < n_way:\n",
    "            print(f\"Warning: Only {len(available_classes)} classes available, but {n_way} requested.\")\n",
    "            n_way = len(available_classes)\n",
    "        \n",
    "        classes = random.sample(available_classes, n_way)\n",
    "        \n",
    "        # Initialize tensors to store images and labels\n",
    "        support_images = []\n",
    "        support_labels = []\n",
    "        query_images = []\n",
    "        query_labels = []\n",
    "        \n",
    "        # For each class, sample n_shot and n_query examples\n",
    "        for i, cls in enumerate(classes):\n",
    "            # Get indices of all examples from this class\n",
    "            cls_indices = class_indices[cls]\n",
    "            \n",
    "            # Sample support and query sets\n",
    "            if len(cls_indices) <= n_shot:\n",
    "                support_indices = cls_indices\n",
    "                query_indices = []\n",
    "            else:\n",
    "                # Randomly sample without replacement\n",
    "                random.shuffle(cls_indices)\n",
    "                support_indices = cls_indices[:n_shot]\n",
    "                query_indices = cls_indices[n_shot:n_shot+min(n_query, len(cls_indices)-n_shot)]\n",
    "            \n",
    "            # Add to support and query sets\n",
    "            for idx in support_indices:\n",
    "                image, _ = original_dataset[idx]\n",
    "                support_images.append(image)\n",
    "                support_labels.append(i)  # Use an index from 0 to n_way-1 as the label\n",
    "            \n",
    "            for idx in query_indices:\n",
    "                image, _ = original_dataset[idx]\n",
    "                query_images.append(image)\n",
    "                query_labels.append(i)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        support_images = torch.stack(support_images)\n",
    "        support_labels = torch.tensor(support_labels)\n",
    "        query_images = torch.stack(query_images)\n",
    "        query_labels = torch.tensor(query_labels)\n",
    "        \n",
    "        return support_images, support_labels, query_images, query_labels\n",
    "    \n",
    "    # Create prototypical network\n",
    "    proto_net = PrototypicalNetworks(backbone).to(device)\n",
    "    \n",
    "    # List to store accuracies\n",
    "    accuracies = []\n",
    "    \n",
    "    # Evaluate over multiple episodes\n",
    "    for episode in tqdm(range(n_episodes), desc=\"Few-shot evaluation\"):\n",
    "        # Create an episode (task)\n",
    "        support_images, support_labels, query_images, query_labels = create_episode(\n",
    "            n_way, n_shot, n_query\n",
    "        )\n",
    "        \n",
    "        # Skip episodes with too few query examples\n",
    "        if len(query_images) < 5:\n",
    "            continue\n",
    "        \n",
    "        # Move to device\n",
    "        support_images = support_images.to(device)\n",
    "        support_labels = support_labels.to(device)\n",
    "        query_images = query_images.to(device)\n",
    "        query_labels = query_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            query_logits = proto_net(support_images, support_labels, query_images)\n",
    "            _, query_preds = torch.max(query_logits, dim=1)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (query_preds == query_labels).float().mean().item() * 100\n",
    "            accuracies.append(accuracy)\n",
    "    \n",
    "    # Return average accuracy\n",
    "    if accuracies:\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        std_accuracy = np.std(accuracies)\n",
    "    else:\n",
    "        avg_accuracy = 0\n",
    "        std_accuracy = 0\n",
    "    \n",
    "    print(f\"Few-shot learning ({n_way}-way, {n_shot}-shot): {avg_accuracy:.2f}% ± {std_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy, std_accuracy\n",
    "\n",
    "print(\"Evaluating few-shot learning capabilities...\")\n",
    "few_shot_acc, few_shot_std = few_shot_evaluation(\n",
    "    feature_extractor, \n",
    "    test_dataset, \n",
    "    device, \n",
    "    n_way=5,    # 5-way classification \n",
    "    n_shot=5,   # 5-shot learning\n",
    "    n_query=15, # 15 query samples per class\n",
    "    n_episodes=20  # 20 episodes for quick evaluation\n",
    ")\n",
    "\n",
    "# After the few-shot evaluation, add this:\n",
    "few_shot_results = {\n",
    "    'name': 'Few-shot Learning (5-way, 5-shot)',\n",
    "    'accuracy': few_shot_acc,\n",
    "    'std': few_shot_std\n",
    "}\n",
    "all_results['few_shot'] = few_shot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== REDUCED TRAINING SET EXPERIMENT ==============================\n",
      "\n",
      "Testing with reduced training set size: 4000 samples\n",
      "\n",
      "==================== Running experiment: Reduced_Train_Size_4000 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbea067dc5242369278ae8b39a61b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.7130 | Train Acc: 75.08%\n",
      "Valid Loss: 0.6234 | Valid Acc: 77.89%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538bb00ba47b43d5ab900cc0947bc1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.3077 | Train Acc: 89.92%\n",
      "Valid Loss: 0.6361 | Valid Acc: 79.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c599cc534900491bab4b0e9805adb4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1832 | Train Acc: 93.75%\n",
      "Valid Loss: 0.8119 | Valid Acc: 77.41%\n",
      "Training completed in 1.96 minutes\n",
      "Test Accuracy: 78.61%\n",
      "\n",
      "Testing with reduced training set size: 2000 samples\n",
      "\n",
      "==================== Running experiment: Reduced_Train_Size_2000 ====================\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "scheduler: plateau\n",
      "weight_decay: 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6d5d1a90294656a37d329c425bbc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | LR: 0.001000\n",
      "Train Loss: 0.6666 | Train Acc: 78.65%\n",
      "Valid Loss: 0.6491 | Valid Acc: 77.36%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308b3198591a4990a9fdec2f23238b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | LR: 0.001000\n",
      "Train Loss: 0.2758 | Train Acc: 91.25%\n",
      "Valid Loss: 0.6237 | Valid Acc: 79.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2089a447799c4d9a85cdef5cd705e33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | LR: 0.001000\n",
      "Train Loss: 0.1061 | Train Acc: 96.70%\n",
      "Valid Loss: 0.7710 | Valid Acc: 77.84%\n",
      "Training completed in 1.24 minutes\n",
      "Test Accuracy: 79.62%\n"
     ]
    }
   ],
   "source": [
    "# 6. Reduced Training Set Size Experiment\n",
    "print(\"\\n\" + \"=\"*30 + \" REDUCED TRAINING SET EXPERIMENT \" + \"=\"*30)\n",
    "\n",
    "# Create even smaller training subsets\n",
    "smaller_train_sizes = [TRAIN_SUBSET_SIZE // 2, TRAIN_SUBSET_SIZE // 4]\n",
    "reduction_results = {}\n",
    "\n",
    "for size in smaller_train_sizes:\n",
    "    print(f\"\\nTesting with reduced training set size: {size} samples\")\n",
    "    \n",
    "    # Create reduced training dataset\n",
    "    reduced_train_dataset = create_subset_dataset(full_train_dataset, num_samples=size)\n",
    "    \n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model = model.to(device)\n",
    "    \n",
    "    experiment_name = f\"Reduced_Train_Size_{size}\"\n",
    "    results = run_experiment(\n",
    "        experiment_name,\n",
    "        model,\n",
    "        reduced_train_dataset,\n",
    "        valid_dataset,\n",
    "        test_dataset,\n",
    "        hyperparams,\n",
    "        batch_size=128,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    \n",
    "    reduction_results[experiment_name] = results\n",
    "    all_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ENSEMBLE METHODS ==============================\n",
      "\n",
      "Training ensemble model 1/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac620c4c813947aca5de6a8791580074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Acc: 88.02% | Valid Acc: 79.76%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1487883c0986428f8885b1e69ff651ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 | Train Acc: 94.50% | Valid Acc: 79.30%\n",
      "\n",
      "Training ensemble model 2/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10a2a81a0804e3eb615dc9c5e7b465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Acc: 90.86% | Valid Acc: 77.64%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4040c03e980e490aa966871553429139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 | Train Acc: 94.67% | Valid Acc: 79.44%\n",
      "\n",
      "Training ensemble model 3/3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fb0a483fb547bbb401db6ea592e7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Acc: 90.70% | Valid Acc: 77.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2079aedd644fc98899ab30197b7b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 | Train Acc: 94.77% | Valid Acc: 76.58%\n",
      "Testing ensemble methods...\n",
      "Hard voting ensemble accuracy: 76.96%\n",
      "Soft voting ensemble accuracy: 76.96%\n"
     ]
    }
   ],
   "source": [
    "# 7. Ensemble Methods\n",
    "print(\"\\n\" + \"=\"*30 + \" ENSEMBLE METHODS \" + \"=\"*30)\n",
    "\n",
    "# Instead of trying to load saved model states which have different architectures,\n",
    "# let's train a few simple models separately for the ensemble\n",
    "\n",
    "# Create test data loader for ensemble evaluation\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "# Train 3 different models with slight variations for the ensemble\n",
    "ensemble_models = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\nTraining ensemble model {i+1}/3...\")\n",
    "    \n",
    "    # Create a new model with the best architecture\n",
    "    model = architectures[best_arch]\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Use slightly different hyperparameters for each model\n",
    "    lr = 0.001 * (1.0 + i * 0.2)  # Vary learning rate\n",
    "    wd = 0.0001 * (1.0 + i * 0.5)  # Vary weight decay\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    \n",
    "    # Create train loader with subset and slightly different transforms\n",
    "    if i == 0:\n",
    "        transform = standard_transforms['baseline']\n",
    "    elif i == 1:\n",
    "        transform = standard_transforms['horizontal_flip']\n",
    "    else:\n",
    "        transform = standard_transforms['color_jitter']\n",
    "    \n",
    "    # Sample a subset of the training data\n",
    "    subset_indices = torch.randperm(len(train_dataset))[:int(len(train_dataset)*0.8)]\n",
    "    subset_dataset = Subset(train_dataset, subset_indices)\n",
    "    \n",
    "    # Create data loader\n",
    "    train_loader = DataLoader(subset_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Train for a few quick epochs\n",
    "    for epoch in range(2):  # Just 2 epochs for quick ensemble creation\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        valid_loss, valid_acc = validate(model, valid_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/2 | Train Acc: {train_acc:.2f}% | Valid Acc: {valid_acc:.2f}%\")\n",
    "    \n",
    "    # Add to ensemble\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "print(\"Testing ensemble methods...\")\n",
    "# Hard voting\n",
    "hard_accuracy, hard_preds, hard_labels = ensemble_prediction(\n",
    "    ensemble_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    method='hard'\n",
    ")\n",
    "print(f\"Hard voting ensemble accuracy: {hard_accuracy:.2f}%\")\n",
    "\n",
    "# Soft voting\n",
    "soft_accuracy, soft_preds, soft_labels = ensemble_prediction(\n",
    "    ensemble_models,\n",
    "    test_loader,\n",
    "    device,\n",
    "    method='soft'\n",
    ")\n",
    "print(f\"Soft voting ensemble accuracy: {soft_accuracy:.2f}%\")\n",
    "\n",
    "ensemble_results = {\n",
    "    'hard_voting': {\n",
    "        'accuracy': hard_accuracy,\n",
    "        'predictions': hard_preds,\n",
    "        'labels': hard_labels\n",
    "    },\n",
    "    'soft_voting': {\n",
    "        'accuracy': soft_accuracy,\n",
    "        'predictions': soft_preds,\n",
    "        'labels': soft_labels\n",
    "    }\n",
    "}\n",
    "all_results['ensemble'] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== RESULTS SUMMARY ==============================\n",
      "\n",
      "Architecture Comparison:\n",
      "efficientnet: 78.66%\n",
      "custom_cnn: 28.48%\n",
      "\n",
      "Training Hyperparameters Comparison:\n",
      "Training_Hyperparams_1 - {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'plateau', 'weight_decay': 0.0001}: 78.65%\n",
      "Training_Hyperparams_2 - {'optimizer': 'sgd', 'learning_rate': 0.01, 'scheduler': 'plateau', 'weight_decay': 0.0001}: 82.46%\n",
      "Training_Hyperparams_3 - {'optimizer': 'adam', 'learning_rate': 0.001, 'scheduler': 'cosine', 'weight_decay': 0.0001}: 81.83%\n",
      "\n",
      "Regularization Hyperparameters Comparison:\n",
      "Regularization_Hyperparams_1 - Weight Decay: 0.0001: 78.22%\n",
      "Regularization_Hyperparams_2 - Weight Decay: 0.001: 77.78%\n",
      "Regularization_Hyperparams_3 - Weight Decay: 0.0: 76.92%\n",
      "\n",
      "Data Augmentation Comparison:\n",
      "Augmentation_baseline: 79.24%\n",
      "Augmentation_horizontal_flip: 80.74%\n",
      "Augmentation_rotation: 81.08%\n",
      "Augmentation_color_jitter: 80.99%\n",
      "Augmentation_cutout: 82.64%\n",
      "\n",
      "Few-shot Learning (5-way, 5-shot): 73.60% ± 7.98%\n",
      "\n",
      "Reduced Training Set Size Comparison:\n",
      "Size 4000: 78.61%\n",
      "Size 2000: 79.62%\n",
      "\n",
      "Ensemble Hard Voting: 76.96%\n",
      "Ensemble Soft Voting: 76.96%\n"
     ]
    }
   ],
   "source": [
    "# 8. Summarize and Visualize Results\n",
    "print(\"\\n\" + \"=\"*30 + \" RESULTS SUMMARY \" + \"=\"*30)\n",
    "\n",
    "# 1. Architecture Comparison\n",
    "print(\"\\nArchitecture Comparison:\")\n",
    "for arch_name, results in architecture_results.items():\n",
    "    print(f\"{arch_name}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 2. Training Hyperparameters\n",
    "print(\"\\nTraining Hyperparameters Comparison:\")\n",
    "for name, results in training_results.items():\n",
    "    print(f\"{name} - {results['hyperparams']}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 3. Regularization Hyperparameters\n",
    "print(\"\\nRegularization Hyperparameters Comparison:\")\n",
    "for name, results in regularization_results.items():\n",
    "    print(f\"{name} - Weight Decay: {results['hyperparams']['weight_decay']}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 4. Data Augmentation\n",
    "print(\"\\nData Augmentation Comparison:\")\n",
    "for name, results in augmentation_results.items():\n",
    "    print(f\"{name}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 5. Few-shot Learning\n",
    "print(f\"\\nFew-shot Learning (5-way, 5-shot): {few_shot_results['accuracy']:.2f}% ± {few_shot_results['std']:.2f}%\")\n",
    "\n",
    "# 6. Reduced Training Set Size\n",
    "print(\"\\nReduced Training Set Size Comparison:\")\n",
    "for name, results in reduction_results.items():\n",
    "    size = name.split('_')[-1]\n",
    "    print(f\"Size {size}: {results['test_accuracy']:.2f}%\")\n",
    "\n",
    "# 7. Ensemble Methods\n",
    "print(f\"\\nEnsemble Hard Voting: {ensemble_results['hard_voting']['accuracy']:.2f}%\")\n",
    "print(f\"Ensemble Soft Voting: {ensemble_results['soft_voting']['accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations\n",
    "\n",
    "# 1. Plot test accuracies\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Architecture comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "arch_names = list(architecture_results.keys())\n",
    "arch_accs = [architecture_results[n]['test_accuracy'] for n in arch_names]\n",
    "plt.bar(arch_names, arch_accs)\n",
    "plt.title('Architecture Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Augmentation comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "aug_names = [name.split('_')[1] for name in augmentation_results.keys()]\n",
    "aug_accs = [augmentation_results[name]['test_accuracy'] for name in augmentation_results.keys()]\n",
    "plt.bar(aug_names, aug_accs)\n",
    "plt.title('Data Augmentation Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Reduced training set size\n",
    "plt.subplot(2, 2, 3)\n",
    "sizes = [name.split('_')[-1] for name in reduction_results.keys()]\n",
    "size_accs = [reduction_results[name]['test_accuracy'] for name in reduction_results.keys()]\n",
    "# Add the full dataset result\n",
    "sizes.append(str(TRAIN_SUBSET_SIZE))\n",
    "size_accs.append(all_results['Architecture_efficientnet']['test_accuracy'])\n",
    "plt.bar(sizes, size_accs)\n",
    "plt.title('Reduced Training Set Size')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Ensemble comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = ['Hard Voting', 'Soft Voting', 'Best Single Model']\n",
    "accuracies = [\n",
    "    ensemble_results['hard_voting']['accuracy'],\n",
    "    ensemble_results['soft_voting']['accuracy'],\n",
    "    max([results['test_accuracy'] for name, results in all_results.items() if 'test_accuracy' in results])\n",
    "]\n",
    "plt.bar(methods, accuracies)\n",
    "plt.title('Ensemble Methods Comparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiment_results_summary.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment results saved to 'experiment_results.json'\n",
      "Summary visualizations saved to 'experiment_results_summary.png'\n",
      "Full results including model states saved to 'full_experiment_results.pkl'\n",
      "\n",
      "============================== EXPERIMENTS COMPLETED ==============================\n"
     ]
    }
   ],
   "source": [
    "# Save all results to file\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy arrays to lists for JSON serialization\n",
    "def convert_numpy_to_list(obj):\n",
    "    # Handle NumPy scalars (int64, float32, etc.)\n",
    "    if isinstance(obj, np.number):\n",
    "        return obj.item()  # Convert to native Python type\n",
    "    # Handle NumPy arrays\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    # Handle dictionaries\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_numpy_to_list(v) for k, v in obj.items()}\n",
    "    # Handle lists and tuples\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return [convert_numpy_to_list(item) for item in obj]\n",
    "    # Return other objects unchanged\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Convert all results\n",
    "serializable_results = convert_numpy_to_list(all_results)\n",
    "\n",
    "# Remove model states which can't be serialized easily\n",
    "for key in serializable_results:\n",
    "    if isinstance(serializable_results[key], dict) and 'model_state' in serializable_results[key]:\n",
    "        del serializable_results[key]['model_state']\n",
    "\n",
    "# Save as JSON for easy viewing\n",
    "with open('experiment_results.json', 'w') as f:\n",
    "    try:\n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "        print(\"\\nExperiment results saved to 'experiment_results.json'\")\n",
    "    except TypeError as e:\n",
    "        print(f\"Error saving JSON: {e}\")\n",
    "        print(\"Trying to identify problematic fields...\")\n",
    "        # Try to identify problematic fields\n",
    "        for key in serializable_results:\n",
    "            try:\n",
    "                json.dumps(serializable_results[key])\n",
    "            except TypeError as e:\n",
    "                print(f\"Problematic field: {key}, Error: {e}\")\n",
    "                # Try to remove or fix this field\n",
    "                if isinstance(serializable_results[key], dict):\n",
    "                    for subkey in list(serializable_results[key].keys()):\n",
    "                        try:\n",
    "                            json.dumps(serializable_results[key][subkey])\n",
    "                        except TypeError:\n",
    "                            print(f\"Removing problematic subfield: {key}.{subkey}\")\n",
    "                            serializable_results[key][subkey] = str(serializable_results[key][subkey])\n",
    "        \n",
    "        # Try again with the fixed data\n",
    "        try:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "            print(\"Successfully saved JSON after fixing problematic fields\")\n",
    "        except TypeError:\n",
    "            print(\"Could not save JSON, falling back to simple format\")\n",
    "            # Save in a simpler format\n",
    "            with open('experiment_results_simple.txt', 'w') as f:\n",
    "                for key, value in serializable_results.items():\n",
    "                    f.write(f\"{key}: {str(value)}\\n\")\n",
    "\n",
    "print(\"Summary visualizations saved to 'experiment_results_summary.png'\")\n",
    "\n",
    "# Save full results including model states with pickle\n",
    "try:\n",
    "    with open('full_experiment_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    print(\"Full results including model states saved to 'full_experiment_results.pkl'\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save full results with model states. Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \" EXPERIMENTS COMPLETED \" + \"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
