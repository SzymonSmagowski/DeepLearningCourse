{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2Fa0l-8nTPM",
        "outputId": "5f5e67c2-8a11-4a9c-a5b6-9cf89df8a1bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lonXxb6KnTPN",
        "outputId": "820abfdd-8ec8-4602-e943-cfdd685a0855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repo dir : /content/DeepLearningCourse\n",
            "Data src : /content/drive/MyDrive/data/processed_cats.zip\n",
            "Data dst : /content/data\n",
            "Outputs dir : /content/drive/MyDrive/project3_outputs\n"
          ]
        }
      ],
      "source": [
        "import pathlib, os, subprocess, json, datetime, shutil\n",
        "\n",
        "REPO_URL = \"https://github.com/SzymonSmagowski/DeepLearningCourse.git\"\n",
        "BRANCH = \"main\"\n",
        "DATA_IN_DRIVE = \"data/processed_cats.zip\"\n",
        "\n",
        "ROOT_DRIVE = pathlib.Path(\"/content/drive/MyDrive\")\n",
        "DATA_SRC = ROOT_DRIVE / DATA_IN_DRIVE\n",
        "\n",
        "DATA_DST = pathlib.Path(\"/content/data\")\n",
        "REPO_DIR = pathlib.Path(\"/content\") / pathlib.Path(REPO_URL).stem\n",
        "OUTPUTS_DIR = ROOT_DRIVE / \"project3_outputs\"\n",
        "PROJECT_DIR = REPO_DIR / \"project_3\"\n",
        "\n",
        "print(\"Repo dir:\", REPO_DIR)\n",
        "print(\"Data src:\", DATA_SRC)\n",
        "print(\"Data dst:\", DATA_DST)\n",
        "print(\"Outputs dir:\", OUTPUTS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK6kPH70nTPN",
        "outputId": "0280fe6e-ca69-4420-c7f6-96dfb63f5789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepLearningCourse\n",
            "From https://github.com/SzymonSmagowski/DeepLearningCourse\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "if not REPO_DIR.exists():\n",
        "    !git clone -b \"$BRANCH\" \"$REPO_URL\" \"$REPO_DIR\"\n",
        "else:\n",
        "    %cd $REPO_DIR\n",
        "    !git pull origin \"$BRANCH\"\n",
        "    %cd -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdfKW9wAnTPN",
        "outputId": "a88b77ec-5e0b-4528-859d-72197c82d3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ dataset already present at /content/data/processed_cats.zip\n"
          ]
        }
      ],
      "source": [
        "import tarfile, time, shutil, os\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_NAME   = \"processed_cats.zip\"\n",
        "DATA_DST.mkdir(parents=True, exist_ok=True)            # ensures /content/data\n",
        "\n",
        "# full path once extracted in Colab\n",
        "LOCAL_DATA = DATA_DST / DATA_NAME\n",
        "DATA_ZIP = DATA_SRC / DATA_NAME\n",
        "\n",
        "# --- logic --------------------------------------------------\n",
        "if LOCAL_DATA.exists():\n",
        "    print(f\"✓ dataset already present at {LOCAL_DATA}\")\n",
        "elif DATA_SRC.exists():                                # extracted on Drive\n",
        "    try:\n",
        "        LOCAL_DATA.symlink_to(DATA_SRC, target_is_directory=True)\n",
        "        print(f\"🔗  Symlinked {DATA_SRC} → {LOCAL_DATA}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Symlink failed ({e.__class__.__name__}); copying …\")\n",
        "        t0 = time.time()\n",
        "        shutil.copytree(DATA_SRC, LOCAL_DATA, dirs_exist_ok=True)\n",
        "        print(f\"✓ copied in {time.time()-t0:.1f}s\")\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"Dataset not found!\\n\"\n",
        "        f\"Looked for either:\\n  • {DATA_SRC}\\n  • {DATA_ZIP}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q $LOCAL_DATA -d $DATA_DST"
      ],
      "metadata": {
        "id": "81-iLVuA_HR3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_ysUS4nnTPO",
        "outputId": "2a44f38f-f337-47d8-81ba-b09ad592b4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -r DeepLearningCourse/project_3/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "049hAfrTnTPO",
        "outputId": "54f80812-757d-40b8-c9e3-498b7d223d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▶️  Running DIFFUSION on config diffusion_fast_test.yaml\n",
            "💻 /usr/bin/python3 /content/DeepLearningCourse/project_3/train_diffusion.py\n",
            "2025-06-07 20:18:35.572685: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749327515.597555    6512 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749327515.604242    6512 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-07 20:18:35.626953: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: train_diffusion.py [-h] --config CONFIG [--resume RESUME]\n",
            "train_diffusion.py: error: the following arguments are required: --config\n",
            "❌  DIFFUSION / taskdiffusion_fast_test.yaml FAILED (exit 2)\n",
            "\n",
            "▶️  Running GAN on config gan_fast_test.yaml\n",
            "💻 /usr/bin/python3 /content/DeepLearningCourse/project_3/train_gan.py\n",
            "2025-06-07 20:18:44.946623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749327524.963409    6563 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749327524.967578    6563 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-07 20:18:44.982547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: train_gan.py [-h] --config CONFIG [--resume RESUME]\n",
            "train_gan.py: error: the following arguments are required: --config\n",
            "❌  GAN / taskgan_fast_test.yaml FAILED (exit 2)\n",
            "\n",
            "═══════════════════════════════════ SUMMARY ═══════════════════════════════════\n",
            "The following runs failed:\n",
            "  • DIFFUSION:configdiffusion_fast_test.yaml\n",
            "  • GAN:configgan_fast_test.yaml\n"
          ]
        }
      ],
      "source": [
        "import os, sys, time, tarfile, subprocess, textwrap, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "CONFIGS = [\n",
        "    ('DIFFUSION', 'diffusion_fast_test.yaml'),\n",
        "    ('GAN', 'gan_fast_test.yaml')\n",
        "#     ('DIFFUSION', 'diffusion_128.yaml'),\n",
        "#     ('DIFFUSION', 'diffusion_256.yaml'),\n",
        "#     ('GAN', 'gan_128.yaml'),\n",
        "#     ('GAN', 'gan_256.yaml'),\n",
        "]\n",
        "\n",
        "def run_and_tee(cmd, cwd, extra_env=None):\n",
        "    \"\"\"\n",
        "    Run *cmd* (list/str) inside *cwd*. Return exit-code.\n",
        "    \"\"\"\n",
        "    env = os.environ.copy()\n",
        "    if extra_env:\n",
        "        env.update(extra_env)\n",
        "\n",
        "    if isinstance(cmd, str):\n",
        "        cmd = cmd.split()\n",
        "\n",
        "    print(\"💻\", \" \".join(cmd))\n",
        "    proc = subprocess.Popen(\n",
        "        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
        "        cwd=str(cwd), env=env, text=True\n",
        "    )\n",
        "    for line in proc.stdout:\n",
        "        print(line, end=\"\")\n",
        "    proc.wait()\n",
        "    return proc.returncode\n",
        "\n",
        "# ─────────────────── main loop ───────────────────\n",
        "failed = []\n",
        "\n",
        "for model, config_name in CONFIGS:\n",
        "    model_path = PROJECT_DIR / model\n",
        "    mname      = model_path.stem\n",
        "    print(f\"\\n▶️  Running {model} on config {config_name}\")\n",
        "    config_path = PROJECT_DIR / 'configs' / config_name\n",
        "\n",
        "    executable = PROJECT_DIR / \\\n",
        "     ('train_diffusion.py' if model == 'DIFFUSION' else 'train_gan.py')\n",
        "    run_results = OUTPUTS_DIR / mname\n",
        "    cmd = [\n",
        "        sys.executable, str(executable)\n",
        "    ]\n",
        "    rc = run_and_tee(cmd, cwd=PROJECT_DIR)\n",
        "    if rc == 0:\n",
        "        print(f\"✅  {model} / {config_name} finished OK\")\n",
        "    else:\n",
        "        print(f\"❌  {model} / {config_name} FAILED (exit {rc})\")\n",
        "        failed.append((model, config_name))\n",
        "\n",
        "# ─────────────────── summary ───────────────────\n",
        "print(\"\\n\" + \"═\"*35 + \" SUMMARY \" + \"═\"*35)\n",
        "if failed:\n",
        "    print(\"The following runs failed:\")\n",
        "    for m, c in failed:\n",
        "        print(f\"  • {m}: {c}\")\n",
        "else:\n",
        "    print(\"🎉  All runs completed successfully!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}